{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "from app.website.extract_features import extract_mfcc, zero_crossing_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n",
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2787, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "# df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 70% train and 30% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1950, 2), Test set size (837, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of mfccs per clip\n",
    "n_mfcc = splits = 13\n",
    "\n",
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Zero Crossing Rate\n",
    "df_train[['zcr']] = df_train['path'].apply(lambda p: zero_crossing_rate(p, splits))\n",
    "df_test[['zcr']] = df_test['path'].apply(lambda p: zero_crossing_rate(p, splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 20\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (1365, 39), Validation set size (585, 39)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta and zero crossing rate columns\n",
    "X = df_train.iloc[:,2:5]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list(), X_train['zcr'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(), X_val['delta'].to_list(), X_val['zcr'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               4000      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 46,320\n",
      "Trainable params: 46,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 21.0180 - accuracy: 0.0930 - val_loss: 2.9275 - val_accuracy: 0.1658\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.92754, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 4.7885 - accuracy: 0.0908 - val_loss: 2.9696 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.92754\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 3.3721 - accuracy: 0.1326 - val_loss: 2.9403 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.92754\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.9857 - accuracy: 0.1685 - val_loss: 2.8522 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.92754 to 2.85222, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.9923 - accuracy: 0.1832 - val_loss: 2.7586 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.85222 to 2.75865, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.8759 - accuracy: 0.1949 - val_loss: 2.7541 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.75865 to 2.75405, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.8228 - accuracy: 0.2044 - val_loss: 2.5970 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.75405 to 2.59696, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.7185 - accuracy: 0.2125 - val_loss: 2.4697 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.59696 to 2.46968, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.6304 - accuracy: 0.2176 - val_loss: 2.3986 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.46968 to 2.39858, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.5654 - accuracy: 0.2227 - val_loss: 2.3477 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.39858 to 2.34772, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.5114 - accuracy: 0.2711 - val_loss: 2.3117 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.34772 to 2.31171, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.4710 - accuracy: 0.2842 - val_loss: 2.2983 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.31171 to 2.29828, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.4474 - accuracy: 0.2806 - val_loss: 2.2692 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.29828 to 2.26925, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.4269 - accuracy: 0.2850 - val_loss: 2.2735 - val_accuracy: 0.2940\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.26925\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.3767 - accuracy: 0.2938 - val_loss: 2.2431 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.26925 to 2.24311, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.3669 - accuracy: 0.2952 - val_loss: 2.2238 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.24311 to 2.22379, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.3168 - accuracy: 0.2967 - val_loss: 2.2133 - val_accuracy: 0.3094\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.22379 to 2.21326, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 2.3374 - accuracy: 0.3070 - val_loss: 2.1881 - val_accuracy: 0.3197\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.21326 to 2.18812, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 2.3041 - accuracy: 0.3048 - val_loss: 2.1823 - val_accuracy: 0.3248\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.18812 to 2.18228, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.2808 - accuracy: 0.3062 - val_loss: 2.1228 - val_accuracy: 0.3385\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.18228 to 2.12277, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 2.2572 - accuracy: 0.3216 - val_loss: 2.1242 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.12277\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 2s 11ms/step - loss: 2.2292 - accuracy: 0.3179 - val_loss: 2.0803 - val_accuracy: 0.3709: 2.1672 - ac\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.12277 to 2.08026, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.1881 - accuracy: 0.3348 - val_loss: 2.0576 - val_accuracy: 0.3863\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.08026 to 2.05763, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 2.1702 - accuracy: 0.3297 - val_loss: 2.0344 - val_accuracy: 0.4017\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.05763 to 2.03443, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 2s 9ms/step - loss: 2.1595 - accuracy: 0.3341 - val_loss: 1.9933 - val_accuracy: 0.4085\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.03443 to 1.99332, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 2.1252 - accuracy: 0.3465 - val_loss: 1.9404 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.99332 to 1.94044, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 2.0823 - accuracy: 0.3626 - val_loss: 1.8769 - val_accuracy: 0.4274\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.94044 to 1.87689, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.0660 - accuracy: 0.3685 - val_loss: 1.8834 - val_accuracy: 0.4684\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.87689\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 2.0128 - accuracy: 0.3839 - val_loss: 1.8013 - val_accuracy: 0.4547\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.87689 to 1.80133, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.0057 - accuracy: 0.3956 - val_loss: 1.8041 - val_accuracy: 0.4838\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.80133\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.9407 - accuracy: 0.3963 - val_loss: 1.7353 - val_accuracy: 0.4974\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.80133 to 1.73527, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 1.9607 - accuracy: 0.4139 - val_loss: 1.6814 - val_accuracy: 0.5231\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.73527 to 1.68144, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.9639 - accuracy: 0.3993 - val_loss: 1.6737 - val_accuracy: 0.5179\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.68144 to 1.67369, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 5ms/step - loss: 1.9392 - accuracy: 0.4007 - val_loss: 1.6673 - val_accuracy: 0.5060\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.67369 to 1.66733, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.8443 - accuracy: 0.4271 - val_loss: 1.5979 - val_accuracy: 0.5231\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.66733 to 1.59794, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.8355 - accuracy: 0.4322 - val_loss: 1.5880 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.59794 to 1.58800, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 1.8160 - accuracy: 0.4293 - val_loss: 1.5851 - val_accuracy: 0.5368\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.58800 to 1.58513, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 2s 13ms/step - loss: 1.8682 - accuracy: 0.4300 - val_loss: 1.5762 - val_accuracy: 0.5624\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.58513 to 1.57616, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 2s 10ms/step - loss: 1.8124 - accuracy: 0.4300 - val_loss: 1.5390 - val_accuracy: 0.5453\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.57616 to 1.53899, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 1.7679 - accuracy: 0.4447 - val_loss: 1.5190 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.53899 to 1.51905, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 2s 9ms/step - loss: 1.7813 - accuracy: 0.4564 - val_loss: 1.5434 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.51905\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 2s 9ms/step - loss: 1.7479 - accuracy: 0.4593 - val_loss: 1.5265 - val_accuracy: 0.5590\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.51905\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.8117 - accuracy: 0.4337 - val_loss: 1.5517 - val_accuracy: 0.5641\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.51905\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.7437 - accuracy: 0.4601 - val_loss: 1.5066 - val_accuracy: 0.5436\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.51905 to 1.50656, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.7582 - accuracy: 0.4374 - val_loss: 1.4777 - val_accuracy: 0.5641\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.50656 to 1.47770, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.7871 - accuracy: 0.4454 - val_loss: 1.4749 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.47770 to 1.47485, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.7210 - accuracy: 0.4667 - val_loss: 1.4699 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.47485 to 1.46991, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.7111 - accuracy: 0.4689 - val_loss: 1.4470 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.46991 to 1.44702, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.7040 - accuracy: 0.4784 - val_loss: 1.4272 - val_accuracy: 0.6103\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.44702 to 1.42719, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6614 - accuracy: 0.4821 - val_loss: 1.4841 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.42719\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.7475 - accuracy: 0.4718 - val_loss: 1.4223 - val_accuracy: 0.5812\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.42719 to 1.42226, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.6762 - accuracy: 0.4740 - val_loss: 1.4231 - val_accuracy: 0.6017\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.42226\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.6798 - accuracy: 0.4813 - val_loss: 1.4502 - val_accuracy: 0.5932\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.42226\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.6757 - accuracy: 0.4784 - val_loss: 1.4039 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.42226 to 1.40387, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6321 - accuracy: 0.4989 - val_loss: 1.4157 - val_accuracy: 0.5846\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.40387\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5998 - accuracy: 0.4894 - val_loss: 1.3962 - val_accuracy: 0.5897\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.40387 to 1.39617, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6392 - accuracy: 0.4901 - val_loss: 1.4035 - val_accuracy: 0.5932\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.39617\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6845 - accuracy: 0.4842 - val_loss: 1.4351 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.39617\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5987 - accuracy: 0.4982 - val_loss: 1.3430 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.39617 to 1.34304, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5984 - accuracy: 0.4894 - val_loss: 1.4073 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.34304\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6448 - accuracy: 0.4974 - val_loss: 1.3780 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.34304\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6101 - accuracy: 0.4857 - val_loss: 1.3801 - val_accuracy: 0.5897\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.34304\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6312 - accuracy: 0.5055 - val_loss: 1.3890 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.34304\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6076 - accuracy: 0.5004 - val_loss: 1.3819 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.34304\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6232 - accuracy: 0.4974 - val_loss: 1.3240 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.34304 to 1.32399, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5548 - accuracy: 0.5136 - val_loss: 1.3186 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.32399 to 1.31864, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5722 - accuracy: 0.5077 - val_loss: 1.2901 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.31864 to 1.29005, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6096 - accuracy: 0.5136 - val_loss: 1.3800 - val_accuracy: 0.6137\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.29005\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5884 - accuracy: 0.5172 - val_loss: 1.3631 - val_accuracy: 0.5966\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.29005\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6919 - accuracy: 0.4923 - val_loss: 1.3501 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.29005\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5859 - accuracy: 0.5194 - val_loss: 1.3353 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.29005\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5406 - accuracy: 0.5055 - val_loss: 1.3126 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.29005\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5161 - accuracy: 0.5216 - val_loss: 1.3660 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.29005\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5342 - accuracy: 0.5070 - val_loss: 1.3009 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.29005\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5642 - accuracy: 0.5194 - val_loss: 1.3169 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.29005\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5044 - accuracy: 0.5333 - val_loss: 1.2646 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.29005 to 1.26464, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5608 - accuracy: 0.5275 - val_loss: 1.3542 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.26464\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4855 - accuracy: 0.5275 - val_loss: 1.2852 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.26464\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.5214 - accuracy: 0.5275 - val_loss: 1.2891 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.26464\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.5694 - accuracy: 0.5253 - val_loss: 1.3422 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.26464\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.5295 - accuracy: 0.5179 - val_loss: 1.3125 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.26464\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4876 - accuracy: 0.5253 - val_loss: 1.3156 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.26464\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5344 - accuracy: 0.5158 - val_loss: 1.3777 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.26464\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5058 - accuracy: 0.5297 - val_loss: 1.2908 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.26464\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5436 - accuracy: 0.5121 - val_loss: 1.3218 - val_accuracy: 0.6034\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.26464\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4616 - accuracy: 0.5458 - val_loss: 1.3451 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.26464\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5281 - accuracy: 0.5443 - val_loss: 1.3116 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.26464\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5055 - accuracy: 0.5231 - val_loss: 1.2939 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.26464\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4993 - accuracy: 0.5311 - val_loss: 1.2766 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.26464\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4817 - accuracy: 0.5487 - val_loss: 1.2820 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.26464\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5169 - accuracy: 0.5172 - val_loss: 1.3089 - val_accuracy: 0.6103\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.26464\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4788 - accuracy: 0.5363 - val_loss: 1.3138 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.26464\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5148 - accuracy: 0.5165 - val_loss: 1.3127 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.26464\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4737 - accuracy: 0.5385 - val_loss: 1.2909 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.26464\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4922 - accuracy: 0.5465 - val_loss: 1.2904 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.26464\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4325 - accuracy: 0.5370 - val_loss: 1.2869 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.26464\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5725 - accuracy: 0.5114 - val_loss: 1.3339 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.26464\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4643 - accuracy: 0.5370 - val_loss: 1.2685 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.26464\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4893 - accuracy: 0.5355 - val_loss: 1.3219 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.26464\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4712 - accuracy: 0.5443 - val_loss: 1.2598 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.26464 to 1.25980, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4746 - accuracy: 0.5297 - val_loss: 1.3112 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.25980\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5113 - accuracy: 0.5194 - val_loss: 1.2419 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.25980 to 1.24193, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4572 - accuracy: 0.5341 - val_loss: 1.2963 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.24193\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5086 - accuracy: 0.5341 - val_loss: 1.3878 - val_accuracy: 0.6137\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.24193\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4478 - accuracy: 0.5377 - val_loss: 1.2398 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.24193 to 1.23979, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4776 - accuracy: 0.5436 - val_loss: 1.2390 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.23979 to 1.23898, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4647 - accuracy: 0.5465 - val_loss: 1.2878 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.23898\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4404 - accuracy: 0.5568 - val_loss: 1.3148 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.23898\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5067 - accuracy: 0.5341 - val_loss: 1.2892 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.23898\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4793 - accuracy: 0.5421 - val_loss: 1.3063 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.23898\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4516 - accuracy: 0.5451 - val_loss: 1.2531 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.23898\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5034 - accuracy: 0.5495 - val_loss: 1.2642 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.23898\n",
      "Epoch 113/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4229 - accuracy: 0.5480 - val_loss: 1.2808 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.23898\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4129 - accuracy: 0.5641 - val_loss: 1.2532 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.23898\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4729 - accuracy: 0.5407 - val_loss: 1.2916 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.23898\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.3799 - accuracy: 0.5758 - val_loss: 1.2928 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.23898\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5071 - accuracy: 0.5458 - val_loss: 1.3006 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.23898\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4015 - accuracy: 0.5634 - val_loss: 1.3151 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.23898\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4430 - accuracy: 0.5641 - val_loss: 1.2643 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.23898\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4346 - accuracy: 0.5480 - val_loss: 1.3285 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.23898\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5109 - accuracy: 0.5319 - val_loss: 1.3102 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.23898\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4599 - accuracy: 0.5436 - val_loss: 1.2715 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.23898\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4634 - accuracy: 0.5414 - val_loss: 1.2680 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.23898\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.5033 - accuracy: 0.5451 - val_loss: 1.2638 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.23898\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4445 - accuracy: 0.5436 - val_loss: 1.2570 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.23898\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 1.4237 - accuracy: 0.5473 - val_loss: 1.2745 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.23898\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.4122 - accuracy: 0.5516 - val_loss: 1.2721 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.23898\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4452 - accuracy: 0.5297 - val_loss: 1.2151 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00128: val_loss improved from 1.23898 to 1.21512, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4180 - accuracy: 0.5678 - val_loss: 1.3049 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.21512\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4708 - accuracy: 0.5656 - val_loss: 1.2812 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.21512\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 1s 9ms/step - loss: 1.4382 - accuracy: 0.5531 - val_loss: 1.3247 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.21512\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 2s 11ms/step - loss: 1.4156 - accuracy: 0.5531 - val_loss: 1.2755 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.21512\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4263 - accuracy: 0.5538 - val_loss: 1.2700 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.21512\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4566 - accuracy: 0.5516 - val_loss: 1.2902 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.21512\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5211 - accuracy: 0.5260 - val_loss: 1.2658 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.21512\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3882 - accuracy: 0.5692 - val_loss: 1.2512 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.21512\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4901 - accuracy: 0.5333 - val_loss: 1.2806 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.21512\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4532 - accuracy: 0.5619 - val_loss: 1.3242 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.21512\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4663 - accuracy: 0.5385 - val_loss: 1.3216 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.21512\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3817 - accuracy: 0.5722 - val_loss: 1.2507 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.21512\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3964 - accuracy: 0.5590 - val_loss: 1.2365 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.21512\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.4541 - accuracy: 0.5473 - val_loss: 1.2837 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.21512\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 1.4687 - accuracy: 0.5458 - val_loss: 1.2786 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.21512\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 1s 8ms/step - loss: 1.4299 - accuracy: 0.5560 - val_loss: 1.2751 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.21512\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.3815 - accuracy: 0.5707 - val_loss: 1.2576 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.21512\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.3856 - accuracy: 0.5648 - val_loss: 1.2726 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1.21512\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4539 - accuracy: 0.5451 - val_loss: 1.2494 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.21512\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4092 - accuracy: 0.5604 - val_loss: 1.2293 - val_accuracy: 0.6547\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.21512\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4907 - accuracy: 0.5480 - val_loss: 1.2749 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.21512\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 4ms/step - loss: 1.3600 - accuracy: 0.5597 - val_loss: 1.2335 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.21512\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4068 - accuracy: 0.5663 - val_loss: 1.2529 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.21512\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3798 - accuracy: 0.5656 - val_loss: 1.2291 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.21512\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4026 - accuracy: 0.5597 - val_loss: 1.2675 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.21512\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4209 - accuracy: 0.5590 - val_loss: 1.2122 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00154: val_loss improved from 1.21512 to 1.21220, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4044 - accuracy: 0.5582 - val_loss: 1.2510 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.21220\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4616 - accuracy: 0.5560 - val_loss: 1.2737 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.21220\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3701 - accuracy: 0.5780 - val_loss: 1.2125 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.21220\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4240 - accuracy: 0.5597 - val_loss: 1.2507 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.21220\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3538 - accuracy: 0.5656 - val_loss: 1.2184 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.21220\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3815 - accuracy: 0.5744 - val_loss: 1.2220 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.21220\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4027 - accuracy: 0.5714 - val_loss: 1.2100 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00161: val_loss improved from 1.21220 to 1.20999, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4396 - accuracy: 0.5538 - val_loss: 1.2629 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.20999\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4535 - accuracy: 0.5407 - val_loss: 1.2705 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.20999\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3774 - accuracy: 0.5656 - val_loss: 1.2504 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.20999\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4735 - accuracy: 0.5495 - val_loss: 1.2577 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.20999\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4639 - accuracy: 0.5560 - val_loss: 1.2721 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.20999\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4379 - accuracy: 0.5568 - val_loss: 1.2435 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.20999\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4442 - accuracy: 0.5495 - val_loss: 1.2873 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.20999\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4441 - accuracy: 0.5641 - val_loss: 1.3602 - val_accuracy: 0.5966\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.20999\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4385 - accuracy: 0.5582 - val_loss: 1.2548 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.20999\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4437 - accuracy: 0.5582 - val_loss: 1.2522 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.20999\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3835 - accuracy: 0.5685 - val_loss: 1.2599 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.20999\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3975 - accuracy: 0.5634 - val_loss: 1.2464 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.20999\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.3733 - accuracy: 0.5670 - val_loss: 1.2282 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.20999\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3892 - accuracy: 0.5612 - val_loss: 1.2638 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.20999\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3932 - accuracy: 0.5758 - val_loss: 1.2269 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.20999\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3801 - accuracy: 0.5780 - val_loss: 1.2468 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.20999\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4914 - accuracy: 0.5458 - val_loss: 1.2925 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.20999\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.5531 - val_loss: 1.2573 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.20999\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3832 - accuracy: 0.5670 - val_loss: 1.2854 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.20999\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4717 - accuracy: 0.5436 - val_loss: 1.2925 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.20999\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4161 - accuracy: 0.5487 - val_loss: 1.2317 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.20999\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4085 - accuracy: 0.5546 - val_loss: 1.3035 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.20999\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.3660 - accuracy: 0.5832 - val_loss: 1.2309 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.20999\n",
      "Training completed in time:  0:02:16.486173\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 8\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 39)\n",
      "['id10004' 'id10009' 'id10004' 'id10004' 'id10003' 'id10003' 'id10003'\n",
      " 'id10016' 'id10003' 'id10016' 'id10003' 'id10009' 'id10004' 'id10004'\n",
      " 'id10009' 'id10016' 'id10009' 'id10009' 'id10007' 'id10007' 'id10008'\n",
      " 'id10007' 'id10007' 'id10001' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10014' 'id10007'\n",
      " 'id10006' 'id10006' 'id10006' 'id10004' 'id10004' 'id10004' 'id10006'\n",
      " 'id10004' 'id10018' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10004' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10004' 'id10014' 'id10009' 'id10006' 'id10004' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10014' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10004' 'id10006' 'id10004' 'id10008' 'id10004' 'id10001'\n",
      " 'id10008' 'id10001' 'id10001' 'id10001' 'id10008' 'id10008' 'id10020'\n",
      " 'id10001' 'id10001' 'id10008' 'id10003' 'id10008' 'id10008' 'id10008'\n",
      " 'id10016' 'id10001' 'id10001' 'id10001' 'id10008' 'id10004' 'id10004'\n",
      " 'id10008' 'id10008' 'id10004' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10001' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10003' 'id10008' 'id10008' 'id10008' 'id10004' 'id10001'\n",
      " 'id10008' 'id10008' 'id10012' 'id10018' 'id10012' 'id10012' 'id10016'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10018' 'id10018'\n",
      " 'id10012' 'id10018' 'id10003' 'id10012' 'id10012' 'id10018' 'id10012'\n",
      " 'id10012' 'id10018' 'id10016' 'id10018' 'id10012' 'id10018' 'id10018'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10018' 'id10002' 'id10012'\n",
      " 'id10018' 'id10016' 'id10012' 'id10020' 'id10018' 'id10012' 'id10018'\n",
      " 'id10012' 'id10018' 'id10018' 'id10018' 'id10018' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10003' 'id10004' 'id10004' 'id10004' 'id10003'\n",
      " 'id10004' 'id10004' 'id10004' 'id10003' 'id10004' 'id10001' 'id10003'\n",
      " 'id10004' 'id10004' 'id10014' 'id10006' 'id10014' 'id10014' 'id10004'\n",
      " 'id10014' 'id10006' 'id10006' 'id10004' 'id10004' 'id10014' 'id10004'\n",
      " 'id10014' 'id10004' 'id10004' 'id10014' 'id10006' 'id10014' 'id10014'\n",
      " 'id10014' 'id10006' 'id10007' 'id10014' 'id10014' 'id10014' 'id10004'\n",
      " 'id10008' 'id10006' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10003' 'id10004' 'id10014' 'id10003' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10001' 'id10004' 'id10008' 'id10004' 'id10008'\n",
      " 'id10004' 'id10004' 'id10008' 'id10004' 'id10004' 'id10008' 'id10008'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10008' 'id10004' 'id10004'\n",
      " 'id10004' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10018' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10002' 'id10002' 'id10002' 'id10018'\n",
      " 'id10018' 'id10002' 'id10003' 'id10018' 'id10018' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10018' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10003' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10003' 'id10018' 'id10008' 'id10008' 'id10003' 'id10018' 'id10003'\n",
      " 'id10003' 'id10018' 'id10003' 'id10018' 'id10003' 'id10018' 'id10003'\n",
      " 'id10016' 'id10008' 'id10008' 'id10003' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10003' 'id10016' 'id10016' 'id10016'\n",
      " 'id10003' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016' 'id10016'\n",
      " 'id10001' 'id10016' 'id10003' 'id10016' 'id10020' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10018' 'id10016' 'id10003'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10020'\n",
      " 'id10016' 'id10003' 'id10016' 'id10016' 'id10016' 'id10011' 'id10003'\n",
      " 'id10016' 'id10020' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10003' 'id10016' 'id10016' 'id10016' 'id10016' 'id10018'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10016' 'id10018' 'id10011'\n",
      " 'id10003' 'id10018' 'id10011' 'id10018' 'id10016' 'id10011' 'id10011'\n",
      " 'id10011' 'id10018' 'id10011' 'id10011' 'id10018' 'id10011' 'id10018'\n",
      " 'id10016' 'id10011' 'id10016' 'id10011' 'id10018' 'id10011' 'id10011'\n",
      " 'id10018' 'id10011' 'id10011' 'id10011' 'id10018' 'id10016' 'id10018'\n",
      " 'id10011' 'id10011' 'id10018' 'id10011' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10003' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10003' 'id10004' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10002' 'id10003' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10004' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10017' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10008' 'id10018' 'id10002' 'id10007' 'id10018'\n",
      " 'id10012' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10003' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10017' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10003' 'id10018'\n",
      " 'id10003' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10001' 'id10020' 'id10020' 'id10020' 'id10012' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10018' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10019' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10001' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10001' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10001' 'id10019' 'id10018' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10001' 'id10019' 'id10019' 'id10003'\n",
      " 'id10001' 'id10019' 'id10003' 'id10020' 'id10019' 'id10020' 'id10003'\n",
      " 'id10019' 'id10020' 'id10019' 'id10020' 'id10019' 'id10002' 'id10002'\n",
      " 'id10003' 'id10016' 'id10001' 'id10008' 'id10016' 'id10007' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10010' 'id10010' 'id10001' 'id10008'\n",
      " 'id10003' 'id10017' 'id10016' 'id10003' 'id10003' 'id10016' 'id10016'\n",
      " 'id10016' 'id10003' 'id10003' 'id10003' 'id10016' 'id10017' 'id10003'\n",
      " 'id10017' 'id10016' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10016' 'id10003' 'id10017' 'id10003' 'id10017' 'id10016'\n",
      " 'id10017' 'id10017' 'id10003' 'id10016' 'id10003' 'id10017' 'id10016'\n",
      " 'id10003' 'id10018' 'id10017' 'id10003' 'id10003' 'id10003' 'id10017'\n",
      " 'id10016' 'id10017' 'id10017' 'id10016']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.39      0.39      0.39        23\n",
      "     id10002       0.85      0.72      0.78        39\n",
      "     id10003       0.45      0.98      0.62        51\n",
      "     id10004       0.32      0.78      0.45        32\n",
      "     id10005       0.00      0.00      0.00        18\n",
      "     id10006       0.81      0.68      0.74        38\n",
      "     id10007       0.88      0.88      0.88        24\n",
      "     id10008       0.47      0.78      0.59        32\n",
      "     id10009       0.83      0.28      0.42        18\n",
      "     id10010       1.00      0.12      0.22        16\n",
      "     id10011       0.95      0.53      0.68        36\n",
      "     id10012       0.92      0.49      0.64        45\n",
      "     id10013       0.00      0.00      0.00        15\n",
      "     id10014       0.76      0.45      0.57        29\n",
      "     id10015       0.00      0.00      0.00        18\n",
      "     id10016       0.69      0.78      0.73        76\n",
      "     id10017       0.90      0.39      0.55        46\n",
      "     id10018       0.57      0.80      0.67        81\n",
      "     id10019       0.92      0.52      0.67        23\n",
      "     id10020       0.95      0.97      0.96       177\n",
      "\n",
      "    accuracy                           0.68       837\n",
      "   macro avg       0.63      0.53      0.53       837\n",
      "weighted avg       0.72      0.68      0.66       837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),\n",
    "                    df_test['delta'].to_list(),\n",
    "                    df_test['zcr'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10001' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001' 'id10001'\n",
      " 'id10001' 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10001' 'id10001' 'id10001' 'id10001' 'id10002'\n",
      " 'id10002' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10001' 'id10001' 'id10002' 'id10002'\n",
      " 'id10001' 'id10001' 'id10001' 'id10002' 'id10002' 'id10002' 'id10001'\n",
      " 'id10002' 'id10001' 'id10002' 'id10002' 'id10001' 'id10002' 'id10001'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10001' 'id10002' 'id10001' 'id10002' 'id10002' 'id10001'\n",
      " 'id10001' 'id10002' 'id10002' 'id10002']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.02      0.39      0.04        23\n",
      "     id10002       0.04      0.49      0.08        39\n",
      "     id10003       0.00      0.00      0.00        51\n",
      "     id10004       0.00      0.00      0.00        32\n",
      "     id10005       0.00      0.00      0.00        18\n",
      "     id10006       0.00      0.00      0.00        38\n",
      "     id10007       0.00      0.00      0.00        24\n",
      "     id10008       0.00      0.00      0.00        32\n",
      "     id10009       0.00      0.00      0.00        18\n",
      "     id10010       0.00      0.00      0.00        16\n",
      "     id10011       0.00      0.00      0.00        36\n",
      "     id10012       0.00      0.00      0.00        45\n",
      "     id10013       0.00      0.00      0.00        15\n",
      "     id10014       0.00      0.00      0.00        29\n",
      "     id10015       0.00      0.00      0.00        18\n",
      "     id10016       0.00      0.00      0.00        76\n",
      "     id10017       0.00      0.00      0.00        46\n",
      "     id10018       0.00      0.00      0.00        81\n",
      "     id10019       0.00      0.00      0.00        23\n",
      "     id10020       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.03       837\n",
      "   macro avg       0.00      0.04      0.01       837\n",
      "weighted avg       0.00      0.03      0.00       837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/mixture/_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "gmm = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "gmm.fit(X_train)\n",
    "\n",
    "y_true_gmm = df_test['speaker']\n",
    "\n",
    "y_pred_gmm = gmm.predict(X_test)\n",
    "y_pred_gmm = le.classes_[y_pred_gmm]\n",
    "print(y_pred_gmm)\n",
    "print(classification_report(y_true_gmm, y_pred_gmm, target_names=le.classes_))\n",
    "\n",
    "filename = 'saved_models/gaussian_mixture_model.sav'\n",
    "pickle.dump(gmm, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "# # display predicted scores by the model as a contour plot\n",
    "# x = np.linspace(0., 39., 39, endpoint=True)\n",
    "# # np.linspace(0, 10, N, endpoint=True)\n",
    "# y = np.linspace(0., 39., 39, endpoint=True)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "# Z = -clf.score_samples(XX)\n",
    "# Z = Z.reshape(X.shape)\n",
    "\n",
    "# CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0),\n",
    "#                  levels=np.logspace(0, 3, 10))\n",
    "# CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "# plt.scatter(X_train[:, 0], X_train[:, 1], .8)\n",
    "\n",
    "# plt.title('Negative log-likelihood predicted by a GMM')\n",
    "# plt.axis('tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
