{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2787, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "# df = df[:200]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 80% train and 20% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1950, 2), Test set size (837, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 20\n",
    "def extract_mfcc(row, nr_mfcc):\n",
    "    signal ,sr = librosa.load(row)\n",
    "    mfcc_feature = librosa.feature.mfcc(signal, n_mfcc=nr_mfcc, sr=sr, hop_length=256)\n",
    "    delta_feature = librosa.feature.delta(mfcc_feature)\n",
    "    \n",
    "    mfcc_feature = np.mean(mfcc_feature.T,axis=0)\n",
    "    delta_feature = np.mean(delta_feature.T, axis=0)\n",
    "\n",
    "    return pd.Series([mfcc_feature, delta_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-234.83286, 133.73509, -31.300879, 38.71376, ...</td>\n",
       "      <td>[-0.22536033, -0.12889376, -0.028585024, 0.124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-423.196, 151.2904, -20.332306, -2.9083853, -...</td>\n",
       "      <td>[0.0002549889, -0.008353452, -0.00092818623, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-271.4974, 132.00212, -48.866318, 48.387047, ...</td>\n",
       "      <td>[-0.20052902, 0.018294884, 0.1554059, 0.065510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-206.58463, 144.25214, -50.279385, 31.640982,...</td>\n",
       "      <td>[-0.05777987, 0.034374237, 0.038280718, 0.0138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-250.60458, 139.20047, -46.59575, 34.955204, ...</td>\n",
       "      <td>[0.0495788, -0.03894916, 0.045858603, -0.10095...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-234.83286, 133.73509, -31.300879, 38.71376, ...   \n",
       "5   [-423.196, 151.2904, -20.332306, -2.9083853, -...   \n",
       "34  [-271.4974, 132.00212, -48.866318, 48.387047, ...   \n",
       "13  [-206.58463, 144.25214, -50.279385, 31.640982,...   \n",
       "45  [-250.60458, 139.20047, -46.59575, 34.955204, ...   \n",
       "\n",
       "                                                delta  \n",
       "0   [-0.22536033, -0.12889376, -0.028585024, 0.124...  \n",
       "5   [0.0002549889, -0.008353452, -0.00092818623, 0...  \n",
       "34  [-0.20052902, 0.018294884, 0.1554059, 0.065510...  \n",
       "13  [-0.05777987, 0.034374237, 0.038280718, 0.0138...  \n",
       "45  [0.0495788, -0.03894916, 0.045858603, -0.10095...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-234.83286, 133.73509, -31.300879, 38.71376, ...</td>\n",
       "      <td>[-0.22536033, -0.12889376, -0.028585024, 0.124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-423.196, 151.2904, -20.332306, -2.9083853, -...</td>\n",
       "      <td>[0.0002549889, -0.008353452, -0.00092818623, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-271.4974, 132.00212, -48.866318, 48.387047, ...</td>\n",
       "      <td>[-0.20052902, 0.018294884, 0.1554059, 0.065510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-206.58463, 144.25214, -50.279385, 31.640982,...</td>\n",
       "      <td>[-0.05777987, 0.034374237, 0.038280718, 0.0138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-250.60458, 139.20047, -46.59575, 34.955204, ...</td>\n",
       "      <td>[0.0495788, -0.03894916, 0.045858603, -0.10095...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-234.83286, 133.73509, -31.300879, 38.71376, ...   \n",
       "5   [-423.196, 151.2904, -20.332306, -2.9083853, -...   \n",
       "34  [-271.4974, 132.00212, -48.866318, 48.387047, ...   \n",
       "13  [-206.58463, 144.25214, -50.279385, 31.640982,...   \n",
       "45  [-250.60458, 139.20047, -46.59575, 34.955204, ...   \n",
       "\n",
       "                                                delta  \n",
       "0   [-0.22536033, -0.12889376, -0.028585024, 0.124...  \n",
       "5   [0.0002549889, -0.008353452, -0.00092818623, 0...  \n",
       "34  [-0.20052902, 0.018294884, 0.1554059, 0.065510...  \n",
       "13  [-0.05777987, 0.034374237, 0.038280718, 0.0138...  \n",
       "45  [0.0495788, -0.03894916, 0.045858603, -0.10095...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 20\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (1365, 40), Validation set size (585, 40)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta columns\n",
    "X = df_train.iloc[:,2:4]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(),X_val['delta'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 46,420\n",
      "Trainable params: 46,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 22.8009 - accuracy: 0.0916 - val_loss: 2.9703 - val_accuracy: 0.0872\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.97031, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 4.4299 - accuracy: 0.0762 - val_loss: 2.9628 - val_accuracy: 0.0821\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.97031 to 2.96281, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 3.3774 - accuracy: 0.1260 - val_loss: 2.9333 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.96281 to 2.93329, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 3.0288 - accuracy: 0.1802 - val_loss: 2.9055 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.93329 to 2.90546, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.9942 - accuracy: 0.1766 - val_loss: 2.8786 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.90546 to 2.87857, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.9108 - accuracy: 0.2066 - val_loss: 2.8553 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.87857 to 2.85531, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 2.9044 - accuracy: 0.1934 - val_loss: 2.8352 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.85531 to 2.83517, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.8331 - accuracy: 0.2073 - val_loss: 2.8196 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.83517 to 2.81955, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.8442 - accuracy: 0.2029 - val_loss: 2.8049 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.81955 to 2.80492, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.7928 - accuracy: 0.2059 - val_loss: 2.7863 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.80492 to 2.78628, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.7809 - accuracy: 0.2073 - val_loss: 2.7353 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.78628 to 2.73534, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.7559 - accuracy: 0.2081 - val_loss: 2.6962 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.73534 to 2.69619, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.7140 - accuracy: 0.2066 - val_loss: 2.5153 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.69619 to 2.51534, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 2.6382 - accuracy: 0.2132 - val_loss: 2.4376 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.51534 to 2.43757, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.5424 - accuracy: 0.2198 - val_loss: 2.3831 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.43757 to 2.38308, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.4962 - accuracy: 0.2264 - val_loss: 2.2762 - val_accuracy: 0.2479\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.38308 to 2.27617, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 2.4590 - accuracy: 0.2300 - val_loss: 2.2619 - val_accuracy: 0.2838\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.27617 to 2.26187, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.3526 - accuracy: 0.2659 - val_loss: 2.1956 - val_accuracy: 0.2940\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.26187 to 2.19555, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.3388 - accuracy: 0.2579 - val_loss: 2.2070 - val_accuracy: 0.2940\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.19555\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.3188 - accuracy: 0.2674 - val_loss: 2.1712 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.19555 to 2.17123, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.2838 - accuracy: 0.2974 - val_loss: 2.1442 - val_accuracy: 0.3026\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.17123 to 2.14415, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 2.2757 - accuracy: 0.2982 - val_loss: 2.0633 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.14415 to 2.06326, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.2350 - accuracy: 0.2967 - val_loss: 2.0648 - val_accuracy: 0.3060\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.06326\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.2267 - accuracy: 0.3011 - val_loss: 2.0865 - val_accuracy: 0.3453\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.06326\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.2247 - accuracy: 0.3297 - val_loss: 2.0052 - val_accuracy: 0.3897\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.06326 to 2.00524, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.1698 - accuracy: 0.3370 - val_loss: 1.9677 - val_accuracy: 0.3368\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.00524 to 1.96771, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.1165 - accuracy: 0.3319 - val_loss: 1.8401 - val_accuracy: 0.4205\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.96771 to 1.84010, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 2.0826 - accuracy: 0.3692 - val_loss: 1.8744 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.84010\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 2.0615 - accuracy: 0.3524 - val_loss: 1.7522 - val_accuracy: 0.4786\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.84010 to 1.75219, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 2.0012 - accuracy: 0.3736 - val_loss: 1.7879 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.75219\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.9852 - accuracy: 0.3751 - val_loss: 1.7275 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.75219 to 1.72752, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.9283 - accuracy: 0.3846 - val_loss: 1.7509 - val_accuracy: 0.4752\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.72752\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.9434 - accuracy: 0.3832 - val_loss: 1.6689 - val_accuracy: 0.4786\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.72752 to 1.66888, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 6ms/step - loss: 1.8926 - accuracy: 0.3853 - val_loss: 1.6040 - val_accuracy: 0.5077\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.66888 to 1.60400, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.9147 - accuracy: 0.3919 - val_loss: 1.6310 - val_accuracy: 0.4991\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.60400\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.8907 - accuracy: 0.4059 - val_loss: 1.5771 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.60400 to 1.57709, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.8424 - accuracy: 0.4095 - val_loss: 1.5344 - val_accuracy: 0.5060\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.57709 to 1.53442, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.8529 - accuracy: 0.4168 - val_loss: 1.5655 - val_accuracy: 0.5402\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.53442\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.7994 - accuracy: 0.4154 - val_loss: 1.5023 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.53442 to 1.50232, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.7884 - accuracy: 0.4366 - val_loss: 1.4878 - val_accuracy: 0.5350\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.50232 to 1.48782, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.8104 - accuracy: 0.4315 - val_loss: 1.4922 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.48782\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.7654 - accuracy: 0.4264 - val_loss: 1.4873 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.48782 to 1.48731, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.7469 - accuracy: 0.4454 - val_loss: 1.4032 - val_accuracy: 0.5709\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.48731 to 1.40319, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.7428 - accuracy: 0.4418 - val_loss: 1.4757 - val_accuracy: 0.5726\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.40319\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.7271 - accuracy: 0.4403 - val_loss: 1.4525 - val_accuracy: 0.5436\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.40319\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6954 - accuracy: 0.4564 - val_loss: 1.4639 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.40319\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6982 - accuracy: 0.4549 - val_loss: 1.4383 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.40319\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.6913 - accuracy: 0.4696 - val_loss: 1.4227 - val_accuracy: 0.5419\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.40319\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6940 - accuracy: 0.4681 - val_loss: 1.3774 - val_accuracy: 0.5744\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.40319 to 1.37738, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6387 - accuracy: 0.4813 - val_loss: 1.3624 - val_accuracy: 0.5846\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.37738 to 1.36243, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6928 - accuracy: 0.4615 - val_loss: 1.3420 - val_accuracy: 0.5709\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.36243 to 1.34204, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.6248 - accuracy: 0.4711 - val_loss: 1.3744 - val_accuracy: 0.5846\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.34204\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6823 - accuracy: 0.4652 - val_loss: 1.3775 - val_accuracy: 0.5795\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.34204\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6400 - accuracy: 0.4960 - val_loss: 1.3277 - val_accuracy: 0.5795\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.34204 to 1.32770, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.6378 - accuracy: 0.4842 - val_loss: 1.3977 - val_accuracy: 0.5436\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.32770\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.6114 - accuracy: 0.4806 - val_loss: 1.3240 - val_accuracy: 0.5897\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.32770 to 1.32399, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5763 - accuracy: 0.4930 - val_loss: 1.3373 - val_accuracy: 0.5915\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.32399\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5832 - accuracy: 0.4901 - val_loss: 1.3158 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.32399 to 1.31577, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5979 - accuracy: 0.5121 - val_loss: 1.2623 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.31577 to 1.26230, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.6444 - accuracy: 0.4777 - val_loss: 1.2796 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.26230\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.6492 - accuracy: 0.4762 - val_loss: 1.3466 - val_accuracy: 0.5624\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.26230\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5772 - accuracy: 0.4872 - val_loss: 1.2443 - val_accuracy: 0.6034\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.26230 to 1.24426, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4978 - accuracy: 0.5179 - val_loss: 1.2728 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.24426\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5392 - accuracy: 0.4974 - val_loss: 1.2210 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.24426 to 1.22097, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.5452 - accuracy: 0.5209 - val_loss: 1.2925 - val_accuracy: 0.5812\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.22097\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5551 - accuracy: 0.5033 - val_loss: 1.2610 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.22097\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5422 - accuracy: 0.5048 - val_loss: 1.2370 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.22097\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5344 - accuracy: 0.5084 - val_loss: 1.2090 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.22097 to 1.20904, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5749 - accuracy: 0.4989 - val_loss: 1.2859 - val_accuracy: 0.5744\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.20904\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 1s 4ms/step - loss: 1.5547 - accuracy: 0.4982 - val_loss: 1.2364 - val_accuracy: 0.6034\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.20904\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5539 - accuracy: 0.4960 - val_loss: 1.2537 - val_accuracy: 0.6034\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.20904\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.5274 - accuracy: 0.5172 - val_loss: 1.2514 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.20904\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.5117 - accuracy: 0.5179 - val_loss: 1.2647 - val_accuracy: 0.6120\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.20904\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4999 - accuracy: 0.5201 - val_loss: 1.2260 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.20904\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4763 - accuracy: 0.5106 - val_loss: 1.2485 - val_accuracy: 0.6137\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.20904\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4752 - accuracy: 0.5172 - val_loss: 1.1977 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.20904 to 1.19767, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4636 - accuracy: 0.5106 - val_loss: 1.2960 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.19767\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4689 - accuracy: 0.5121 - val_loss: 1.1661 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.19767 to 1.16605, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4910 - accuracy: 0.5136 - val_loss: 1.2396 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.16605\n",
      "Epoch 80/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4754 - accuracy: 0.5070 - val_loss: 1.1998 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.16605\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4875 - accuracy: 0.5201 - val_loss: 1.2147 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.16605\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.4407 - accuracy: 0.5267 - val_loss: 1.1630 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.16605 to 1.16296, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4591 - accuracy: 0.5275 - val_loss: 1.1872 - val_accuracy: 0.6291\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.16296\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4175 - accuracy: 0.5253 - val_loss: 1.1624 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.16296 to 1.16239, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4548 - accuracy: 0.5282 - val_loss: 1.2060 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.16239\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4534 - accuracy: 0.5377 - val_loss: 1.2936 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.16239\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4752 - accuracy: 0.5245 - val_loss: 1.1992 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.16239\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4704 - accuracy: 0.5333 - val_loss: 1.2233 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.16239\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3980 - accuracy: 0.5458 - val_loss: 1.1436 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.16239 to 1.14355, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4403 - accuracy: 0.5253 - val_loss: 1.1469 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.14355\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4700 - accuracy: 0.5245 - val_loss: 1.2108 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.14355\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4714 - accuracy: 0.5209 - val_loss: 1.1988 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.14355\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4680 - accuracy: 0.5194 - val_loss: 1.1959 - val_accuracy: 0.6462\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.14355\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.5009 - accuracy: 0.5114 - val_loss: 1.1691 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.14355\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3827 - accuracy: 0.5604 - val_loss: 1.1742 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.14355\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.4562 - accuracy: 0.5348 - val_loss: 1.2162 - val_accuracy: 0.6085\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.14355\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 1.3740 - accuracy: 0.5509 - val_loss: 1.2344 - val_accuracy: 0.6034\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.14355\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4602 - accuracy: 0.53 - 1s 4ms/step - loss: 1.4557 - accuracy: 0.5311 - val_loss: 1.2108 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.14355\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 1s 6ms/step - loss: 1.4371 - accuracy: 0.5348 - val_loss: 1.1542 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.14355\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4402 - accuracy: 0.5304 - val_loss: 1.2175 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.14355\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4169 - accuracy: 0.5297 - val_loss: 1.1579 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.14355\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3910 - accuracy: 0.5473 - val_loss: 1.1224 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00102: val_loss improved from 1.14355 to 1.12239, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4049 - accuracy: 0.5568 - val_loss: 1.1877 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.12239\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3955 - accuracy: 0.5502 - val_loss: 1.2068 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.12239\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.5465 - val_loss: 1.2092 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.12239\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4601 - accuracy: 0.5297 - val_loss: 1.1485 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.12239\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4223 - accuracy: 0.5407 - val_loss: 1.2125 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.12239\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.3978 - accuracy: 0.5516 - val_loss: 1.1530 - val_accuracy: 0.6342\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.12239\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4301 - accuracy: 0.5326 - val_loss: 1.1447 - val_accuracy: 0.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00109: val_loss did not improve from 1.12239\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4105 - accuracy: 0.5458 - val_loss: 1.1810 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.12239\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3970 - accuracy: 0.5524 - val_loss: 1.1871 - val_accuracy: 0.6547\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.12239\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 1s 4ms/step - loss: 1.4155 - accuracy: 0.5531 - val_loss: 1.1402 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.12239\n",
      "Epoch 113/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.4051 - accuracy: 0.5473 - val_loss: 1.1714 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.12239\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3710 - accuracy: 0.5465 - val_loss: 1.1844 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.12239\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3922 - accuracy: 0.5355 - val_loss: 1.2144 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.12239\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3784 - accuracy: 0.5524 - val_loss: 1.1417 - val_accuracy: 0.6188\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.12239\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3807 - accuracy: 0.5516 - val_loss: 1.2037 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.12239\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3800 - accuracy: 0.5634 - val_loss: 1.1638 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.12239\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3995 - accuracy: 0.5473 - val_loss: 1.2077 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.12239\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3420 - accuracy: 0.5546 - val_loss: 1.1847 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.12239\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.3794 - accuracy: 0.5582 - val_loss: 1.2591 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.12239\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3959 - accuracy: 0.5370 - val_loss: 1.1600 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.12239\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3336 - accuracy: 0.5604 - val_loss: 1.1249 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.12239\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3716 - accuracy: 0.5495 - val_loss: 1.2641 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.12239\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3297 - accuracy: 0.5560 - val_loss: 1.0995 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.12239 to 1.09954, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3700 - accuracy: 0.5319 - val_loss: 1.1137 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.09954\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 1s 3ms/step - loss: 1.4403 - accuracy: 0.5370 - val_loss: 1.1027 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.09954\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3504 - accuracy: 0.5473 - val_loss: 1.1122 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.09954\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3853 - accuracy: 0.5429 - val_loss: 1.0864 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00129: val_loss improved from 1.09954 to 1.08644, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3575 - accuracy: 0.5451 - val_loss: 1.1702 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.08644\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5538 - val_loss: 1.0828 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.08644 to 1.08282, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3377 - accuracy: 0.5516 - val_loss: 1.1376 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1.08282\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3429 - accuracy: 0.5465 - val_loss: 1.0938 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.08282\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3290 - accuracy: 0.5685 - val_loss: 1.1017 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.08282\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3938 - accuracy: 0.5495 - val_loss: 1.1081 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.08282\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3446 - accuracy: 0.5692 - val_loss: 1.1802 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.08282\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.5451 - val_loss: 1.1417 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.08282\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3551 - accuracy: 0.5582 - val_loss: 1.1963 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.08282\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3900 - accuracy: 0.5480 - val_loss: 1.2634 - val_accuracy: 0.6274\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.08282\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2594 - accuracy: 0.5766 - val_loss: 1.1021 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.08282\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3533 - accuracy: 0.5678 - val_loss: 1.1547 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.08282\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2894 - accuracy: 0.5553 - val_loss: 1.1256 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.08282\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3749 - accuracy: 0.5531 - val_loss: 1.1616 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.08282\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3400 - accuracy: 0.5619 - val_loss: 1.1078 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.08282\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3544 - accuracy: 0.5685 - val_loss: 1.1293 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1.08282\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3613 - accuracy: 0.5560 - val_loss: 1.0781 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00146: val_loss improved from 1.08282 to 1.07812, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2966 - accuracy: 0.5729 - val_loss: 1.0946 - val_accuracy: 0.6855\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.07812\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3126 - accuracy: 0.5692 - val_loss: 1.1267 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.07812\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3291 - accuracy: 0.5553 - val_loss: 1.0919 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.07812\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3550 - accuracy: 0.5590 - val_loss: 1.0868 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.07812\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3390 - accuracy: 0.5810 - val_loss: 1.1062 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.07812\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2825 - accuracy: 0.5758 - val_loss: 1.0771 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00152: val_loss improved from 1.07812 to 1.07706, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3759 - accuracy: 0.5700 - val_loss: 1.1436 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.07706\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3195 - accuracy: 0.5443 - val_loss: 1.1963 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.07706\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2853 - accuracy: 0.5744 - val_loss: 1.0813 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.07706\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3007 - accuracy: 0.5832 - val_loss: 1.1399 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.07706\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2792 - accuracy: 0.5670 - val_loss: 1.1134 - val_accuracy: 0.6615\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.07706\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2808 - accuracy: 0.5692 - val_loss: 1.1439 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 1.07706\n",
      "Epoch 159/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3677 - accuracy: 0.5722 - val_loss: 1.1531 - val_accuracy: 0.6393\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.07706\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3031 - accuracy: 0.5670 - val_loss: 1.1021 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.07706\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2981 - accuracy: 0.5824 - val_loss: 1.1038 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.07706\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2483 - accuracy: 0.5897 - val_loss: 1.0597 - val_accuracy: 0.6838\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.07706 to 1.05965, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3668 - accuracy: 0.5648 - val_loss: 1.1425 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.05965\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2870 - accuracy: 0.5817 - val_loss: 1.0795 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.05965\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2563 - accuracy: 0.5883 - val_loss: 1.1004 - val_accuracy: 0.6427\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.05965\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2942 - accuracy: 0.5714 - val_loss: 1.1247 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.05965\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3251 - accuracy: 0.5619 - val_loss: 1.1531 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.05965\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3211 - accuracy: 0.5780 - val_loss: 1.1832 - val_accuracy: 0.6547\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 1.05965\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3468 - accuracy: 0.5531 - val_loss: 1.0712 - val_accuracy: 0.6547\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.05965\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3393 - accuracy: 0.5663 - val_loss: 1.1157 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 1.05965\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2897 - accuracy: 0.5692 - val_loss: 1.0663 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 1.05965\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3056 - accuracy: 0.5582 - val_loss: 1.0625 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 1.05965\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3113 - accuracy: 0.5729 - val_loss: 1.0868 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.05965\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3235 - accuracy: 0.5641 - val_loss: 1.1022 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.05965\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3179 - accuracy: 0.5751 - val_loss: 1.1146 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 1.05965\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3022 - accuracy: 0.5634 - val_loss: 1.1032 - val_accuracy: 0.6838\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.05965\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2663 - accuracy: 0.5824 - val_loss: 1.1227 - val_accuracy: 0.7026\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.05965\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3362 - accuracy: 0.5722 - val_loss: 1.1681 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.05965\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2993 - accuracy: 0.5663 - val_loss: 1.1411 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.05965\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3401 - accuracy: 0.5590 - val_loss: 1.1171 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 1.05965\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2685 - accuracy: 0.5846 - val_loss: 1.1577 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.05965\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2944 - accuracy: 0.5714 - val_loss: 1.0822 - val_accuracy: 0.6838\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.05965\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2705 - accuracy: 0.5941 - val_loss: 1.0863 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.05965\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2761 - accuracy: 0.5736 - val_loss: 1.1528 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.05965\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3093 - accuracy: 0.5670 - val_loss: 1.1512 - val_accuracy: 0.6444\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.05965\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3414 - accuracy: 0.5568 - val_loss: 1.1870 - val_accuracy: 0.6547\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.05965\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3561 - accuracy: 0.5663 - val_loss: 1.1182 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.05965\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2503 - accuracy: 0.5766 - val_loss: 1.0657 - val_accuracy: 0.6906\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.05965\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2944 - accuracy: 0.5780 - val_loss: 1.1759 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.05965\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.3975 - accuracy: 0.5436 - val_loss: 1.0862 - val_accuracy: 0.6581\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.05965\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3560 - accuracy: 0.5722 - val_loss: 1.1262 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.05965\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2866 - accuracy: 0.5824 - val_loss: 1.1243 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.05965\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2934 - accuracy: 0.5788 - val_loss: 1.1381 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.05965\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3048 - accuracy: 0.5736 - val_loss: 1.1428 - val_accuracy: 0.6615\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 1.05965\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 0s 3ms/step - loss: 1.2808 - accuracy: 0.5692 - val_loss: 1.1529 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.05965\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3224 - accuracy: 0.5780 - val_loss: 1.1567 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 1.05965\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3366 - accuracy: 0.5516 - val_loss: 1.1754 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.05965\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2845 - accuracy: 0.5663 - val_loss: 1.1678 - val_accuracy: 0.6838\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.05965\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.3043 - accuracy: 0.5780 - val_loss: 1.1396 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 1.05965\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 0s 2ms/step - loss: 1.2522 - accuracy: 0.5751 - val_loss: 1.1335 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.05965\n",
      "Training completed in time:  0:01:47.951138\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 8\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 40)\n",
      "['id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10001' 'id10004'\n",
      " 'id10001' 'id10004' 'id10009' 'id10001' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10009' 'id10004' 'id10004' 'id10007' 'id10007' 'id10014'\n",
      " 'id10007' 'id10007' 'id10004' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10014' 'id10007' 'id10014' 'id10007' 'id10007'\n",
      " 'id10014' 'id10007' 'id10014' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10014' 'id10006' 'id10006'\n",
      " 'id10004' 'id10014' 'id10006' 'id10014' 'id10006' 'id10006' 'id10006'\n",
      " 'id10004' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10004' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10004' 'id10006' 'id10014' 'id10004' 'id10004' 'id10001'\n",
      " 'id10008' 'id10004' 'id10004' 'id10004' 'id10004' 'id10001' 'id10001'\n",
      " 'id10016' 'id10014' 'id10004' 'id10004' 'id10016' 'id10004' 'id10004'\n",
      " 'id10016' 'id10001' 'id10001' 'id10004' 'id10004' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10001' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10012' 'id10012' 'id10012' 'id10012' 'id10018'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10018' 'id10012' 'id10018' 'id10012' 'id10012' 'id10018'\n",
      " 'id10012' 'id10012' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10018' 'id10012' 'id10012'\n",
      " 'id10012' 'id10018' 'id10018' 'id10012' 'id10018' 'id10014' 'id10014'\n",
      " 'id10008' 'id10015' 'id10008' 'id10004' 'id10015' 'id10008' 'id10008'\n",
      " 'id10015' 'id10015' 'id10004' 'id10008' 'id10015' 'id10004' 'id10008'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10014' 'id10006' 'id10004'\n",
      " 'id10004' 'id10006' 'id10014' 'id10004' 'id10004' 'id10006' 'id10004'\n",
      " 'id10006' 'id10004' 'id10004' 'id10014' 'id10004' 'id10014' 'id10007'\n",
      " 'id10004' 'id10006' 'id10014' 'id10014' 'id10004' 'id10014' 'id10006'\n",
      " 'id10014' 'id10006' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10014' 'id10004' 'id10004' 'id10004' 'id10004' 'id10014' 'id10004'\n",
      " 'id10001' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10001' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10003' 'id10003' 'id10016' 'id10018' 'id10004' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10016' 'id10003'\n",
      " 'id10003' 'id10004' 'id10016' 'id10016' 'id10003' 'id10003' 'id10004'\n",
      " 'id10003' 'id10003' 'id10011' 'id10018' 'id10016' 'id10016' 'id10016'\n",
      " 'id10003' 'id10003' 'id10003' 'id10016' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10016' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10016' 'id10003' 'id10016' 'id10003'\n",
      " 'id10016' 'id10003' 'id10003' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10003' 'id10002' 'id10011' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10011'\n",
      " 'id10002' 'id10011' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10011' 'id10002' 'id10002'\n",
      " 'id10004' 'id10016' 'id10004' 'id10004' 'id10017' 'id10018' 'id10004'\n",
      " 'id10016' 'id10003' 'id10003' 'id10005' 'id10004' 'id10004' 'id10016'\n",
      " 'id10016' 'id10004' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10004' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10018'\n",
      " 'id10001' 'id10016' 'id10003' 'id10016' 'id10001' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10019'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10009'\n",
      " 'id10016' 'id10020' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10004' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016'\n",
      " 'id10016' 'id10004' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10016' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10016' 'id10011' 'id10011' 'id10004' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10004'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10003' 'id10004' 'id10011' 'id10011' 'id10011' 'id10018'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10003' 'id10011' 'id10018' 'id10018' 'id10018' 'id10011'\n",
      " 'id10018' 'id10011' 'id10018' 'id10018' 'id10011' 'id10003' 'id10018'\n",
      " 'id10011' 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018' 'id10018'\n",
      " 'id10011' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10011' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10011' 'id10003' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10003' 'id10018'\n",
      " 'id10018' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10001' 'id10020' 'id10020' 'id10020' 'id10018' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10016' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10012' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10001' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10012' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10018' 'id10019' 'id10018' 'id10019'\n",
      " 'id10019' 'id10001' 'id10019' 'id10001' 'id10003' 'id10003' 'id10003'\n",
      " 'id10019' 'id10001' 'id10003' 'id10001' 'id10020' 'id10020' 'id10003'\n",
      " 'id10019' 'id10001' 'id10018' 'id10020' 'id10003' 'id10004' 'id10016'\n",
      " 'id10016' 'id10001' 'id10004' 'id10016' 'id10016' 'id10004' 'id10001'\n",
      " 'id10004' 'id10009' 'id10016' 'id10004' 'id10010' 'id10020' 'id10016'\n",
      " 'id10016' 'id10003' 'id10016' 'id10003' 'id10016' 'id10016' 'id10017'\n",
      " 'id10017' 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10017'\n",
      " 'id10003' 'id10016' 'id10003' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10016' 'id10017' 'id10017' 'id10003' 'id10017' 'id10016'\n",
      " 'id10017' 'id10017' 'id10016' 'id10017' 'id10017' 'id10017' 'id10018'\n",
      " 'id10011' 'id10016' 'id10017' 'id10017' 'id10017' 'id10016' 'id10003'\n",
      " 'id10016' 'id10017' 'id10017' 'id10016']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.23      0.22      0.22        23\n",
      "     id10002       1.00      0.87      0.93        39\n",
      "     id10003       0.56      0.65      0.60        51\n",
      "     id10004       0.28      0.97      0.43        32\n",
      "     id10005       1.00      0.06      0.11        18\n",
      "     id10006       0.82      0.82      0.82        38\n",
      "     id10007       0.95      0.75      0.84        24\n",
      "     id10008       0.82      0.97      0.89        32\n",
      "     id10009       0.50      0.11      0.18        18\n",
      "     id10010       1.00      0.06      0.12        16\n",
      "     id10011       0.67      0.81      0.73        36\n",
      "     id10012       0.95      0.78      0.85        45\n",
      "     id10013       0.00      0.00      0.00        15\n",
      "     id10014       0.36      0.28      0.31        29\n",
      "     id10015       1.00      0.28      0.43        18\n",
      "     id10016       0.59      0.86      0.70        76\n",
      "     id10017       0.96      0.48      0.64        46\n",
      "     id10018       0.76      0.80      0.78        81\n",
      "     id10019       0.86      0.26      0.40        23\n",
      "     id10020       0.97      0.97      0.97       177\n",
      "\n",
      "    accuracy                           0.71       837\n",
      "   macro avg       0.71      0.55      0.55       837\n",
      "weighted avg       0.77      0.71      0.69       837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),df_test['delta'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = '/Users/vpapadop/Documents/GitHub/speaker-similarity/vox_dev_wav/wav/id10001/1zcIwhmdeo4/00001.wav'\n",
    "# tmp = pd.DataFrame()\n",
    "# tmp[['mfcc', 'delta']] = extract_mfcc(clip,20)\n",
    "# X_tmp = np.hstack((tmp['mfcc'].to_list(),tmp['delta'].to_list()))\n",
    "# X_tmp = np.expand_dims(X_tmp, axis=0)\n",
    "# print(X_tmp.shape)\n",
    "\n",
    "# y_pred = model.predict(X_tmp)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
