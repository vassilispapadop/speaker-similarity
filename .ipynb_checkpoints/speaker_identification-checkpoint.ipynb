{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "from app.website.extract_features import extract_mfcc, zero_crossing_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n",
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 80% train and 20% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (70, 2), Test set size (30, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of mfccs per clip\n",
    "n_mfcc = splits = 13\n",
    "\n",
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Zero Crossing Rate\n",
    "df_train[['zcr']] = df_train['path'].apply(lambda p: zero_crossing_rate(p, splits))\n",
    "df_test[['zcr']] = df_test['path'].apply(lambda p: zero_crossing_rate(p, splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-234.83286, 133.73509, -31.300879, 38.71376, ...</td>\n",
       "      <td>[-0.22536033, -0.12889376, -0.028585024, 0.124...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-423.196, 151.2904, -20.332306, -2.9083853, -...</td>\n",
       "      <td>[0.0002549889, -0.008353452, -0.00092818623, 0...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-271.4974, 132.00212, -48.866318, 48.387047, ...</td>\n",
       "      <td>[-0.20052902, 0.018294884, 0.1554059, 0.065510...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-206.58463, 144.25214, -50.279385, 31.640982,...</td>\n",
       "      <td>[-0.05777987, 0.034374237, 0.038280718, 0.0138...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-250.60458, 139.20047, -46.59575, 34.955204, ...</td>\n",
       "      <td>[0.0495788, -0.03894916, 0.045858603, -0.10095...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-234.83286, 133.73509, -31.300879, 38.71376, ...   \n",
       "5   [-423.196, 151.2904, -20.332306, -2.9083853, -...   \n",
       "34  [-271.4974, 132.00212, -48.866318, 48.387047, ...   \n",
       "13  [-206.58463, 144.25214, -50.279385, 31.640982,...   \n",
       "45  [-250.60458, 139.20047, -46.59575, 34.955204, ...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.22536033, -0.12889376, -0.028585024, 0.124...   \n",
       "5   [0.0002549889, -0.008353452, -0.00092818623, 0...   \n",
       "34  [-0.20052902, 0.018294884, 0.1554059, 0.065510...   \n",
       "13  [-0.05777987, 0.034374237, 0.038280718, 0.0138...   \n",
       "45  [0.0495788, -0.03894916, 0.045858603, -0.10095...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>[-234.83286, 133.73509, -31.300879, 38.71376, ...</td>\n",
       "      <td>[-0.22536033, -0.12889376, -0.028585024, 0.124...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>[-423.196, 151.2904, -20.332306, -2.9083853, -...</td>\n",
       "      <td>[0.0002549889, -0.008353452, -0.00092818623, 0...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>[-271.4974, 132.00212, -48.866318, 48.387047, ...</td>\n",
       "      <td>[-0.20052902, 0.018294884, 0.1554059, 0.065510...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>[-206.58463, 144.25214, -50.279385, 31.640982,...</td>\n",
       "      <td>[-0.05777987, 0.034374237, 0.038280718, 0.0138...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>[-250.60458, 139.20047, -46.59575, 34.955204, ...</td>\n",
       "      <td>[0.0495788, -0.03894916, 0.045858603, -0.10095...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav   \n",
       "\n",
       "                                                 mfcc  \\\n",
       "0   [-234.83286, 133.73509, -31.300879, 38.71376, ...   \n",
       "5   [-423.196, 151.2904, -20.332306, -2.9083853, -...   \n",
       "34  [-271.4974, 132.00212, -48.866318, 48.387047, ...   \n",
       "13  [-206.58463, 144.25214, -50.279385, 31.640982,...   \n",
       "45  [-250.60458, 139.20047, -46.59575, 34.955204, ...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.22536033, -0.12889376, -0.028585024, 0.124...   \n",
       "5   [0.0002549889, -0.008353452, -0.00092818623, 0...   \n",
       "34  [-0.20052902, 0.018294884, 0.1554059, 0.065510...   \n",
       "13  [-0.05777987, 0.034374237, 0.038280718, 0.0138...   \n",
       "45  [0.0495788, -0.03894916, 0.045858603, -0.10095...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 2\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (49, 39), Validation set size (21, 39)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta and zero crossing rate columns\n",
    "X = df_train.iloc[:,2:5]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list(), X_train['zcr'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(), X_val['delta'].to_list(), X_val['zcr'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4000      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 44,502\n",
      "Trainable params: 44,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 68ms/step - loss: 27.7979 - accuracy: 0.5102 - val_loss: 14.1379 - val_accuracy: 0.1905\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.13792, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 37.2964 - accuracy: 0.3469 - val_loss: 1.5881 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00002: val_loss improved from 14.13792 to 1.58805, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 39.9156 - accuracy: 0.3061 - val_loss: 8.5205 - val_accuracy: 0.1905\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58805\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 22.7708 - accuracy: 0.4898 - val_loss: 17.7888 - val_accuracy: 0.1905\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58805\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 23.4240 - accuracy: 0.5714 - val_loss: 16.2368 - val_accuracy: 0.1905\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58805\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 17.8849 - accuracy: 0.5714 - val_loss: 2.7863 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58805\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 10.8308 - accuracy: 0.6327 - val_loss: 0.4272 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.58805 to 0.42716, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 22.5519 - accuracy: 0.4082 - val_loss: 0.7008 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42716\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 19.9027 - accuracy: 0.3878 - val_loss: 4.3669 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42716\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 16.7541 - accuracy: 0.4490 - val_loss: 6.8030 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42716\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 15.1257 - accuracy: 0.5714 - val_loss: 3.0908 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42716\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 8.4342 - accuracy: 0.5102 - val_loss: 0.9070 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42716\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 11.5575 - accuracy: 0.5714 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42716\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.7062 - accuracy: 0.5918 - val_loss: 1.0378 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.42716\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 5.9306 - accuracy: 0.6327 - val_loss: 0.6024 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42716\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 6.7237 - accuracy: 0.6531 - val_loss: 1.5090 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.42716\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 7.3900 - accuracy: 0.5918 - val_loss: 1.8897 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.42716\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.3601 - accuracy: 0.6531 - val_loss: 1.3810 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.42716\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 6.5411 - accuracy: 0.6939 - val_loss: 0.4421 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.42716\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 7.3868 - accuracy: 0.5918 - val_loss: 0.4098 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.42716 to 0.40985, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.6789 - accuracy: 0.6122 - val_loss: 0.4473 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.40985\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 7.2121 - accuracy: 0.5918 - val_loss: 0.7747 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.40985\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.5533 - accuracy: 0.6735 - val_loss: 1.0081 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.40985\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 7.3395 - accuracy: 0.5714 - val_loss: 0.8978 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.40985\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 6.2115 - accuracy: 0.5510 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.40985\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.8188 - accuracy: 0.5510 - val_loss: 0.5545 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.40985\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 7.0662 - accuracy: 0.4694 - val_loss: 0.4521 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.40985\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 5.6278 - accuracy: 0.5306 - val_loss: 0.6288 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.40985\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 5.8847 - accuracy: 0.4694 - val_loss: 1.5448 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.40985\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.6329 - accuracy: 0.6735 - val_loss: 1.8402 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.40985\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.9501 - accuracy: 0.6531 - val_loss: 1.7553 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.40985\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 4.7539 - accuracy: 0.6122 - val_loss: 1.8285 - val_accuracy: 0.2381\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.40985\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.3445 - accuracy: 0.6531 - val_loss: 1.4208 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.40985\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.7755 - accuracy: 0.5714 - val_loss: 0.9247 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.40985\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0122 - accuracy: 0.7755 - val_loss: 0.7079 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.40985\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 3.2253 - accuracy: 0.5714 - val_loss: 0.6998 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.40985\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.5954 - accuracy: 0.5102 - val_loss: 0.5769 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.40985\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 4.1470 - accuracy: 0.6531 - val_loss: 0.4750 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.40985\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.5445 - accuracy: 0.6939 - val_loss: 0.4237 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.40985\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.8732 - accuracy: 0.5918 - val_loss: 0.4300 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.40985\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 3.2863 - accuracy: 0.6327 - val_loss: 0.4602 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.40985\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 19ms/step - loss: 2.8747 - accuracy: 0.6531 - val_loss: 0.5879 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.40985\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8907 - accuracy: 0.6122 - val_loss: 0.7056 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.40985\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 5.5036 - accuracy: 0.5102 - val_loss: 0.6479 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40985\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.5067 - accuracy: 0.5306 - val_loss: 0.5827 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40985\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 1.6376 - accuracy: 0.6735 - val_loss: 0.5277 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40985\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.7032 - accuracy: 0.5510 - val_loss: 0.5606 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40985\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.3949 - accuracy: 0.5714 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.40985\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2843 - accuracy: 0.6939 - val_loss: 0.5599 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.40985\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.3914 - accuracy: 0.6531 - val_loss: 0.5222 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.40985\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2.3018 - accuracy: 0.5918 - val_loss: 0.5096 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.40985\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9060 - accuracy: 0.6327 - val_loss: 0.4903 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.40985\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.3679 - accuracy: 0.6735 - val_loss: 0.5120 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.40985\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3026 - accuracy: 0.6122 - val_loss: 0.5493 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.40985\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2.1952 - accuracy: 0.5918 - val_loss: 0.5594 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.40985\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.3010 - accuracy: 0.5714 - val_loss: 0.5376 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.40985\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.1720 - accuracy: 0.5306 - val_loss: 0.5048 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.40985\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0462 - accuracy: 0.5714 - val_loss: 0.5001 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.40985\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.0105 - accuracy: 0.6122 - val_loss: 0.5576 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.40985\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 2.0790 - accuracy: 0.5918 - val_loss: 0.5692 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.40985\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.0753 - accuracy: 0.6327 - val_loss: 0.5725 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.40985\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0804 - accuracy: 0.5306 - val_loss: 0.5834 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.40985\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3963 - accuracy: 0.6735 - val_loss: 0.5911 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.40985\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8147 - accuracy: 0.7347 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.40985\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2365 - accuracy: 0.7143 - val_loss: 0.6144 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.40985\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4872 - accuracy: 0.6735 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.40985\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3793 - accuracy: 0.6735 - val_loss: 0.6164 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.40985\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2868 - accuracy: 0.5510 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.40985\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1566 - accuracy: 0.5918 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.40985\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6056 - accuracy: 0.6327 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.40985\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1293 - accuracy: 0.6939 - val_loss: 0.5641 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.40985\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3044 - accuracy: 0.5918 - val_loss: 0.5467 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.40985\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8135 - accuracy: 0.7143 - val_loss: 0.5508 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.40985\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.5872 - accuracy: 0.5510 - val_loss: 0.5707 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.40985\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8105 - accuracy: 0.6122 - val_loss: 0.6122 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.40985\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9098 - accuracy: 0.7347 - val_loss: 0.6294 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.40985\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8616 - accuracy: 0.5918 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.40985\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3471 - accuracy: 0.5918 - val_loss: 0.6229 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.40985\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8777 - accuracy: 0.6735 - val_loss: 0.6194 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.40985\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1914 - accuracy: 0.6531 - val_loss: 0.6337 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.40985\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2378 - accuracy: 0.6735 - val_loss: 0.6365 - val_accuracy: 0.7619\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.40985\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2979 - accuracy: 0.6531 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.40985\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6554 - accuracy: 0.6327 - val_loss: 0.6096 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.40985\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1034 - accuracy: 0.5918 - val_loss: 0.5760 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_loss did not improve from 0.40985\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2014 - accuracy: 0.6327 - val_loss: 0.5769 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.40985\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9045 - accuracy: 0.6327 - val_loss: 0.6116 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.40985\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.2195 - accuracy: 0.5918 - val_loss: 0.6255 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.40985\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6007 - accuracy: 0.6122 - val_loss: 0.6454 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.40985\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1317 - accuracy: 0.6122 - val_loss: 0.6481 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.40985\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5656 - accuracy: 0.5510 - val_loss: 0.6475 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.40985\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1926 - accuracy: 0.6531 - val_loss: 0.6690 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.40985\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1404 - accuracy: 0.6327 - val_loss: 0.6881 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.40985\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7884 - accuracy: 0.7551 - val_loss: 0.6889 - val_accuracy: 0.3810\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.40985\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.0487 - accuracy: 0.6939 - val_loss: 0.6755 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.40985\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7439 - accuracy: 0.7347 - val_loss: 0.6665 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.40985\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9812 - accuracy: 0.6939 - val_loss: 0.6606 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.40985\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8050 - accuracy: 0.6735 - val_loss: 0.6543 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.40985\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8542 - accuracy: 0.7347 - val_loss: 0.6524 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.40985\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2770 - accuracy: 0.5714 - val_loss: 0.6532 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.40985\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9746 - accuracy: 0.6939 - val_loss: 0.6577 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.40985\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.8779 - accuracy: 0.6122 - val_loss: 0.6610 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.40985\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6468 - accuracy: 0.6939 - val_loss: 0.6523 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.40985\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0315 - accuracy: 0.6327 - val_loss: 0.6363 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.40985\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9188 - accuracy: 0.6531 - val_loss: 0.6124 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.40985\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.8752 - accuracy: 0.7143 - val_loss: 0.6106 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.40985\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8299 - accuracy: 0.6531 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.40985\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6328 - accuracy: 0.6939 - val_loss: 0.6220 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.40985\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.7347 - val_loss: 0.6255 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.40985\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6643 - accuracy: 0.7959 - val_loss: 0.6341 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.40985\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.7551 - val_loss: 0.6351 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.40985\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.7143 - val_loss: 0.6339 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.40985\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.6738 - accuracy: 0.7959 - val_loss: 0.6288 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.40985\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6107 - accuracy: 0.7143 - val_loss: 0.6230 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.40985\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7806 - accuracy: 0.6531 - val_loss: 0.6233 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.40985\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0650 - accuracy: 0.6735 - val_loss: 0.6282 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.40985\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8957 - accuracy: 0.7959 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.40985\n",
      "Epoch 117/200\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2313 - accuracy: 0.8750"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 8\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),\n",
    "                    df_test['delta'].to_list(),\n",
    "                    df_test['zcr'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip = '/Users/vpapadop/Documents/GitHub/speaker-similarity/vox_dev_wav/wav/id10001/1zcIwhmdeo4/00001.wav'\n",
    "# tmp = pd.DataFrame()\n",
    "# tmp[['mfcc', 'delta']] = extract_mfcc(clip,20)\n",
    "# X_tmp = np.hstack((tmp['mfcc'].to_list(),tmp['delta'].to_list()))\n",
    "# X_tmp = np.expand_dims(X_tmp, axis=0)\n",
    "# print(X_tmp.shape)\n",
    "\n",
    "# y_pred = model.predict(X_tmp)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
