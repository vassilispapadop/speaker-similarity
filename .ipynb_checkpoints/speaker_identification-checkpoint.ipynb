{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "from app.website.extract_features import extract_mfcc, zero_crossing_rate, get_audio_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n",
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2787, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "# df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 70% train and 30% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1950, 2), Test set size (837, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration  \n",
       "0   4.640062  \n",
       "5   5.720063  \n",
       "34  5.640062  \n",
       "13  5.680063  \n",
       "45  6.200062  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample rate and clip duration for every clip\n",
    "df_train[['sr','duration']] = df_train['path'].apply(lambda p: get_audio_info(p))\n",
    "df_test[['sr','duration']] = df_test['path'].apply(lambda p: get_audio_info(p))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sr     duration\n",
      "count   1950.0  1950.000000\n",
      "mean   16000.0     7.688083\n",
      "std        0.0     4.507359\n",
      "min    16000.0     3.960062\n",
      "25%    16000.0     4.840063\n",
      "50%    16000.0     6.240062\n",
      "75%    16000.0     8.960062\n",
      "max    16000.0    61.680062 \n",
      "             sr    duration\n",
      "count    837.0  837.000000\n",
      "mean   16000.0    7.755045\n",
      "std        0.0    4.491689\n",
      "min    16000.0    3.960062\n",
      "25%    16000.0    4.880063\n",
      "50%    16000.0    6.360062\n",
      "75%    16000.0    8.920063\n",
      "max    16000.0   37.280062\n"
     ]
    }
   ],
   "source": [
    "print(f'{df_train.describe()} \\n {df_test.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of mfccs per clip\n",
    "n_mfcc = splits = 13\n",
    "\n",
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Zero Crossing Rate\n",
    "df_train[['zcr']] = df_train['path'].apply(lambda p: zero_crossing_rate(p, splits))\n",
    "df_test[['zcr']] = df_test['path'].apply(lambda p: zero_crossing_rate(p, splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df_test.iloc[26,5]\n",
    "# plt.plot(a)\n",
    "# plt.show()\n",
    "# print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 20\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (1365, 39), Validation set size (585, 39)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta and zero crossing rate columns\n",
    "X = df_train.iloc[:,4:7]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list(), X_train['zcr'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(), X_val['delta'].to_list(), X_val['zcr'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 100)               4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 46,320\n",
      "Trainable params: 46,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "43/43 [==============================] - 1s 11ms/step - loss: 18.7316 - accuracy: 0.1018 - val_loss: 3.1264 - val_accuracy: 0.1402\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.12639, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 4.8634 - accuracy: 0.0938 - val_loss: 2.9836 - val_accuracy: 0.0598\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.12639 to 2.98364, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 3.3927 - accuracy: 0.1238 - val_loss: 2.9696 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.98364 to 2.96958, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 3.0856 - accuracy: 0.1729 - val_loss: 2.9544 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.96958 to 2.95441, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 3.0299 - accuracy: 0.1875 - val_loss: 2.9406 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.95441 to 2.94055, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 3.0190 - accuracy: 0.1949 - val_loss: 2.9274 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.94055 to 2.92736, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.9882 - accuracy: 0.1934 - val_loss: 2.9148 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.92736 to 2.91484, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 8/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.9155 - accuracy: 0.2000 - val_loss: 2.9033 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.91484 to 2.90329, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.9233 - accuracy: 0.2007 - val_loss: 2.8924 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.90329 to 2.89237, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.8849 - accuracy: 0.2051 - val_loss: 2.8822 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.89237 to 2.88219, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.9204 - accuracy: 0.2051 - val_loss: 2.8724 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.88219 to 2.87245, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.8750 - accuracy: 0.2051 - val_loss: 2.8632 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.87245 to 2.86321, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.8617 - accuracy: 0.2051 - val_loss: 2.8545 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.86321 to 2.85454, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.8330 - accuracy: 0.2059 - val_loss: 2.8298 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.85454 to 2.82977, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.8421 - accuracy: 0.2066 - val_loss: 2.7921 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.82977 to 2.79207, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.8009 - accuracy: 0.2088 - val_loss: 2.7261 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.79207 to 2.72610, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 2.7574 - accuracy: 0.2066 - val_loss: 2.6740 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.72610 to 2.67403, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 2.7041 - accuracy: 0.2095 - val_loss: 2.4567 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.67403 to 2.45673, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.6547 - accuracy: 0.2081 - val_loss: 2.3968 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.45673 to 2.39679, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.6047 - accuracy: 0.2095 - val_loss: 2.3907 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.39679 to 2.39071, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5632 - accuracy: 0.2110 - val_loss: 2.3830 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.39071 to 2.38304, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5729 - accuracy: 0.2088 - val_loss: 2.3766 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.38304 to 2.37658, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5571 - accuracy: 0.2073 - val_loss: 2.3629 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.37658 to 2.36293, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5107 - accuracy: 0.2095 - val_loss: 2.3350 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.36293 to 2.33499, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5064 - accuracy: 0.2117 - val_loss: 2.3501 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.33499\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4982 - accuracy: 0.2308 - val_loss: 2.3318 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.33499 to 2.33179, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4636 - accuracy: 0.2777 - val_loss: 2.3202 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.33179 to 2.32020, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4607 - accuracy: 0.2791 - val_loss: 2.3170 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.32020 to 2.31702, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4577 - accuracy: 0.2769 - val_loss: 2.3261 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.31702\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4484 - accuracy: 0.2799 - val_loss: 2.3136 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.31702 to 2.31357, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4338 - accuracy: 0.2864 - val_loss: 2.3216 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.31357\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4139 - accuracy: 0.2850 - val_loss: 2.3290 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.31357\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4220 - accuracy: 0.2806 - val_loss: 2.3063 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.31357 to 2.30627, saving model to saved_models/speakers_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/250\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 2.4175 - accuracy: 0.2791 - val_loss: 2.3043 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.30627 to 2.30430, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.4067 - accuracy: 0.2842 - val_loss: 2.3022 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.30430 to 2.30217, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 36/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.3959 - accuracy: 0.2828 - val_loss: 2.2930 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.30217 to 2.29299, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 37/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.3929 - accuracy: 0.2916 - val_loss: 2.2966 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.29299\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.3858 - accuracy: 0.2886 - val_loss: 2.2960 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.29299\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.3709 - accuracy: 0.2960 - val_loss: 2.2961 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.29299\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3636 - accuracy: 0.2901 - val_loss: 2.2893 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.29299 to 2.28927, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 2.3797 - accuracy: 0.2894 - val_loss: 2.2903 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.28927\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 2.3533 - accuracy: 0.2996 - val_loss: 2.2756 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.28927 to 2.27563, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.3556 - accuracy: 0.29 - 0s 8ms/step - loss: 2.3365 - accuracy: 0.2989 - val_loss: 2.2979 - val_accuracy: 0.3009\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.27563\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3503 - accuracy: 0.3004 - val_loss: 2.2785 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.27563\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.3434 - accuracy: 0.2916 - val_loss: 2.2689 - val_accuracy: 0.3009\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.27563 to 2.26891, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.3061 - accuracy: 0.2989 - val_loss: 2.2749 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.26891\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 2.3119 - accuracy: 0.3004 - val_loss: 2.2586 - val_accuracy: 0.3111\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.26891 to 2.25858, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3093 - accuracy: 0.3033 - val_loss: 2.2541 - val_accuracy: 0.3179\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.25858 to 2.25413, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3104 - accuracy: 0.3128 - val_loss: 2.2124 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.25413 to 2.21240, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 2.2656 - accuracy: 0.3121 - val_loss: 2.2000 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.21240 to 2.19996, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 2.2796 - accuracy: 0.3121 - val_loss: 2.1987 - val_accuracy: 0.3197\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.19996 to 2.19866, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.2540 - accuracy: 0.3179 - val_loss: 2.1820 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00052: val_loss improved from 2.19866 to 2.18201, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.2341 - accuracy: 0.3143 - val_loss: 2.1368 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.18201 to 2.13681, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 2.1914 - accuracy: 0.3128 - val_loss: 2.1320 - val_accuracy: 0.3368\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.13681 to 2.13204, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1811 - accuracy: 0.3297 - val_loss: 2.1214 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00055: val_loss improved from 2.13204 to 2.12144, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.2067 - accuracy: 0.3209 - val_loss: 2.0738 - val_accuracy: 0.3573\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.12144 to 2.07383, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.1579 - accuracy: 0.3429 - val_loss: 2.0524 - val_accuracy: 0.3641\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.07383 to 2.05244, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.1528 - accuracy: 0.3260 - val_loss: 2.0423 - val_accuracy: 0.3658\n",
      "\n",
      "Epoch 00058: val_loss improved from 2.05244 to 2.04226, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1095 - accuracy: 0.3568 - val_loss: 2.0357 - val_accuracy: 0.3795\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.04226 to 2.03572, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.0844 - accuracy: 0.3604 - val_loss: 2.0385 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.03572\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.1078 - accuracy: 0.3487 - val_loss: 1.9626 - val_accuracy: 0.3949\n",
      "\n",
      "Epoch 00061: val_loss improved from 2.03572 to 1.96259, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.0076 - accuracy: 0.3890 - val_loss: 1.8618 - val_accuracy: 0.4513\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.96259 to 1.86178, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.9429 - accuracy: 0.3963 - val_loss: 1.8180 - val_accuracy: 0.4256\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.86178 to 1.81795, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9072 - accuracy: 0.4007 - val_loss: 1.7319 - val_accuracy: 0.4496\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.81795 to 1.73186, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.8629 - accuracy: 0.4205 - val_loss: 1.6312 - val_accuracy: 0.4855\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.73186 to 1.63123, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.8414 - accuracy: 0.4154 - val_loss: 1.6806 - val_accuracy: 0.4684\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.63123\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7918 - accuracy: 0.4498 - val_loss: 1.5812 - val_accuracy: 0.5060\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.63123 to 1.58118, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 68/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7413 - accuracy: 0.4520 - val_loss: 1.5348 - val_accuracy: 0.5197\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.58118 to 1.53479, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 69/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7380 - accuracy: 0.4410 - val_loss: 1.5030 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.53479 to 1.50296, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - 1s 11ms/step - loss: 1.6996 - accuracy: 0.4593 - val_loss: 1.4556 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.50296 to 1.45564, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.6280 - accuracy: 0.4901 - val_loss: 1.4398 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.45564 to 1.43979, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 1.6361 - accuracy: 0.4901 - val_loss: 1.4144 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.43979 to 1.41435, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.5955 - accuracy: 0.4974 - val_loss: 1.3804 - val_accuracy: 0.5709\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.41435 to 1.38040, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5391 - accuracy: 0.5187 - val_loss: 1.3547 - val_accuracy: 0.5692\n",
      "\n",
      "Epoch 00074: val_loss improved from 1.38040 to 1.35472, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4761 - accuracy: 0.5370 - val_loss: 1.3410 - val_accuracy: 0.5607\n",
      "\n",
      "Epoch 00075: val_loss improved from 1.35472 to 1.34098, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4878 - accuracy: 0.5377 - val_loss: 1.2813 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.34098 to 1.28132, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4516 - accuracy: 0.5575 - val_loss: 1.2457 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.28132 to 1.24574, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - 1s 19ms/step - loss: 1.4709 - accuracy: 0.5297 - val_loss: 1.2402 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.24574 to 1.24022, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - 1s 7ms/step - loss: 1.4201 - accuracy: 0.5443 - val_loss: 1.2023 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.24022 to 1.20232, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.5795 - val_loss: 1.1461 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.20232 to 1.14608, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.3920 - accuracy: 0.5663 - val_loss: 1.2057 - val_accuracy: 0.6462\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.14608\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2993 - accuracy: 0.5839 - val_loss: 1.1153 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.14608 to 1.11531, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3165 - accuracy: 0.5853 - val_loss: 1.1081 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.11531 to 1.10813, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3128 - accuracy: 0.5883 - val_loss: 1.0950 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.10813 to 1.09501, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2666 - accuracy: 0.5993 - val_loss: 1.0715 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.09501 to 1.07150, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.2629 - accuracy: 0.5949 - val_loss: 1.1001 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.07150\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2240 - accuracy: 0.6029 - val_loss: 1.0772 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.07150\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2029 - accuracy: 0.6212 - val_loss: 1.0574 - val_accuracy: 0.6513\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.07150 to 1.05740, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2548 - accuracy: 0.6176 - val_loss: 1.0171 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.05740 to 1.01715, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1818 - accuracy: 0.6403 - val_loss: 1.0582 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.01715\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.1943 - accuracy: 0.6205 - val_loss: 1.0092 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.01715 to 1.00916, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1267 - accuracy: 0.6418 - val_loss: 1.0383 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.00916\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0879 - accuracy: 0.6432 - val_loss: 0.9864 - val_accuracy: 0.6821\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.00916 to 0.98635, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1357 - accuracy: 0.6381 - val_loss: 0.9783 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.98635 to 0.97830, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.1309 - accuracy: 0.6491 - val_loss: 0.9677 - val_accuracy: 0.6940\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.97830 to 0.96772, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 96/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.6586 - val_loss: 0.9739 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.96772\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.6586 - val_loss: 0.9364 - val_accuracy: 0.6974\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.96772 to 0.93636, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1051 - accuracy: 0.6593 - val_loss: 0.9888 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.93636\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0414 - accuracy: 0.6564 - val_loss: 0.9442 - val_accuracy: 0.7043\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.93636\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.6542 - val_loss: 0.9267 - val_accuracy: 0.7128\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.93636 to 0.92670, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0478 - accuracy: 0.6491 - val_loss: 0.9064 - val_accuracy: 0.7026\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.92670 to 0.90638, saving model to saved_models/speakers_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9645 - accuracy: 0.6857 - val_loss: 0.8724 - val_accuracy: 0.7197\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.90638 to 0.87236, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.0101 - accuracy: 0.6791 - val_loss: 0.9078 - val_accuracy: 0.7077\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.87236\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 1.0273 - accuracy: 0.6689 - val_loss: 0.9133 - val_accuracy: 0.7145\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.87236\n",
      "Epoch 105/250\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.9752 - accuracy: 0.6872 - val_loss: 0.8613 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.87236 to 0.86129, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9655 - accuracy: 0.6952 - val_loss: 0.8619 - val_accuracy: 0.7179\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.86129\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.9172 - accuracy: 0.7033 - val_loss: 0.8695 - val_accuracy: 0.7214\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.86129\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9789 - accuracy: 0.6930 - val_loss: 0.8807 - val_accuracy: 0.7299\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.86129\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9264 - accuracy: 0.7011 - val_loss: 0.8467 - val_accuracy: 0.7197\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.86129 to 0.84670, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9459 - accuracy: 0.6952 - val_loss: 0.8486 - val_accuracy: 0.7231\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.84670\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8968 - accuracy: 0.7026 - val_loss: 0.8104 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.84670 to 0.81041, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.9170 - accuracy: 0.7048 - val_loss: 0.8262 - val_accuracy: 0.7402\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.81041\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.9147 - accuracy: 0.7114 - val_loss: 0.8255 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.81041\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.8960 - accuracy: 0.6989 - val_loss: 0.8357 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.81041\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.8889 - accuracy: 0.7216 - val_loss: 0.8109 - val_accuracy: 0.7350\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.81041\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.8622 - accuracy: 0.7289 - val_loss: 0.8134 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.81041\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.8611 - accuracy: 0.7355 - val_loss: 0.7918 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.81041 to 0.79176, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.8408 - accuracy: 0.7238 - val_loss: 0.7986 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.79176\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.8386 - accuracy: 0.7209 - val_loss: 0.7618 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.79176 to 0.76183, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.8499 - accuracy: 0.7158 - val_loss: 0.7765 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.76183\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.8278 - accuracy: 0.7297 - val_loss: 0.7583 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.76183 to 0.75831, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7858 - accuracy: 0.7348 - val_loss: 0.7599 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.75831\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.7909 - accuracy: 0.7385 - val_loss: 0.7239 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.75831 to 0.72390, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8216 - accuracy: 0.7282 - val_loss: 0.7633 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.72390\n",
      "Epoch 125/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.8139 - accuracy: 0.7231 - val_loss: 0.7384 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.72390\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.8274 - accuracy: 0.7297 - val_loss: 0.7867 - val_accuracy: 0.7573\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.72390\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.7546 - val_loss: 0.7371 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.72390\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7499 - accuracy: 0.7465 - val_loss: 0.7675 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.72390\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7691 - accuracy: 0.7502 - val_loss: 0.7546 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.72390\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7546 - val_loss: 0.7535 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.72390\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8101 - accuracy: 0.7385 - val_loss: 0.7589 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.72390\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.7370 - val_loss: 0.7475 - val_accuracy: 0.7573\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.72390\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7447 - accuracy: 0.7480 - val_loss: 0.7391 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.72390\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7236 - accuracy: 0.7678 - val_loss: 0.7272 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.72390\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.7575 - val_loss: 0.7242 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.72390\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7155 - accuracy: 0.7648 - val_loss: 0.7168 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.72390 to 0.71683, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7766 - val_loss: 0.7387 - val_accuracy: 0.7658\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.71683\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.7758 - val_loss: 0.7062 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.71683 to 0.70622, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.7853 - val_loss: 0.7449 - val_accuracy: 0.7573\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.70622\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7670 - val_loss: 0.6895 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.70622 to 0.68949, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 141/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.7795 - val_loss: 0.7413 - val_accuracy: 0.7556\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.68949\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.7758 - val_loss: 0.7060 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.68949\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6600 - accuracy: 0.7810 - val_loss: 0.6986 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.68949\n",
      "Epoch 144/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.7560 - val_loss: 0.7354 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.68949\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.7846 - val_loss: 0.7380 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.68949\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7751 - val_loss: 0.7049 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.68949\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7861 - val_loss: 0.7098 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.68949\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.7773 - val_loss: 0.6996 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.68949\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.7766 - val_loss: 0.6984 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.68949\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.8007 - val_loss: 0.6784 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.68949 to 0.67843, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7839 - val_loss: 0.6853 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.67843\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.7788 - val_loss: 0.6838 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.67843\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.7626 - val_loss: 0.6806 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.67843\n",
      "Epoch 154/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7883 - val_loss: 0.6888 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.67843\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7934 - val_loss: 0.7172 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.67843\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7985 - val_loss: 0.6907 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.67843\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.8000 - val_loss: 0.6589 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.67843 to 0.65892, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.7949 - val_loss: 0.6462 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.65892 to 0.64622, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.8088 - val_loss: 0.6490 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.64622\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7927 - val_loss: 0.6590 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.64622\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7949 - val_loss: 0.6518 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.64622\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.8168 - val_loss: 0.6663 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.64622\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7919 - val_loss: 0.7012 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.64622\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7978 - val_loss: 0.6410 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.64622 to 0.64103, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.8081 - val_loss: 0.6745 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.64103\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.7890 - val_loss: 0.6592 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.64103\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8110 - val_loss: 0.6399 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.64103 to 0.63989, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7949 - val_loss: 0.6509 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.63989\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.8125 - val_loss: 0.6565 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.63989\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8271 - val_loss: 0.6524 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.63989\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.8168 - val_loss: 0.6509 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.63989\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.8132 - val_loss: 0.6879 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.63989\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.8161 - val_loss: 0.6779 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.63989\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7985 - val_loss: 0.6508 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.63989\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.8132 - val_loss: 0.6342 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.63989 to 0.63424, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.8139 - val_loss: 0.6693 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.63424\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.7971 - val_loss: 0.6998 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.63424\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.8190 - val_loss: 0.6986 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.63424\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.8183 - val_loss: 0.6618 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.63424\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.8066 - val_loss: 0.6561 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.63424\n",
      "Epoch 181/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.8117 - val_loss: 0.6345 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.63424\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8337 - val_loss: 0.6228 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.63424 to 0.62278, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 183/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8271 - val_loss: 0.6571 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.62278\n",
      "Epoch 184/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8212 - val_loss: 0.6751 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.62278\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8315 - val_loss: 0.6599 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.62278\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.8103 - val_loss: 0.6245 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.62278\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.8198 - val_loss: 0.6337 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.62278\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8183 - val_loss: 0.6522 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.62278\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.8264 - val_loss: 0.6544 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.62278\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8161 - val_loss: 0.6783 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.62278\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.8176 - val_loss: 0.6584 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.62278\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8315 - val_loss: 0.6318 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.62278\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.8374 - val_loss: 0.6573 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.62278\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.8396 - val_loss: 0.6748 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.62278\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.8227 - val_loss: 0.6737 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.62278\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.8366 - val_loss: 0.6466 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.62278\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8403 - val_loss: 0.6652 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.62278\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.8513 - val_loss: 0.6769 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.62278\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.8381 - val_loss: 0.6245 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.62278\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.8322 - val_loss: 0.6210 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.62278 to 0.62100, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.8337 - val_loss: 0.6587 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.62100\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8286 - val_loss: 0.6547 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.62100\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8425 - val_loss: 0.6158 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.62100 to 0.61580, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.8315 - val_loss: 0.6088 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.61580 to 0.60878, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8403 - val_loss: 0.6141 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.60878\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8352 - val_loss: 0.6373 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.60878\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.8396 - val_loss: 0.6600 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.60878\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8308 - val_loss: 0.6056 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.60878 to 0.60563, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.8352 - val_loss: 0.6668 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.60563\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.8315 - val_loss: 0.6472 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.60563\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8374 - val_loss: 0.6646 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.60563\n",
      "Epoch 212/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8374 - val_loss: 0.6892 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.60563\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8484 - val_loss: 0.6371 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.60563\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8498 - val_loss: 0.6338 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.60563\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8645 - val_loss: 0.5776 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.60563 to 0.57756, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8454 - val_loss: 0.6364 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.57756\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.8491 - val_loss: 0.5938 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.57756\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8527 - val_loss: 0.6195 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.57756\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.8432 - val_loss: 0.5728 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.57756 to 0.57277, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8535 - val_loss: 0.6103 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.57277\n",
      "Epoch 221/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8388 - val_loss: 0.6088 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.57277\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8535 - val_loss: 0.6053 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.57277\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8418 - val_loss: 0.5954 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.57277\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8615 - val_loss: 0.6305 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.57277\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8447 - val_loss: 0.6037 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.57277\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8359 - val_loss: 0.6390 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.57277\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8491 - val_loss: 0.6441 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.57277\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8586 - val_loss: 0.6230 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.57277\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8593 - val_loss: 0.5994 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.57277\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8601 - val_loss: 0.5970 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.57277\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8454 - val_loss: 0.6095 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.57277\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8579 - val_loss: 0.6561 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.57277\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8615 - val_loss: 0.6614 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.57277\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8454 - val_loss: 0.6053 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.57277\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.5100 - accuracy: 0.8344 - val_loss: 0.6571 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.57277\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.8388 - val_loss: 0.6261 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.57277\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8425 - val_loss: 0.6387 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.57277\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4459 - accuracy: 0.8484 - val_loss: 0.6463 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.57277\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.8432 - val_loss: 0.6372 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.57277\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8527 - val_loss: 0.6328 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.57277\n",
      "Epoch 241/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8322 - val_loss: 0.6298 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.57277\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8579 - val_loss: 0.6690 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.57277\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8454 - val_loss: 0.6341 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.57277\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8527 - val_loss: 0.6167 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.57277\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8484 - val_loss: 0.6430 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.57277\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8462 - val_loss: 0.5939 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.57277\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.8645 - val_loss: 0.6201 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.57277\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.8366 - val_loss: 0.6327 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.57277\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8696 - val_loss: 0.6230 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.57277\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.8484 - val_loss: 0.6219 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.57277\n",
      "Training completed in time:  0:01:22.696359\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 250\n",
    "num_batch_size = 32\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 39)\n",
      "['id10006' 'id10009' 'id10009' 'id10004' 'id10009' 'id10009' 'id10009'\n",
      " 'id10016' 'id10009' 'id10016' 'id10004' 'id10009' 'id10009' 'id10009'\n",
      " 'id10009' 'id10009' 'id10009' 'id10009' 'id10007' 'id10007' 'id10004'\n",
      " 'id10007' 'id10007' 'id10001' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10014' 'id10007'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10014' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10006' 'id10001' 'id10017' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10001' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10012' 'id10018' 'id10017' 'id10012' 'id10016'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10018' 'id10002'\n",
      " 'id10012' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10016' 'id10018' 'id10012' 'id10018' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10018' 'id10002' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10018' 'id10012' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10004' 'id10015' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015'\n",
      " 'id10016' 'id10015' 'id10014' 'id10014' 'id10014' 'id10006' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10004' 'id10014' 'id10014' 'id10014'\n",
      " 'id10006' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10006' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10013' 'id10013' 'id10013' 'id10013'\n",
      " 'id10006' 'id10006' 'id10013' 'id10013' 'id10013' 'id10013' 'id10004'\n",
      " 'id10019' 'id10004' 'id10013' 'id10013' 'id10004' 'id10014' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10019' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10017' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10009'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10012' 'id10002'\n",
      " 'id10005' 'id10005' 'id10005' 'id10005' 'id10005' 'id10012' 'id10005'\n",
      " 'id10017' 'id10005' 'id10003' 'id10005' 'id10005' 'id10005' 'id10017'\n",
      " 'id10005' 'id10005' 'id10005' 'id10005' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10016' 'id10016' 'id10017'\n",
      " 'id10016' 'id10020' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10017' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10016' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10003' 'id10011' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10017' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10009'\n",
      " 'id10018' 'id10018' 'id10018' 'id10003' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10004' 'id10018' 'id10018' 'id10009' 'id10003'\n",
      " 'id10012' 'id10016' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10020' 'id10019' 'id10019' 'id10001' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019' 'id10019'\n",
      " 'id10020' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10012' 'id10020' 'id10020' 'id10019'\n",
      " 'id10019' 'id10001' 'id10019' 'id10019' 'id10020' 'id10019' 'id10019'\n",
      " 'id10020' 'id10019' 'id10001' 'id10019' 'id10020' 'id10019' 'id10020'\n",
      " 'id10001' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020'\n",
      " 'id10019' 'id10001' 'id10019' 'id10020' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10020' 'id10019' 'id10019' 'id10019' 'id10001' 'id10020'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10001' 'id10019'\n",
      " 'id10019' 'id10001' 'id10019' 'id10019' 'id10020' 'id10019' 'id10019'\n",
      " 'id10020' 'id10020' 'id10020' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10019' 'id10020' 'id10001' 'id10019' 'id10001' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10001' 'id10001' 'id10001'\n",
      " 'id10019' 'id10020' 'id10019' 'id10019' 'id10019' 'id10001' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10001' 'id10020' 'id10020' 'id10019' 'id10020' 'id10020' 'id10019'\n",
      " 'id10019' 'id10001' 'id10019' 'id10020' 'id10019' 'id10001' 'id10001'\n",
      " 'id10019' 'id10019' 'id10001' 'id10019' 'id10020' 'id10019' 'id10020'\n",
      " 'id10019' 'id10019' 'id10020' 'id10019' 'id10020' 'id10019' 'id10019'\n",
      " 'id10020' 'id10012' 'id10001' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10020' 'id10019' 'id10020' 'id10001' 'id10019' 'id10001' 'id10019'\n",
      " 'id10019' 'id10019' 'id10020' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10018' 'id10010'\n",
      " 'id10003' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010'\n",
      " 'id10010' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10003' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10016'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10003' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.47      0.91      0.62        23\n",
      "     id10002       0.95      0.97      0.96        39\n",
      "     id10003       0.84      0.96      0.90        51\n",
      "     id10004       0.79      0.94      0.86        32\n",
      "     id10005       1.00      0.78      0.88        18\n",
      "     id10006       0.84      0.97      0.90        38\n",
      "     id10007       1.00      0.88      0.93        24\n",
      "     id10008       1.00      0.97      0.98        32\n",
      "     id10009       0.81      0.72      0.76        18\n",
      "     id10010       1.00      0.88      0.93        16\n",
      "     id10011       0.95      0.97      0.96        36\n",
      "     id10012       0.87      0.73      0.80        45\n",
      "     id10013       1.00      0.67      0.80        15\n",
      "     id10014       0.89      0.86      0.88        29\n",
      "     id10015       1.00      0.89      0.94        18\n",
      "     id10016       0.89      0.89      0.89        76\n",
      "     id10017       0.80      0.93      0.86        46\n",
      "     id10018       0.90      0.86      0.88        81\n",
      "     id10019       0.16      0.96      0.27        23\n",
      "     id10020       0.95      0.21      0.34       177\n",
      "\n",
      "    accuracy                           0.75       837\n",
      "   macro avg       0.86      0.85      0.82       837\n",
      "weighted avg       0.88      0.75      0.75       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),\n",
    "                    df_test['delta'].to_list(),\n",
    "                    df_test['zcr'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "# for every speaker fit a GMM and save the model\n",
    "unique_speakers = df_train['speaker'].unique()\n",
    "for speaker in unique_speakers:\n",
    "    df_speaker = df_train[df_train['speaker'] == speaker]\n",
    "    features = np.asarray(())\n",
    "    for index, row in df_speaker.iterrows():\n",
    "        vector = np.hstack((row['mfcc'], row['delta'], row['zcr']))\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features,vector))\n",
    "    \n",
    "    gmm = mixture.GaussianMixture(n_components = 16, covariance_type='diag',n_init = 3)\n",
    "    gmm.fit(features)\n",
    "    gmm_models.append(gmm)\n",
    "    \n",
    "    filename = 'saved_models/gmm/' + f'gmm_{speaker}.sav'\n",
    "    pickle.dump(gmm, open(filename, 'wb'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmm_id10020.sav', 'gmm_id10008.sav', 'gmm_id10009.sav', 'gmm_id10019.sav', 'gmm_id10018.sav', 'gmm_id10016.sav', 'gmm_id10002.sav', 'gmm_id10003.sav', 'gmm_id10017.sav', 'gmm_id10001.sav', 'gmm_id10015.sav', 'gmm_id10014.sav', 'gmm_id10004.sav', 'gmm_id10010.sav', 'gmm_id10011.sav', 'gmm_id10005.sav', 'gmm_id10013.sav', 'gmm_id10007.sav', 'gmm_id10006.sav', 'gmm_id10012.sav']\n",
      "The Accuracy with (MFCC + DELTA + ZCR) and GMM is : 99.4026284348865\n"
     ]
    }
   ],
   "source": [
    "# load models and predict on test\n",
    "gmm_files = [os.path.join('saved_models/gmm/',fname) for fname in \n",
    "              os.listdir('saved_models/gmm/') if fname.endswith('.sav')]\n",
    "\n",
    "#Load the Gaussian gender Models\n",
    "gmm_models = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "unique_speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "              in gmm_files]\n",
    "\n",
    "print(unique_speakers)\n",
    "nr_errors = 0\n",
    "total_samples = len(df_test)\n",
    "for index, row in df_test.iterrows():\n",
    "    log_likelihood = np.zeros(len(gmm_models)) \n",
    "    features = np.hstack((row['mfcc'], row['delta'], row['zcr']))\n",
    "    features = features.reshape(1,-1)\n",
    "    \n",
    "    for i, gmm in enumerate(gmm_models):\n",
    "        scores = np.array(gmm.score(features))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    y_pred = np.argmax(log_likelihood)\n",
    "    if unique_speakers[y_pred] != 'gmm_' + row['speaker']+ '.sav':\n",
    "        nr_errors += 1\n",
    "\n",
    "accuracy = ((total_samples - nr_errors) / total_samples) * 100\n",
    "print (f'The Accuracy with (MFCC + DELTA + ZCR) and GMM is : {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
