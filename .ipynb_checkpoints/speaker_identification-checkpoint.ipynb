{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "from app.website.extract_features import extract_mfcc, zero_crossing_rate, get_audio_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n",
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2787, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "# df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 70% train and 30% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1950, 2), Test set size (837, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration  \n",
       "0   4.640062  \n",
       "5   5.720063  \n",
       "34  5.640062  \n",
       "13  5.680063  \n",
       "45  6.200062  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample rate and clip duration for every clip\n",
    "df_train[['sr','duration']] = df_train['path'].apply(lambda p: get_audio_info(p))\n",
    "df_test[['sr','duration']] = df_test['path'].apply(lambda p: get_audio_info(p))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sr     duration\n",
      "count   1950.0  1950.000000\n",
      "mean   16000.0     7.688083\n",
      "std        0.0     4.507359\n",
      "min    16000.0     3.960062\n",
      "25%    16000.0     4.840063\n",
      "50%    16000.0     6.240062\n",
      "75%    16000.0     8.960062\n",
      "max    16000.0    61.680062 \n",
      "             sr    duration\n",
      "count    837.0  837.000000\n",
      "mean   16000.0    7.755045\n",
      "std        0.0    4.491689\n",
      "min    16000.0    3.960062\n",
      "25%    16000.0    4.880063\n",
      "50%    16000.0    6.360062\n",
      "75%    16000.0    8.920063\n",
      "max    16000.0   37.280062\n"
     ]
    }
   ],
   "source": [
    "print(f'{df_train.describe()} \\n {df_test.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of mfccs per clip\n",
    "n_mfcc = splits = 13\n",
    "\n",
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Zero Crossing Rate\n",
    "df_train[['zcr']] = df_train['path'].apply(lambda p: zero_crossing_rate(p, splits))\n",
    "df_test[['zcr']] = df_test['path'].apply(lambda p: zero_crossing_rate(p, splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df_test.iloc[26,5]\n",
    "# plt.plot(a)\n",
    "# plt.show()\n",
    "# print(a.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 20\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (1365, 39), Validation set size (585, 39)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta and zero crossing rate columns\n",
    "X = df_train.iloc[:,4:7]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list(), X_train['zcr'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(), X_val['delta'].to_list(), X_val['zcr'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               4000      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 46,320\n",
      "Trainable params: 46,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "86/86 [==============================] - 1s 5ms/step - loss: 15.2565 - accuracy: 0.0901 - val_loss: 2.9700 - val_accuracy: 0.0462\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.97004, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 3.8514 - accuracy: 0.0989 - val_loss: 2.9725 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.97004\n",
      "Epoch 3/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 3.1091 - accuracy: 0.1326 - val_loss: 2.9503 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.97004 to 2.95033, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 4/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.9945 - accuracy: 0.1678 - val_loss: 2.9290 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.95033 to 2.92900, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 5/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.9315 - accuracy: 0.1861 - val_loss: 2.9099 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.92900 to 2.90992, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 6/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.9031 - accuracy: 0.1919 - val_loss: 2.7138 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.90992 to 2.71378, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 7/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.8300 - accuracy: 0.1934 - val_loss: 2.6412 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.71378 to 2.64123, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 8/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.7664 - accuracy: 0.2066 - val_loss: 2.5610 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.64123 to 2.56097, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 9/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.7235 - accuracy: 0.2081 - val_loss: 2.5388 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.56097 to 2.53879, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 10/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.6213 - accuracy: 0.2088 - val_loss: 2.3842 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.53879 to 2.38421, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 11/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.5797 - accuracy: 0.2103 - val_loss: 2.3755 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.38421 to 2.37547, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 12/200\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 2.5527 - accuracy: 0.2352 - val_loss: 2.3762 - val_accuracy: 0.2923\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.37547\n",
      "Epoch 13/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.5112 - accuracy: 0.2872 - val_loss: 2.3544 - val_accuracy: 0.2923\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.37547 to 2.35437, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 14/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.4607 - accuracy: 0.2857 - val_loss: 2.3455 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.35437 to 2.34554, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 15/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.4601 - accuracy: 0.2886 - val_loss: 2.3345 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.34554 to 2.33454, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 16/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.4374 - accuracy: 0.2835 - val_loss: 2.3208 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.33454 to 2.32081, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 17/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.4118 - accuracy: 0.2908 - val_loss: 2.3268 - val_accuracy: 0.2957\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.32081\n",
      "Epoch 18/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3978 - accuracy: 0.2945 - val_loss: 2.3240 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.32081\n",
      "Epoch 19/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.4023 - accuracy: 0.2886 - val_loss: 2.3087 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.32081 to 2.30871, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 20/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3765 - accuracy: 0.2857 - val_loss: 2.2923 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.30871 to 2.29226, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3833 - accuracy: 0.2864 - val_loss: 2.2862 - val_accuracy: 0.3060\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.29226 to 2.28616, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 22/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3710 - accuracy: 0.2908 - val_loss: 2.2650 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.28616 to 2.26499, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 23/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3563 - accuracy: 0.2908 - val_loss: 2.2858 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.26499\n",
      "Epoch 24/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3259 - accuracy: 0.2886 - val_loss: 2.2599 - val_accuracy: 0.3060\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.26499 to 2.25986, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 25/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3003 - accuracy: 0.2967 - val_loss: 2.2541 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.25986 to 2.25410, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 26/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.3179 - accuracy: 0.2996 - val_loss: 2.2430 - val_accuracy: 0.3026\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.25410 to 2.24304, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 27/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.3083 - accuracy: 0.3004 - val_loss: 2.2243 - val_accuracy: 0.3162\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.24304 to 2.22429, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 28/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 2.2729 - accuracy: 0.3143 - val_loss: 2.1751 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.22429 to 2.17506, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 29/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2622 - accuracy: 0.3121 - val_loss: 2.1666 - val_accuracy: 0.3162\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.17506 to 2.16658, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 30/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2523 - accuracy: 0.3194 - val_loss: 2.1441 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.16658 to 2.14411, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 31/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2210 - accuracy: 0.3253 - val_loss: 2.1096 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.14411 to 2.10963, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 32/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2185 - accuracy: 0.3092 - val_loss: 2.1311 - val_accuracy: 0.3231\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.10963\n",
      "Epoch 33/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2214 - accuracy: 0.3165 - val_loss: 2.0821 - val_accuracy: 0.3419\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.10963 to 2.08213, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 34/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.2103 - accuracy: 0.3209 - val_loss: 2.0530 - val_accuracy: 0.3470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from 2.08213 to 2.05296, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 35/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.1519 - accuracy: 0.3319 - val_loss: 2.0097 - val_accuracy: 0.3949\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.05296 to 2.00969, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 36/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.1397 - accuracy: 0.3348 - val_loss: 1.9890 - val_accuracy: 0.3641\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.00969 to 1.98897, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 37/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0633 - accuracy: 0.3524 - val_loss: 1.9398 - val_accuracy: 0.4017\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.98897 to 1.93978, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 38/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0801 - accuracy: 0.3568 - val_loss: 1.9564 - val_accuracy: 0.4017\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.93978\n",
      "Epoch 39/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 2.0431 - accuracy: 0.3597 - val_loss: 1.9101 - val_accuracy: 0.4274\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.93978 to 1.91013, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 40/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.9998 - accuracy: 0.3722 - val_loss: 1.8384 - val_accuracy: 0.4359\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.91013 to 1.83839, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 41/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.9793 - accuracy: 0.3919 - val_loss: 1.7714 - val_accuracy: 0.4462\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.83839 to 1.77136, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 42/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.9132 - accuracy: 0.3941 - val_loss: 1.7677 - val_accuracy: 0.4615\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.77136 to 1.76772, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 43/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.8967 - accuracy: 0.3919 - val_loss: 1.7013 - val_accuracy: 0.4769\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.76772 to 1.70131, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 44/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.8778 - accuracy: 0.4183 - val_loss: 1.6381 - val_accuracy: 0.5043\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.70131 to 1.63807, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 45/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.8397 - accuracy: 0.4403 - val_loss: 1.5943 - val_accuracy: 0.5333\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.63807 to 1.59430, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 46/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.8217 - accuracy: 0.4359 - val_loss: 1.5920 - val_accuracy: 0.5282\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.59430 to 1.59200, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 47/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.7212 - accuracy: 0.4615 - val_loss: 1.5082 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.59200 to 1.50818, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 48/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6382 - accuracy: 0.4821 - val_loss: 1.4370 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.50818 to 1.43701, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 49/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.6286 - accuracy: 0.4930 - val_loss: 1.4089 - val_accuracy: 0.5658\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.43701 to 1.40887, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 50/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.5914 - accuracy: 0.5143 - val_loss: 1.4198 - val_accuracy: 0.5624\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.40887\n",
      "Epoch 51/200\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 1.5557 - accuracy: 0.5136 - val_loss: 1.3202 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.40887 to 1.32021, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 52/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.4948 - accuracy: 0.5370 - val_loss: 1.3077 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.32021 to 1.30774, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 53/200\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 1.5288 - accuracy: 0.5319 - val_loss: 1.3178 - val_accuracy: 0.5932\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.30774\n",
      "Epoch 54/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4845 - accuracy: 0.5590 - val_loss: 1.2556 - val_accuracy: 0.6051\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.30774 to 1.25565, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 55/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.4031 - accuracy: 0.5560 - val_loss: 1.2232 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.25565 to 1.22323, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 56/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.4076 - accuracy: 0.5656 - val_loss: 1.2291 - val_accuracy: 0.6171\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.22323\n",
      "Epoch 57/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 1.3617 - accuracy: 0.5729 - val_loss: 1.1956 - val_accuracy: 0.6222\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.22323 to 1.19562, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 58/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.3182 - accuracy: 0.5919 - val_loss: 1.1230 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.19562 to 1.12299, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 59/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2627 - accuracy: 0.5941 - val_loss: 1.1413 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.12299\n",
      "Epoch 60/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.3004 - accuracy: 0.6095 - val_loss: 1.1397 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.12299\n",
      "Epoch 61/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.2418 - accuracy: 0.6095 - val_loss: 1.0787 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.12299 to 1.07869, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 62/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1891 - accuracy: 0.6190 - val_loss: 1.0738 - val_accuracy: 0.6530\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.07869 to 1.07377, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 63/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1678 - accuracy: 0.6425 - val_loss: 1.0182 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.07377 to 1.01816, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 64/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1258 - accuracy: 0.6447 - val_loss: 1.0193 - val_accuracy: 0.6906\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.01816\n",
      "Epoch 65/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1427 - accuracy: 0.6293 - val_loss: 0.9873 - val_accuracy: 0.6803\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.01816 to 0.98729, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 66/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0998 - accuracy: 0.6520 - val_loss: 1.0377 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.98729\n",
      "Epoch 67/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0736 - accuracy: 0.6652 - val_loss: 1.0119 - val_accuracy: 0.6598\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.98729\n",
      "Epoch 68/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.1054 - accuracy: 0.6527 - val_loss: 0.9687 - val_accuracy: 0.6957\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.98729 to 0.96875, saving model to saved_models/speakers_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0668 - accuracy: 0.6696 - val_loss: 1.0113 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.96875\n",
      "Epoch 70/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0293 - accuracy: 0.6777 - val_loss: 0.9309 - val_accuracy: 0.7060\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.96875 to 0.93091, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 71/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.1041 - accuracy: 0.6418 - val_loss: 0.9473 - val_accuracy: 0.6889\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.93091\n",
      "Epoch 72/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 1.0409 - accuracy: 0.6733 - val_loss: 0.9250 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.93091 to 0.92501, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 73/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 1.0155 - accuracy: 0.6762 - val_loss: 0.8980 - val_accuracy: 0.7197\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.92501 to 0.89799, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 74/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.9652 - accuracy: 0.6879 - val_loss: 0.8889 - val_accuracy: 0.7162\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.89799 to 0.88890, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 75/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.9765 - accuracy: 0.6886 - val_loss: 0.8971 - val_accuracy: 0.7179\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.88890\n",
      "Epoch 76/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 1.0116 - accuracy: 0.6879 - val_loss: 0.8743 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.88890 to 0.87427, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 77/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.9944 - accuracy: 0.6857 - val_loss: 0.8654 - val_accuracy: 0.7282\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.87427 to 0.86537, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 78/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.9449 - accuracy: 0.6938 - val_loss: 0.8929 - val_accuracy: 0.7248\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.86537\n",
      "Epoch 79/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.8936 - accuracy: 0.7114 - val_loss: 0.8546 - val_accuracy: 0.7231\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.86537 to 0.85463, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 80/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.6901 - val_loss: 0.8725 - val_accuracy: 0.7145\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.85463\n",
      "Epoch 81/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.9311 - accuracy: 0.7114 - val_loss: 0.8765 - val_accuracy: 0.7162\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.85463\n",
      "Epoch 82/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.9044 - accuracy: 0.7172 - val_loss: 0.8678 - val_accuracy: 0.7111\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.85463\n",
      "Epoch 83/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8936 - accuracy: 0.7106 - val_loss: 0.8246 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.85463 to 0.82457, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 84/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.7275 - val_loss: 0.8389 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.82457\n",
      "Epoch 85/200\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 0.8369 - accuracy: 0.7245 - val_loss: 0.8095 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.82457 to 0.80947, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 86/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.8297 - accuracy: 0.7282 - val_loss: 0.8084 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.80947 to 0.80835, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 87/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8755 - accuracy: 0.7194 - val_loss: 0.7853 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.80835 to 0.78526, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 88/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.8560 - accuracy: 0.7238 - val_loss: 0.8138 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.78526\n",
      "Epoch 89/200\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8350 - accuracy: 0.7407 - val_loss: 0.7999 - val_accuracy: 0.7453\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.78526\n",
      "Epoch 90/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8246 - accuracy: 0.7201 - val_loss: 0.7736 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.78526 to 0.77360, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 91/200\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.7807 - accuracy: 0.7282 - val_loss: 0.8053 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.77360\n",
      "Epoch 92/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.8326 - accuracy: 0.7267 - val_loss: 0.7661 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.77360 to 0.76607, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 93/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.7951 - accuracy: 0.7495 - val_loss: 0.8021 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.76607\n",
      "Epoch 94/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.8059 - accuracy: 0.7443 - val_loss: 0.7592 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.76607 to 0.75925, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 95/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.7451 - val_loss: 0.7419 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.75925 to 0.74187, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 96/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7777 - accuracy: 0.7495 - val_loss: 0.7366 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.74187 to 0.73655, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 97/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.7487 - val_loss: 0.7313 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.73655 to 0.73131, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 98/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7936 - accuracy: 0.7429 - val_loss: 0.7181 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.73131 to 0.71805, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 99/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.7487 - val_loss: 0.7280 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.71805\n",
      "Epoch 100/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7754 - accuracy: 0.7392 - val_loss: 0.7413 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.71805\n",
      "Epoch 101/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.7538 - val_loss: 0.7621 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.71805\n",
      "Epoch 102/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.7575 - val_loss: 0.7641 - val_accuracy: 0.7368\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.71805\n",
      "Epoch 103/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.7663 - val_loss: 0.7758 - val_accuracy: 0.7385\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.71805\n",
      "Epoch 104/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7313 - accuracy: 0.7692 - val_loss: 0.7463 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.71805\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step - loss: 0.7796 - accuracy: 0.7465 - val_loss: 0.7978 - val_accuracy: 0.7453\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.71805\n",
      "Epoch 106/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.7692 - val_loss: 0.7350 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.71805\n",
      "Epoch 107/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7044 - accuracy: 0.7729 - val_loss: 0.7245 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.71805\n",
      "Epoch 108/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.7729 - val_loss: 0.7242 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.71805\n",
      "Epoch 109/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7714 - val_loss: 0.7053 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.71805 to 0.70535, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 110/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.7648 - val_loss: 0.7226 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.70535\n",
      "Epoch 111/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.7060 - accuracy: 0.7722 - val_loss: 0.7019 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.70535 to 0.70194, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 112/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.7698 - accuracy: 0.7495 - val_loss: 0.7389 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.70194\n",
      "Epoch 113/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.7685 - val_loss: 0.7371 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.70194\n",
      "Epoch 114/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.7802 - val_loss: 0.7170 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.70194\n",
      "Epoch 115/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.7619 - val_loss: 0.7146 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.70194\n",
      "Epoch 116/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.7678 - val_loss: 0.7074 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.70194\n",
      "Epoch 117/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.7832 - val_loss: 0.7117 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.70194\n",
      "Epoch 118/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.7262 - accuracy: 0.7641 - val_loss: 0.7931 - val_accuracy: 0.7658\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.70194\n",
      "Epoch 119/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.7824 - val_loss: 0.7147 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.70194\n",
      "Epoch 120/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 0.7846 - val_loss: 0.6747 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.70194 to 0.67467, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 121/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7912 - val_loss: 0.7089 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.67467\n",
      "Epoch 122/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7949 - val_loss: 0.6875 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.67467\n",
      "Epoch 123/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.7736 - val_loss: 0.7256 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.67467\n",
      "Epoch 124/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.8037 - val_loss: 0.7167 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.67467\n",
      "Epoch 125/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.7949 - val_loss: 0.7564 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.67467\n",
      "Epoch 126/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7875 - val_loss: 0.6946 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.67467\n",
      "Epoch 127/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.8029 - val_loss: 0.7063 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.67467\n",
      "Epoch 128/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.7883 - val_loss: 0.7437 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.67467\n",
      "Epoch 129/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7934 - val_loss: 0.7077 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.67467\n",
      "Epoch 130/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7875 - val_loss: 0.6881 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.67467\n",
      "Epoch 131/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7993 - val_loss: 0.6874 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.67467\n",
      "Epoch 132/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.8007 - val_loss: 0.6946 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.67467\n",
      "Epoch 133/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8147 - val_loss: 0.6989 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.67467\n",
      "Epoch 134/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7956 - val_loss: 0.6902 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.67467\n",
      "Epoch 135/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7890 - val_loss: 0.6509 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.67467 to 0.65089, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 136/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7971 - val_loss: 0.6720 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.65089\n",
      "Epoch 137/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8059 - val_loss: 0.6685 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.65089\n",
      "Epoch 138/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.8037 - val_loss: 0.6668 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.65089\n",
      "Epoch 139/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.8007 - val_loss: 0.6755 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.65089\n",
      "Epoch 140/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.8132 - val_loss: 0.6476 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.65089 to 0.64760, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 141/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.8037 - val_loss: 0.6650 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.64760\n",
      "Epoch 142/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.8015 - val_loss: 0.6573 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.64760\n",
      "Epoch 143/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.8147 - val_loss: 0.6367 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.64760 to 0.63672, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 144/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.8139 - val_loss: 0.6886 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.63672\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.8000 - val_loss: 0.6946 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.63672\n",
      "Epoch 146/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8198 - val_loss: 0.6918 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.63672\n",
      "Epoch 147/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.8000 - val_loss: 0.6884 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.63672\n",
      "Epoch 148/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.8234 - val_loss: 0.7142 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.63672\n",
      "Epoch 149/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.8059 - val_loss: 0.6723 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.63672\n",
      "Epoch 150/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.8190 - val_loss: 0.6829 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.63672\n",
      "Epoch 151/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.8147 - val_loss: 0.6579 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.63672\n",
      "Epoch 152/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.5857 - accuracy: 0.8190 - val_loss: 0.6779 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.63672\n",
      "Epoch 153/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.8088 - val_loss: 0.6974 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.63672\n",
      "Epoch 154/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.8154 - val_loss: 0.6520 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.63672\n",
      "Epoch 155/200\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.8103 - val_loss: 0.6674 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.63672\n",
      "Epoch 156/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.8256 - val_loss: 0.6636 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.63672\n",
      "Epoch 157/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.8168 - val_loss: 0.6745 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.63672\n",
      "Epoch 158/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.8278 - val_loss: 0.7177 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.63672\n",
      "Epoch 159/200\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.8300 - val_loss: 0.6804 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.63672\n",
      "Epoch 160/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.8212 - val_loss: 0.6730 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.63672\n",
      "Epoch 161/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.8256 - val_loss: 0.6447 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.63672\n",
      "Epoch 162/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.8447 - val_loss: 0.6912 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.63672\n",
      "Epoch 163/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8198 - val_loss: 0.6656 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.63672\n",
      "Epoch 164/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.4400 - accuracy: 0.8498 - val_loss: 0.6710 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.63672\n",
      "Epoch 165/200\n",
      "86/86 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.8315 - val_loss: 0.6713 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.63672\n",
      "Epoch 166/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.8117 - val_loss: 0.7131 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.63672\n",
      "Epoch 167/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8198 - val_loss: 0.7263 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.63672\n",
      "Epoch 168/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.8198 - val_loss: 0.6780 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.63672\n",
      "Epoch 169/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8352 - val_loss: 0.6517 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.63672\n",
      "Epoch 170/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8212 - val_loss: 0.6460 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.63672\n",
      "Epoch 171/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8271 - val_loss: 0.6789 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.63672\n",
      "Epoch 172/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.8344 - val_loss: 0.6838 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.63672\n",
      "Epoch 173/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.8462 - val_loss: 0.6894 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.63672\n",
      "Epoch 174/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8396 - val_loss: 0.7477 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.63672\n",
      "Epoch 175/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8330 - val_loss: 0.6742 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.63672\n",
      "Epoch 176/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.8286 - val_loss: 0.6883 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.63672\n",
      "Epoch 177/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.8234 - val_loss: 0.7387 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.63672\n",
      "Epoch 178/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8374 - val_loss: 0.7096 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.63672\n",
      "Epoch 179/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.8132 - val_loss: 0.7838 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.63672\n",
      "Epoch 180/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.8205 - val_loss: 0.7626 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.63672\n",
      "Epoch 181/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8271 - val_loss: 0.7139 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.63672\n",
      "Epoch 182/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.8256 - val_loss: 0.6793 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.63672\n",
      "Epoch 183/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.8293 - val_loss: 0.7100 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.63672\n",
      "Epoch 184/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8315 - val_loss: 0.6679 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.63672\n",
      "Epoch 185/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.8315 - val_loss: 0.6775 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.63672\n",
      "Epoch 186/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8469 - val_loss: 0.6494 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.63672\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8469 - val_loss: 0.7015 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.63672\n",
      "Epoch 188/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8271 - val_loss: 0.6719 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.63672\n",
      "Epoch 189/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8491 - val_loss: 0.6583 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.63672\n",
      "Epoch 190/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.8271 - val_loss: 0.6523 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.63672\n",
      "Epoch 191/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8308 - val_loss: 0.6451 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.63672\n",
      "Epoch 192/200\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 0.5206 - accuracy: 0.8234 - val_loss: 0.6764 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.63672\n",
      "Epoch 193/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.8447 - val_loss: 0.6575 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.63672\n",
      "Epoch 194/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.8418 - val_loss: 0.6931 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.63672\n",
      "Epoch 195/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8535 - val_loss: 0.6716 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.63672\n",
      "Epoch 196/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.8520 - val_loss: 0.6862 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.63672\n",
      "Epoch 197/200\n",
      "86/86 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.8418 - val_loss: 0.6835 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.63672\n",
      "Epoch 198/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8447 - val_loss: 0.6741 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.63672\n",
      "Epoch 199/200\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8234 - val_loss: 0.6912 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.63672\n",
      "Epoch 200/200\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.8484 - val_loss: 0.6677 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.63672\n",
      "Training completed in time:  0:01:10.389199\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 16\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 39)\n",
      "['id10003' 'id10009' 'id10009' 'id10003' 'id10009' 'id10009' 'id10009'\n",
      " 'id10016' 'id10009' 'id10016' 'id10004' 'id10009' 'id10009' 'id10009'\n",
      " 'id10009' 'id10009' 'id10009' 'id10009' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10001' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10014' 'id10007'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10004' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10014' 'id10006'\n",
      " 'id10004' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10014' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10006' 'id10001' 'id10017' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10001' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10015' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10012' 'id10018' 'id10012' 'id10012' 'id10018'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10002'\n",
      " 'id10012' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10011' 'id10018' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10018' 'id10018' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10019' 'id10015' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015'\n",
      " 'id10011' 'id10015' 'id10014' 'id10014' 'id10014' 'id10007' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10001' 'id10009' 'id10014' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10006' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10013' 'id10013' 'id10013' 'id10013'\n",
      " 'id10006' 'id10006' 'id10013' 'id10013' 'id10013' 'id10013' 'id10013'\n",
      " 'id10019' 'id10004' 'id10013' 'id10013' 'id10004' 'id10004' 'id10003'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10001' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10017' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10017' 'id10003'\n",
      " 'id10017' 'id10003' 'id10003' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10012' 'id10002'\n",
      " 'id10005' 'id10005' 'id10005' 'id10005' 'id10003' 'id10018' 'id10005'\n",
      " 'id10017' 'id10003' 'id10004' 'id10005' 'id10005' 'id10005' 'id10017'\n",
      " 'id10016' 'id10005' 'id10005' 'id10005' 'id10016' 'id10012' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10012' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10016' 'id10016' 'id10017'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10003' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10012'\n",
      " 'id10016' 'id10016' 'id10016' 'id10011' 'id10003' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10003' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10019' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10004' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10012' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10012'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10019' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10020' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10018' 'id10010'\n",
      " 'id10003' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010' 'id10010'\n",
      " 'id10010' 'id10004' 'id10010' 'id10007' 'id10010' 'id10010' 'id10010'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10003' 'id10017' 'id10016'\n",
      " 'id10017' 'id10017' 'id10017' 'id10016' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10003' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10003' 'id10017' 'id10017' 'id10016' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.84      0.91      0.87        23\n",
      "     id10002       0.97      0.97      0.97        39\n",
      "     id10003       0.80      0.94      0.86        51\n",
      "     id10004       0.81      0.94      0.87        32\n",
      "     id10005       1.00      0.61      0.76        18\n",
      "     id10006       0.89      0.89      0.89        38\n",
      "     id10007       0.92      0.92      0.92        24\n",
      "     id10008       1.00      0.94      0.97        32\n",
      "     id10009       0.93      0.72      0.81        18\n",
      "     id10010       1.00      0.75      0.86        16\n",
      "     id10011       0.92      0.97      0.95        36\n",
      "     id10012       0.86      0.82      0.84        45\n",
      "     id10013       1.00      0.73      0.85        15\n",
      "     id10014       0.89      0.86      0.88        29\n",
      "     id10015       0.94      0.89      0.91        18\n",
      "     id10016       0.92      0.92      0.92        76\n",
      "     id10017       0.85      0.87      0.86        46\n",
      "     id10018       0.90      0.94      0.92        81\n",
      "     id10019       0.85      0.96      0.90        23\n",
      "     id10020       0.99      0.99      0.99       177\n",
      "\n",
      "    accuracy                           0.92       837\n",
      "   macro avg       0.91      0.88      0.89       837\n",
      "weighted avg       0.92      0.92      0.92       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),\n",
    "                    df_test['delta'].to_list(),\n",
    "                    df_test['zcr'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "# for every speaker fit a GMM and save the model\n",
    "unique_speakers = df_train['speaker'].unique()\n",
    "for speaker in unique_speakers:\n",
    "    df_speaker = df_train[df_train['speaker'] == speaker]\n",
    "    features = np.asarray(())\n",
    "    for index, row in df_speaker.iterrows():\n",
    "        vector = np.hstack((row['mfcc'], row['delta'], row['zcr']))\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features,vector))\n",
    "    \n",
    "    gmm = mixture.GaussianMixture(n_components = 16, covariance_type='diag',n_init = 3)\n",
    "    gmm.fit(features)    \n",
    "    filename = 'saved_models/gmm/' + f'gmm_{speaker}.sav'\n",
    "    pickle.dump(gmm, open(filename, 'wb'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gmm_id10020.sav', 'gmm_id10008.sav', 'gmm_id10009.sav', 'gmm_id10019.sav', 'gmm_id10018.sav', 'gmm_id10016.sav', 'gmm_id10002.sav', 'gmm_id10003.sav', 'gmm_id10017.sav', 'gmm_id10001.sav', 'gmm_id10015.sav', 'gmm_id10014.sav', 'gmm_id10004.sav', 'gmm_id10010.sav', 'gmm_id10011.sav', 'gmm_id10005.sav', 'gmm_id10013.sav', 'gmm_id10007.sav', 'gmm_id10006.sav', 'gmm_id10012.sav']\n",
      "The Accuracy with (MFCC + DELTA + ZCR) and GMM is : 99.4026284348865\n"
     ]
    }
   ],
   "source": [
    "# load models and predict on test\n",
    "gmm_files = [os.path.join('saved_models/gmm/',fname) for fname in \n",
    "              os.listdir('saved_models/gmm/') if fname.endswith('.sav')]\n",
    "\n",
    "#Load the Gaussian gender Models\n",
    "gmm_models = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "unique_speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "              in gmm_files]\n",
    "\n",
    "print(unique_speakers)\n",
    "nr_errors = 0\n",
    "total_samples = len(df_test)\n",
    "for index, row in df_test.iterrows():\n",
    "    log_likelihood = np.zeros(len(gmm_models)) \n",
    "    features = np.hstack((row['mfcc'], row['delta'], row['zcr']))\n",
    "    features = features.reshape(1,-1)\n",
    "    \n",
    "    for i, gmm in enumerate(gmm_models):\n",
    "        scores = np.array(gmm.score(features))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    y_pred = np.argmax(log_likelihood)\n",
    "    if unique_speakers[y_pred] != 'gmm_' + row['speaker']+ '.sav':\n",
    "        nr_errors += 1\n",
    "\n",
    "accuracy = ((total_samples - nr_errors) / total_samples) * 100\n",
    "print (f'The Accuracy with (MFCC + DELTA + ZCR) and GMM is : {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
