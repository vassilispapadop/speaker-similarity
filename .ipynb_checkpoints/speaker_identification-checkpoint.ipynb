{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "from app.website.extract_features import extract_mfcc, zero_crossing_rate, get_audio_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We check given directory to find all available *.wav* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def contains_number(s):\n",
    "    return any(i.isdigit() for i in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id10009', 'id10007', 'id10006', 'id10001', 'id10008', 'id10012', 'id10015', 'id10014', 'id10013', 'id10004', 'id10003', 'id10002', 'id10005', 'id10016', 'id10011', 'id10018', 'id10020', 'id10019', 'id10010', 'id10017']\n",
      "checking dir: ./vox_dev_wav/wav/id10009/\n",
      "./vox_dev_wav/wav/id10009/HCGXIgKsozU/\n",
      "./vox_dev_wav/wav/id10009/AtavJVP4bCk/\n",
      "./vox_dev_wav/wav/id10009/x_HdUZuSusA/\n",
      "./vox_dev_wav/wav/id10009/seo9TTTEoE4/\n",
      "./vox_dev_wav/wav/id10009/7hpSiT9_gCE/\n",
      "./vox_dev_wav/wav/id10009/JrwqvWr5_VE/\n",
      "./vox_dev_wav/wav/id10009/FOFbkVlz-wQ/\n",
      "./vox_dev_wav/wav/id10009/JntZkGsH2Cc/\n",
      "./vox_dev_wav/wav/id10009/aFttHpeaXaQ/\n",
      "./vox_dev_wav/wav/id10009/vy8sQ82o0fM/\n",
      "./vox_dev_wav/wav/id10009/qdop2-gjKBQ/\n",
      "./vox_dev_wav/wav/id10009/VM8gJWbQsEY/\n",
      "./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/\n",
      "./vox_dev_wav/wav/id10009/sQIqfA-I_Ew/\n",
      "checking dir: ./vox_dev_wav/wav/id10007/\n",
      "./vox_dev_wav/wav/id10007/10Oe0XETA0s/\n",
      "./vox_dev_wav/wav/id10007/ny4iV7xwhRM/\n",
      "./vox_dev_wav/wav/id10007/HxfxcxUXPDA/\n",
      "./vox_dev_wav/wav/id10007/G0lVD5d0KJo/\n",
      "./vox_dev_wav/wav/id10007/Lc2IMwkXgnI/\n",
      "./vox_dev_wav/wav/id10007/5ExvrJyWpe8/\n",
      "./vox_dev_wav/wav/id10007/uyOlasN_UhQ/\n",
      "./vox_dev_wav/wav/id10007/CzQPAaPrC-E/\n",
      "./vox_dev_wav/wav/id10007/foG5a3YtZzI/\n",
      "./vox_dev_wav/wav/id10007/IWAkF5uWjis/\n",
      "checking dir: ./vox_dev_wav/wav/id10006/\n",
      "./vox_dev_wav/wav/id10006/ZCRCpLUo9Ro/\n",
      "./vox_dev_wav/wav/id10006/KFllccZyqeY/\n",
      "./vox_dev_wav/wav/id10006/3RybHF5mX78/\n",
      "./vox_dev_wav/wav/id10006/7W9goO0lNrA/\n",
      "./vox_dev_wav/wav/id10006/3MwyuwaVE50/\n",
      "./vox_dev_wav/wav/id10006/ZlLPhRabPPw/\n",
      "./vox_dev_wav/wav/id10006/J7VccwLPdrI/\n",
      "./vox_dev_wav/wav/id10006/88biLNZtnag/\n",
      "./vox_dev_wav/wav/id10006/7qUfkhbDaqc/\n",
      "./vox_dev_wav/wav/id10006/Dv-wtqTn0wE/\n",
      "./vox_dev_wav/wav/id10006/nLEBBc9oIFs/\n",
      "./vox_dev_wav/wav/id10006/zQROl4ZsMVA/\n",
      "./vox_dev_wav/wav/id10006/5tGaUGO_z50/\n",
      "./vox_dev_wav/wav/id10006/rgfcI2Wy4mY/\n",
      "./vox_dev_wav/wav/id10006/VaFNI2T9PTA/\n",
      "./vox_dev_wav/wav/id10006/aaOv6y3Ii4o/\n",
      "./vox_dev_wav/wav/id10006/DjrTX2Z-rzI/\n",
      "./vox_dev_wav/wav/id10006/0otHlFztX8I/\n",
      "./vox_dev_wav/wav/id10006/c-4jmRmEqEc/\n",
      "./vox_dev_wav/wav/id10006/5PBimrKDrJQ/\n",
      "./vox_dev_wav/wav/id10006/QEUVd2ZIcTg/\n",
      "./vox_dev_wav/wav/id10006/_xUsNvG7-Jk/\n",
      "./vox_dev_wav/wav/id10006/nzDmrjyy8ls/\n",
      "checking dir: ./vox_dev_wav/wav/id10001/\n",
      "./vox_dev_wav/wav/id10001/J9lHsKG98U8/\n",
      "./vox_dev_wav/wav/id10001/DtdEYdViWdw/\n",
      "./vox_dev_wav/wav/id10001/7w0IBEWc9Qw/\n",
      "./vox_dev_wav/wav/id10001/zELwAz2W6hM/\n",
      "./vox_dev_wav/wav/id10001/eWIX7sfn-M0/\n",
      "./vox_dev_wav/wav/id10001/1zcIwhmdeo4/\n",
      "./vox_dev_wav/wav/id10001/7gWzIy6yIIk/\n",
      "./vox_dev_wav/wav/id10001/utrA-v8pPm4/\n",
      "./vox_dev_wav/wav/id10001/Y8hIVOBuels/\n",
      "./vox_dev_wav/wav/id10001/9mQ11vBs1wc/\n",
      "checking dir: ./vox_dev_wav/wav/id10008/\n",
      "./vox_dev_wav/wav/id10008/D5RZyExnz8g/\n",
      "./vox_dev_wav/wav/id10008/CFwSMiMzoiA/\n",
      "./vox_dev_wav/wav/id10008/gdQhQUcKrds/\n",
      "./vox_dev_wav/wav/id10008/l8vq6uu_aNE/\n",
      "./vox_dev_wav/wav/id10008/X7JNabXlduc/\n",
      "./vox_dev_wav/wav/id10008/_rz5gmMFZTo/\n",
      "./vox_dev_wav/wav/id10008/X9OPcj9ID10/\n",
      "./vox_dev_wav/wav/id10008/MIinwxeI1H0/\n",
      "./vox_dev_wav/wav/id10008/r4IZRsEGDFs/\n",
      "./vox_dev_wav/wav/id10008/YEkuUBPkSZg/\n",
      "./vox_dev_wav/wav/id10008/CXgomMquVt8/\n",
      "./vox_dev_wav/wav/id10008/dL5jx3GLNxU/\n",
      "./vox_dev_wav/wav/id10008/58jhTekFbHk/\n",
      "./vox_dev_wav/wav/id10008/ZwprcvqTH3w/\n",
      "checking dir: ./vox_dev_wav/wav/id10012/\n",
      "./vox_dev_wav/wav/id10012/1miD-AWtXqk/\n",
      "./vox_dev_wav/wav/id10012/pVhap6mxjW4/\n",
      "./vox_dev_wav/wav/id10012/Mb2crBji7Cc/\n",
      "./vox_dev_wav/wav/id10012/nCwwVjPNloY/\n",
      "./vox_dev_wav/wav/id10012/tdeNGXCvfno/\n",
      "./vox_dev_wav/wav/id10012/o-8xXV5MC8I/\n",
      "./vox_dev_wav/wav/id10012/PfrOkWQfi08/\n",
      "./vox_dev_wav/wav/id10012/ugLQaIVIxIw/\n",
      "./vox_dev_wav/wav/id10012/q6SMDFi6fuY/\n",
      "./vox_dev_wav/wav/id10012/AStt8Tx-HXU/\n",
      "./vox_dev_wav/wav/id10012/GQxAiL_gSJg/\n",
      "./vox_dev_wav/wav/id10012/elHFKzE4K7g/\n",
      "./vox_dev_wav/wav/id10012/UJFb8jDbWl0/\n",
      "./vox_dev_wav/wav/id10012/zvZZyolTF4g/\n",
      "./vox_dev_wav/wav/id10012/W6kAA9GhYxs/\n",
      "./vox_dev_wav/wav/id10012/0AXjxNXiEzo/\n",
      "./vox_dev_wav/wav/id10012/vYBOvwSW--4/\n",
      "./vox_dev_wav/wav/id10012/zsNhH4wHVdc/\n",
      "./vox_dev_wav/wav/id10012/g5-eq6I-KSo/\n",
      "./vox_dev_wav/wav/id10012/Mki-3pJgdMw/\n",
      "./vox_dev_wav/wav/id10012/EHSEDnLxkC4/\n",
      "checking dir: ./vox_dev_wav/wav/id10015/\n",
      "./vox_dev_wav/wav/id10015/uoAEmu-GbjQ/\n",
      "./vox_dev_wav/wav/id10015/V_x_l3deWaU/\n",
      "./vox_dev_wav/wav/id10015/Y2FI1LS8lzg/\n",
      "./vox_dev_wav/wav/id10015/1uUxa00zKXE/\n",
      "./vox_dev_wav/wav/id10015/LbR3PNHiXms/\n",
      "./vox_dev_wav/wav/id10015/GpBIco6EWl0/\n",
      "./vox_dev_wav/wav/id10015/3hdsN9oG45Q/\n",
      "./vox_dev_wav/wav/id10015/Wr_zcjHCZLk/\n",
      "./vox_dev_wav/wav/id10015/PIqPzGtHqNY/\n",
      "./vox_dev_wav/wav/id10015/oWww40TVo-s/\n",
      "./vox_dev_wav/wav/id10015/cnfBsYa5iOM/\n",
      "./vox_dev_wav/wav/id10015/dKAazrqEcuI/\n",
      "./vox_dev_wav/wav/id10015/wNQ9HultFDs/\n",
      "./vox_dev_wav/wav/id10015/ESZSf-D4cgw/\n",
      "./vox_dev_wav/wav/id10015/7rzuEmfRFEA/\n",
      "checking dir: ./vox_dev_wav/wav/id10014/\n",
      "./vox_dev_wav/wav/id10014/70z-Im2hzlg/\n",
      "./vox_dev_wav/wav/id10014/AERvjDy1Bn0/\n",
      "./vox_dev_wav/wav/id10014/QATUag13zcI/\n",
      "./vox_dev_wav/wav/id10014/xbDbdm5iv9Q/\n",
      "./vox_dev_wav/wav/id10014/32rU5csGG3U/\n",
      "./vox_dev_wav/wav/id10014/hepofXpeNAA/\n",
      "./vox_dev_wav/wav/id10014/Llzfnc-K38c/\n",
      "./vox_dev_wav/wav/id10014/b8reDPl-P0w/\n",
      "./vox_dev_wav/wav/id10014/XP0NEmdnh40/\n",
      "./vox_dev_wav/wav/id10014/RbXXh_l-qH8/\n",
      "./vox_dev_wav/wav/id10014/2kd0eGbbIeg/\n",
      "./vox_dev_wav/wav/id10014/6RiWT7JoAkk/\n",
      "./vox_dev_wav/wav/id10014/iZ6XrudZsSw/\n",
      "./vox_dev_wav/wav/id10014/s4Go6oBiQ8Y/\n",
      "./vox_dev_wav/wav/id10014/FHiYKAd2Th4/\n",
      "./vox_dev_wav/wav/id10014/x6SoLOKT19w/\n",
      "checking dir: ./vox_dev_wav/wav/id10013/\n",
      "./vox_dev_wav/wav/id10013/ayglFsYxfj0/\n",
      "./vox_dev_wav/wav/id10013/J4dr4jUUPWs/\n",
      "./vox_dev_wav/wav/id10013/D8N1aTvis1o/\n",
      "./vox_dev_wav/wav/id10013/8Ia5Ffj4MtQ/\n",
      "./vox_dev_wav/wav/id10013/a3cI12ZNVms/\n",
      "./vox_dev_wav/wav/id10013/IAFLCkJh_PM/\n",
      "./vox_dev_wav/wav/id10013/hGL2tRHivdw/\n",
      "./vox_dev_wav/wav/id10013/HpmwLdV5TAc/\n",
      "./vox_dev_wav/wav/id10013/EYYiAyJk1w8/\n",
      "./vox_dev_wav/wav/id10013/qJ8keZPNFZ4/\n",
      "./vox_dev_wav/wav/id10013/fYVXJaLX4dA/\n",
      "checking dir: ./vox_dev_wav/wav/id10004/\n",
      "./vox_dev_wav/wav/id10004/8mWxQ6DRO-U/\n",
      "./vox_dev_wav/wav/id10004/q6QJY1ndpOY/\n",
      "./vox_dev_wav/wav/id10004/BOAd7pybyZw/\n",
      "./vox_dev_wav/wav/id10004/CCygVo0iPvw/\n",
      "./vox_dev_wav/wav/id10004/JKMfqmjUwMU/\n",
      "./vox_dev_wav/wav/id10004/wQJ3cED8ZSw/\n",
      "./vox_dev_wav/wav/id10004/CWTpJe2RqOA/\n",
      "./vox_dev_wav/wav/id10004/bIZQaEVuATQ/\n",
      "./vox_dev_wav/wav/id10004/eaYIxBz6lBU/\n",
      "./vox_dev_wav/wav/id10004/qqhJQYlENHs/\n",
      "./vox_dev_wav/wav/id10004/IEV-I9f21ns/\n",
      "./vox_dev_wav/wav/id10004/dwKTFeIhTOQ/\n",
      "./vox_dev_wav/wav/id10004/zcB1pnBt_Tc/\n",
      "./vox_dev_wav/wav/id10004/SMKC-WLY6F0/\n",
      "./vox_dev_wav/wav/id10004/Oftn1-Z0Lbk/\n",
      "./vox_dev_wav/wav/id10004/lu_eVSfv3Tg/\n",
      "./vox_dev_wav/wav/id10004/6WxS8rpNjmk/\n",
      "checking dir: ./vox_dev_wav/wav/id10003/\n",
      "./vox_dev_wav/wav/id10003/_JpHD6VnJ3I/\n",
      "./vox_dev_wav/wav/id10003/A7Hh1WKmHsg/\n",
      "./vox_dev_wav/wav/id10003/K5zRxtXc27s/\n",
      "./vox_dev_wav/wav/id10003/A8SBCxYzJgs/\n",
      "./vox_dev_wav/wav/id10003/5ablueV_1tw/\n",
      "./vox_dev_wav/wav/id10003/BQxxhq4539A/\n",
      "./vox_dev_wav/wav/id10003/tCq2LcKO6xY/\n",
      "./vox_dev_wav/wav/id10003/bDxy7bnj_bc/\n",
      "./vox_dev_wav/wav/id10003/na8-QEFmj44/\n",
      "./vox_dev_wav/wav/id10003/E_6MjfYr0sQ/\n",
      "./vox_dev_wav/wav/id10003/yzIXg93UOIM/\n",
      "./vox_dev_wav/wav/id10003/NC70RWJDnMg/\n",
      "./vox_dev_wav/wav/id10003/Tzn91xwBaWE/\n",
      "./vox_dev_wav/wav/id10003/EGPV-Xa0LGk/\n",
      "./vox_dev_wav/wav/id10003/FfmnkloV_zg/\n",
      "checking dir: ./vox_dev_wav/wav/id10002/\n",
      "./vox_dev_wav/wav/id10002/C7k7C-PDvAA/\n",
      "./vox_dev_wav/wav/id10002/VMaXdHLz5Bk/\n",
      "./vox_dev_wav/wav/id10002/SI4D2_YXvBE/\n",
      "./vox_dev_wav/wav/id10002/wd_7oYV4dsU/\n",
      "./vox_dev_wav/wav/id10002/cMGEuZ1zqXk/\n",
      "./vox_dev_wav/wav/id10002/w9H-ZMvdE9M/\n",
      "./vox_dev_wav/wav/id10002/QnnjJ9i5WFs/\n",
      "./vox_dev_wav/wav/id10002/eNc4LrrvV80/\n",
      "./vox_dev_wav/wav/id10002/Mpr9wqUuLQA/\n",
      "./vox_dev_wav/wav/id10002/RLKKsYiCMvc/\n",
      "./vox_dev_wav/wav/id10002/xTV-jFAUKcw/\n",
      "./vox_dev_wav/wav/id10002/gaQqIoV_aLY/\n",
      "./vox_dev_wav/wav/id10002/TqUbiOgEb0w/\n",
      "./vox_dev_wav/wav/id10002/0_laIeN-Q44/\n",
      "./vox_dev_wav/wav/id10002/Y2Gr1I2DO7M/\n",
      "./vox_dev_wav/wav/id10002/QanuGhOhb9A/\n",
      "./vox_dev_wav/wav/id10002/6WO410QOeuo/\n",
      "checking dir: ./vox_dev_wav/wav/id10005/\n",
      "./vox_dev_wav/wav/id10005/WMh3ye5tBsE/\n",
      "./vox_dev_wav/wav/id10005/RSguOg1U-NA/\n",
      "./vox_dev_wav/wav/id10005/UguBGTDl3FM/\n",
      "./vox_dev_wav/wav/id10005/1geDB-I2TjE/\n",
      "./vox_dev_wav/wav/id10005/Yks5By_Hv_Y/\n",
      "./vox_dev_wav/wav/id10005/L21ozpbmODY/\n",
      "./vox_dev_wav/wav/id10005/WD-MtwoWSxs/\n",
      "./vox_dev_wav/wav/id10005/PP0cQLwYz5M/\n",
      "./vox_dev_wav/wav/id10005/oJYptXzCASM/\n",
      "./vox_dev_wav/wav/id10005/mzZj5a0FgZY/\n",
      "./vox_dev_wav/wav/id10005/6-crWEwaThs/\n",
      "./vox_dev_wav/wav/id10005/38_N-A-QOUo/\n",
      "./vox_dev_wav/wav/id10005/ZZR6EqjbzwI/\n",
      "./vox_dev_wav/wav/id10005/x-1gq_B3snI/\n",
      "checking dir: ./vox_dev_wav/wav/id10016/\n",
      "./vox_dev_wav/wav/id10016/2wHaOQUrkHU/\n",
      "./vox_dev_wav/wav/id10016/a3j4Vg7CtjA/\n",
      "./vox_dev_wav/wav/id10016/MPkuYnDHS4E/\n",
      "./vox_dev_wav/wav/id10016/ocnz4PPv-RQ/\n",
      "./vox_dev_wav/wav/id10016/hgB5ziAudzU/\n",
      "./vox_dev_wav/wav/id10016/Zxab80IZxU8/\n",
      "./vox_dev_wav/wav/id10016/SCFgvk0Sm24/\n",
      "./vox_dev_wav/wav/id10016/k4l2cRqjT78/\n",
      "./vox_dev_wav/wav/id10016/7OacMAs-Crc/\n",
      "./vox_dev_wav/wav/id10016/j0CaA8LPTdc/\n",
      "./vox_dev_wav/wav/id10016/CsU9a10ccxA/\n",
      "./vox_dev_wav/wav/id10016/WfkA4lUZwZ4/\n",
      "./vox_dev_wav/wav/id10016/LSeSZiv7evE/\n",
      "./vox_dev_wav/wav/id10016/5xGJYiNH2Jw/\n",
      "./vox_dev_wav/wav/id10016/dOnuu_9-nyI/\n",
      "./vox_dev_wav/wav/id10016/pdTdefdQ_QI/\n",
      "./vox_dev_wav/wav/id10016/7FOcBtZM-rI/\n",
      "./vox_dev_wav/wav/id10016/WwguhI5dInQ/\n",
      "./vox_dev_wav/wav/id10016/l5sY-WWVnZM/\n",
      "./vox_dev_wav/wav/id10016/37mbJ9bXK28/\n",
      "./vox_dev_wav/wav/id10016/8gWjr_-ROCc/\n",
      "./vox_dev_wav/wav/id10016/uM5GCGOXVXc/\n",
      "./vox_dev_wav/wav/id10016/FDXUYIgkTgk/\n",
      "./vox_dev_wav/wav/id10016/vpnw2jQlZn4/\n",
      "./vox_dev_wav/wav/id10016/bIi7FnNx6m0/\n",
      "./vox_dev_wav/wav/id10016/wg6IOBMAdOc/\n",
      "./vox_dev_wav/wav/id10016/ywRolvE7ToY/\n",
      "./vox_dev_wav/wav/id10016/NJygdnZs634/\n",
      "./vox_dev_wav/wav/id10016/fb31EtxsZDs/\n",
      "./vox_dev_wav/wav/id10016/MMTrblYIEgM/\n",
      "./vox_dev_wav/wav/id10016/o524HaR7jfE/\n",
      "./vox_dev_wav/wav/id10016/RREb7K-SoSQ/\n",
      "./vox_dev_wav/wav/id10016/PnSNt2F59-U/\n",
      "checking dir: ./vox_dev_wav/wav/id10011/\n",
      "./vox_dev_wav/wav/id10011/g3SlFv2ui8A/\n",
      "./vox_dev_wav/wav/id10011/wbcvg6hIyjs/\n",
      "./vox_dev_wav/wav/id10011/mwKVL6cadQw/\n",
      "./vox_dev_wav/wav/id10011/u3odsIbYouc/\n",
      "./vox_dev_wav/wav/id10011/UzGMFpIv-ss/\n",
      "./vox_dev_wav/wav/id10011/L_Q9NL9H1wI/\n",
      "./vox_dev_wav/wav/id10011/Q1aiO-vpabc/\n",
      "./vox_dev_wav/wav/id10011/TsWNxShkS9A/\n",
      "./vox_dev_wav/wav/id10011/QmFNWMU2hKU/\n",
      "./vox_dev_wav/wav/id10011/978HIG18Lek/\n",
      "./vox_dev_wav/wav/id10011/0Wg6d-v2CrQ/\n",
      "./vox_dev_wav/wav/id10011/YyB6Rk0bOSg/\n",
      "./vox_dev_wav/wav/id10011/NY8rvshKUzU/\n",
      "./vox_dev_wav/wav/id10011/ujWHD_MTa44/\n",
      "./vox_dev_wav/wav/id10011/R8SJg-rcjKI/\n",
      "./vox_dev_wav/wav/id10011/01En9rUo_Co/\n",
      "checking dir: ./vox_dev_wav/wav/id10018/\n",
      "./vox_dev_wav/wav/id10018/YOjilzTiE-Y/\n",
      "./vox_dev_wav/wav/id10018/sci80gk6bUc/\n",
      "./vox_dev_wav/wav/id10018/eckQg181kQY/\n",
      "./vox_dev_wav/wav/id10018/A-Q7SmHQT70/\n",
      "./vox_dev_wav/wav/id10018/TIFdSOTYIBg/\n",
      "./vox_dev_wav/wav/id10018/9tu4uaM0YTc/\n",
      "./vox_dev_wav/wav/id10018/EFFEzbt2k6o/\n",
      "./vox_dev_wav/wav/id10018/RM55SnIw2uQ/\n",
      "./vox_dev_wav/wav/id10018/iYaSdx4Qhv4/\n",
      "./vox_dev_wav/wav/id10018/ZBioF6ulHg8/\n",
      "./vox_dev_wav/wav/id10018/2fsToHH2Qz4/\n",
      "./vox_dev_wav/wav/id10018/lCA6CCS7mxc/\n",
      "./vox_dev_wav/wav/id10018/RBlk-zGCm0g/\n",
      "./vox_dev_wav/wav/id10018/8WVqEfbZ4Ic/\n",
      "./vox_dev_wav/wav/id10018/sqdHikUKOK0/\n",
      "./vox_dev_wav/wav/id10018/0gR9vlGI8ro/\n",
      "./vox_dev_wav/wav/id10018/G4ytSwL9uak/\n",
      "./vox_dev_wav/wav/id10018/4UXieX7te0U/\n",
      "./vox_dev_wav/wav/id10018/pJcq28hEvHg/\n",
      "./vox_dev_wav/wav/id10018/BaesL7QJLFU/\n",
      "./vox_dev_wav/wav/id10018/Q7aBwU0ZeUk/\n",
      "./vox_dev_wav/wav/id10018/aDIdItugOC0/\n",
      "./vox_dev_wav/wav/id10018/wyaUcxpHOQs/\n",
      "./vox_dev_wav/wav/id10018/su3ku9D00jA/\n",
      "checking dir: ./vox_dev_wav/wav/id10020/\n",
      "./vox_dev_wav/wav/id10020/jrZbWZ6Y8Jk/\n",
      "./vox_dev_wav/wav/id10020/hun71wPQvlI/\n",
      "./vox_dev_wav/wav/id10020/RSevwDj13_g/\n",
      "./vox_dev_wav/wav/id10020/UilhQH32RHA/\n",
      "./vox_dev_wav/wav/id10020/zFyun6tYFaw/\n",
      "./vox_dev_wav/wav/id10020/986AHSerdyI/\n",
      "./vox_dev_wav/wav/id10020/Tv92FNzH3Qc/\n",
      "./vox_dev_wav/wav/id10020/zHAGrIElkDU/\n",
      "./vox_dev_wav/wav/id10020/aGVMDWHASho/\n",
      "./vox_dev_wav/wav/id10020/xHcXn2RLNS8/\n",
      "./vox_dev_wav/wav/id10020/Gi11Fgbjqdc/\n",
      "./vox_dev_wav/wav/id10020/Sj407D6anmI/\n",
      "./vox_dev_wav/wav/id10020/7H3a2ZhOt1U/\n",
      "./vox_dev_wav/wav/id10020/70e-rrF1NnQ/\n",
      "./vox_dev_wav/wav/id10020/1elTcNGC3q8/\n",
      "./vox_dev_wav/wav/id10020/37HXBdOMKOk/\n",
      "./vox_dev_wav/wav/id10020/HELG9IIqhBE/\n",
      "./vox_dev_wav/wav/id10020/oIn5J6YJAmQ/\n",
      "./vox_dev_wav/wav/id10020/jPGRVcnoOWY/\n",
      "./vox_dev_wav/wav/id10020/NCFG73oAvUE/\n",
      "./vox_dev_wav/wav/id10020/nW-4wrt332E/\n",
      "./vox_dev_wav/wav/id10020/PzSCbADJSzg/\n",
      "./vox_dev_wav/wav/id10020/mcFRwLcBrQA/\n",
      "./vox_dev_wav/wav/id10020/miCK2SKm3XE/\n",
      "./vox_dev_wav/wav/id10020/H_NA9yw_kVE/\n",
      "./vox_dev_wav/wav/id10020/A_blsQbRRC8/\n",
      "./vox_dev_wav/wav/id10020/iNwAECjAAAM/\n",
      "checking dir: ./vox_dev_wav/wav/id10019/\n",
      "./vox_dev_wav/wav/id10019/XYGmvRZiNNg/\n",
      "./vox_dev_wav/wav/id10019/KjHVVTWafJQ/\n",
      "./vox_dev_wav/wav/id10019/cE3StI6Qw0w/\n",
      "./vox_dev_wav/wav/id10019/5AfbbZolonc/\n",
      "./vox_dev_wav/wav/id10019/dCpykP6iJnA/\n",
      "./vox_dev_wav/wav/id10019/IipkRlgAGC0/\n",
      "./vox_dev_wav/wav/id10019/N4ZN6AAv4vU/\n",
      "./vox_dev_wav/wav/id10019/YLTaZK6x2z8/\n",
      "./vox_dev_wav/wav/id10019/nSpt6fRmaV4/\n",
      "./vox_dev_wav/wav/id10019/KPM7HF0Xc18/\n",
      "./vox_dev_wav/wav/id10019/FoACkHPFRTo/\n",
      "./vox_dev_wav/wav/id10019/2vSPFNQoKmk/\n",
      "./vox_dev_wav/wav/id10019/vw9WhRtxRhE/\n",
      "./vox_dev_wav/wav/id10019/ABpVMOt0WEE/\n",
      "./vox_dev_wav/wav/id10019/feJ12-OYVaU/\n",
      "checking dir: ./vox_dev_wav/wav/id10010/\n",
      "./vox_dev_wav/wav/id10010/5ssVY9a5X-M/\n",
      "./vox_dev_wav/wav/id10010/1O_m0G4rf9Q/\n",
      "./vox_dev_wav/wav/id10010/zJHub1wydMw/\n",
      "./vox_dev_wav/wav/id10010/Sw8HigpvVsg/\n",
      "./vox_dev_wav/wav/id10010/fapnl6uxeEw/\n",
      "./vox_dev_wav/wav/id10010/zbFJH6QsV48/\n",
      "./vox_dev_wav/wav/id10010/5xGZ4I9Bltc/\n",
      "./vox_dev_wav/wav/id10010/Fi21gDronE4/\n",
      "./vox_dev_wav/wav/id10010/QlrC83eEY2s/\n",
      "./vox_dev_wav/wav/id10010/LcCFDB7yT6A/\n",
      "./vox_dev_wav/wav/id10010/ik0addgjsVM/\n",
      "./vox_dev_wav/wav/id10010/aVg9a5-hRsw/\n",
      "./vox_dev_wav/wav/id10010/w_dgWRKS91Q/\n",
      "./vox_dev_wav/wav/id10010/E454T_sS_AM/\n",
      "./vox_dev_wav/wav/id10010/GZnnXtImnGA/\n",
      "checking dir: ./vox_dev_wav/wav/id10017/\n",
      "./vox_dev_wav/wav/id10017/CYb_opUpiw4/\n",
      "./vox_dev_wav/wav/id10017/xH3Pp_5yxOk/\n",
      "./vox_dev_wav/wav/id10017/iwN6Hu6xyM0/\n",
      "./vox_dev_wav/wav/id10017/7QOGR0zvTxY/\n",
      "./vox_dev_wav/wav/id10017/pOJlOI5cDZw/\n",
      "./vox_dev_wav/wav/id10017/PynZ3bQ3Ga4/\n",
      "./vox_dev_wav/wav/id10017/uy0-9hpmHJs/\n",
      "./vox_dev_wav/wav/id10017/5VxX7ZI5z5s/\n",
      "./vox_dev_wav/wav/id10017/Pkfu9rKM5QA/\n",
      "./vox_dev_wav/wav/id10017/qFUUDSjCy5M/\n",
      "./vox_dev_wav/wav/id10017/bNNIcOJGy4w/\n",
      "./vox_dev_wav/wav/id10017/6ya9UpdRCPs/\n",
      "./vox_dev_wav/wav/id10017/BuecddErOwU/\n",
      "./vox_dev_wav/wav/id10017/5r-26vNFeJU/\n",
      "./vox_dev_wav/wav/id10017/Px9R6A3XKDM/\n",
      "./vox_dev_wav/wav/id10017/xLakEK2bbQw/\n",
      "./vox_dev_wav/wav/id10017/8rp9UYZp-zA/\n"
     ]
    }
   ],
   "source": [
    "#check source directory and find classes\n",
    "source_dir = './vox_dev_wav/wav/'\n",
    "# source_dir = './audio/'\n",
    "speakers = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "print(speakers)\n",
    "raw = []\n",
    "for speaker in speakers:\n",
    "    path = os.path.join(source_dir, speaker) + '/'\n",
    "    print('checking dir:', path)\n",
    "    folders = [f for f in os.listdir(path) if not f.startswith('.') ]\n",
    "    for folder in folders:\n",
    "        clip_path = os.path.join(path, folder) + '/'\n",
    "        print(clip_path)\n",
    "        clips = [f for f in os.listdir(clip_path) if f.endswith('.wav')]\n",
    "        for clip in clips:\n",
    "            raw.append({'speaker': speaker, 'path':clip_path+clip})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2787, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                             path\n",
       "0  id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav\n",
       "1  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00009.wav\n",
       "2  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00008.wav\n",
       "3  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00006.wav\n",
       "4  id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00007.wav"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw)\n",
    "# df = df[:100]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Feuture Extraction\n",
    "\n",
    "* We split the dataset as 70% train and 30% test. The split is performed per speaker and not the entire dataset\n",
    "* Then, we extract MFCC and Delta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (1950, 2), Test set size (837, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create test dataframe, keep 0.7 of each speaker as train and 0.3 as test\n",
    "train_split = 0.7\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "for id in df['speaker'].unique():\n",
    "    speaker = df.loc[df['speaker'] == id]\n",
    "    #suffle and split dataset\n",
    "    speaker = speaker.sample(frac=1, replace=False, random_state=42)\n",
    "    train_indices = int(round(train_split*len(speaker)))\n",
    "    train = speaker[:train_indices]\n",
    "    test = speaker[:len(speaker) - train_indices]\n",
    "    df_train_list.append(train)\n",
    "    df_test_list.append(test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_test = pd.concat(df_test_list)\n",
    "print(f'Train set size: {df_train.shape}, Test set size {df_test.shape}')\n",
    "\n",
    "# sanity check, check if both train and test sets have same speakers\n",
    "b = set(df_train['speaker'].unique()) == set(df_test['speaker'].unique())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration  \n",
       "0   4.640062  \n",
       "5   5.720063  \n",
       "34  5.640062  \n",
       "13  5.680063  \n",
       "45  6.200062  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample rate and clip duration for every clip\n",
    "df_train[['sr','duration']] = df_train['path'].apply(lambda p: get_audio_info(p))\n",
    "df_test[['sr','duration']] = df_test['path'].apply(lambda p: get_audio_info(p))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sr     duration\n",
      "count   1950.0  1950.000000\n",
      "mean   16000.0     7.688083\n",
      "std        0.0     4.507359\n",
      "min    16000.0     3.960062\n",
      "25%    16000.0     4.840063\n",
      "50%    16000.0     6.240062\n",
      "75%    16000.0     8.960062\n",
      "max    16000.0    61.680062 \n",
      "             sr    duration\n",
      "count    837.0  837.000000\n",
      "mean   16000.0    7.755045\n",
      "std        0.0    4.491689\n",
      "min    16000.0    3.960062\n",
      "25%    16000.0    4.880063\n",
      "50%    16000.0    6.360062\n",
      "75%    16000.0    8.920063\n",
      "max    16000.0   37.280062\n"
     ]
    }
   ],
   "source": [
    "print(f'{df_train.describe()} \\n {df_test.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of mfccs per clip\n",
    "n_mfcc = splits = 13\n",
    "\n",
    "df_train[['mfcc','delta']] = df_train['path'].apply(lambda p: extract_mfcc(p, n_mfcc))\n",
    "df_test[['mfcc','delta']] = df_test['path'].apply(lambda p: extract_mfcc(p, n_mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Zero Crossing Rate\n",
    "df_train[['zcr']] = df_train['path'].apply(lambda p: zero_crossing_rate(p, splits))\n",
    "df_test[['zcr']] = df_test['path'].apply(lambda p: zero_crossing_rate(p, splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>path</th>\n",
       "      <th>sr</th>\n",
       "      <th>duration</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>delta</th>\n",
       "      <th>zcr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>4.640062</td>\n",
       "      <td>[-196.19745, 96.77209, -9.442002, 22.09873, -2...</td>\n",
       "      <td>[-0.29390892, -0.18999796, -0.014305613, 0.165...</td>\n",
       "      <td>[0.06953932387458399, 0.13154668067962866, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.720063</td>\n",
       "      <td>[-385.69135, 122.257576, -14.257886, -23.04002...</td>\n",
       "      <td>[0.08598741, -0.07328853, 0.024153156, 0.01808...</td>\n",
       "      <td>[0.09745702514561727, 0.16309134820286972, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.640062</td>\n",
       "      <td>[-223.81839, 86.769295, -17.60496, 23.541613, ...</td>\n",
       "      <td>[-0.16981685, 0.023842582, 0.12981227, 0.07679...</td>\n",
       "      <td>[0.2788184438040346, 0.25230547550432275, 0.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>5.680063</td>\n",
       "      <td>[-159.21338, 96.507286, -21.005232, 2.2055504,...</td>\n",
       "      <td>[-0.1431608, 0.0911606, 0.027648797, 0.0220658...</td>\n",
       "      <td>[0.14064959221633996, 0.1417942481041637, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id10009</td>\n",
       "      <td>./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>6.200062</td>\n",
       "      <td>[-204.95496, 92.93275, -16.543903, 7.745483, 2...</td>\n",
       "      <td>[-0.039691795, 0.113837615, -0.073666826, -0.0...</td>\n",
       "      <td>[0.19740464018875345, 0.14195831694848604, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             path       sr  \\\n",
       "0   id10009  ./vox_dev_wav/wav/id10009/HCGXIgKsozU/00001.wav  16000.0   \n",
       "5   id10009  ./vox_dev_wav/wav/id10009/AtavJVP4bCk/00005.wav  16000.0   \n",
       "34  id10009  ./vox_dev_wav/wav/id10009/vy8sQ82o0fM/00004.wav  16000.0   \n",
       "13  id10009  ./vox_dev_wav/wav/id10009/seo9TTTEoE4/00002.wav  16000.0   \n",
       "45  id10009  ./vox_dev_wav/wav/id10009/EJ3tyqGqYfw/00001.wav  16000.0   \n",
       "\n",
       "    duration                                               mfcc  \\\n",
       "0   4.640062  [-196.19745, 96.77209, -9.442002, 22.09873, -2...   \n",
       "5   5.720063  [-385.69135, 122.257576, -14.257886, -23.04002...   \n",
       "34  5.640062  [-223.81839, 86.769295, -17.60496, 23.541613, ...   \n",
       "13  5.680063  [-159.21338, 96.507286, -21.005232, 2.2055504,...   \n",
       "45  6.200062  [-204.95496, 92.93275, -16.543903, 7.745483, 2...   \n",
       "\n",
       "                                                delta  \\\n",
       "0   [-0.29390892, -0.18999796, -0.014305613, 0.165...   \n",
       "5   [0.08598741, -0.07328853, 0.024153156, 0.01808...   \n",
       "34  [-0.16981685, 0.023842582, 0.12981227, 0.07679...   \n",
       "13  [-0.1431608, 0.0911606, 0.027648797, 0.0220658...   \n",
       "45  [-0.039691795, 0.113837615, -0.073666826, -0.0...   \n",
       "\n",
       "                                                  zcr  \n",
       "0   [0.06953932387458399, 0.13154668067962866, 0.0...  \n",
       "5   [0.09745702514561727, 0.16309134820286972, 0.0...  \n",
       "34  [0.2788184438040346, 0.25230547550432275, 0.25...  \n",
       "13  [0.14064959221633996, 0.1417942481041637, 0.10...  \n",
       "45  [0.19740464018875345, 0.14195831694848604, 0.1...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers is 20\n",
      "<class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "Train set size: (1365, 39), Validation set size (585, 39)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# keep mfcc and delta and zero crossing rate columns\n",
    "X = df_train.iloc[:,4:7]\n",
    "# keep speaker colum\n",
    "y = df_train.iloc[:,0]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y))\n",
    "num_labels=len(list(le.classes_))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "print(f'Number of speakers is {num_labels}')\n",
    "# save label encoder to file\n",
    "np.save('saved_models/classes.npy', le.classes_)\n",
    "print(type(le))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "X_train = np.hstack((X_train['mfcc'].to_list(),X_train['delta'].to_list(), X_train['zcr'].to_list()))\n",
    "X_val = np.hstack((X_val['mfcc'].to_list(), X_val['delta'].to_list(), X_val['zcr'].to_list()))\n",
    "print(f'Train set size: {X_train.shape}, Validation set size {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 100)               4000      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 46,320\n",
      "Trainable params: 46,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "43/43 [==============================] - 1s 6ms/step - loss: 16.9147 - accuracy: 0.0777 - val_loss: 2.8245 - val_accuracy: 0.2274\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.82449, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 2/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 4.4246 - accuracy: 0.0864 - val_loss: 2.9782 - val_accuracy: 0.1094\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.82449\n",
      "Epoch 3/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 3.3050 - accuracy: 0.1018 - val_loss: 2.9632 - val_accuracy: 0.2017\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.82449\n",
      "Epoch 4/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 3.0541 - accuracy: 0.1355 - val_loss: 2.9476 - val_accuracy: 0.2103\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.82449\n",
      "Epoch 5/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 3.0065 - accuracy: 0.1597 - val_loss: 2.9332 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.82449\n",
      "Epoch 6/250\n",
      "43/43 [==============================] - 1s 20ms/step - loss: 2.9671 - accuracy: 0.1736 - val_loss: 2.9196 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.82449\n",
      "Epoch 7/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 2.9440 - accuracy: 0.1905 - val_loss: 2.9019 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.82449\n",
      "Epoch 8/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 2.9112 - accuracy: 0.1817 - val_loss: 2.8762 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.82449\n",
      "Epoch 9/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.8404 - accuracy: 0.1971 - val_loss: 2.7909 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.82449 to 2.79093, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 10/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.7780 - accuracy: 0.1993 - val_loss: 2.5335 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.79093 to 2.53345, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 11/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.6886 - accuracy: 0.2000 - val_loss: 2.4677 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.53345 to 2.46771, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 12/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.6622 - accuracy: 0.2037 - val_loss: 2.4205 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.46771 to 2.42046, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 13/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.5912 - accuracy: 0.2066 - val_loss: 2.3809 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.42046 to 2.38087, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 14/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5671 - accuracy: 0.2132 - val_loss: 2.3376 - val_accuracy: 0.2188\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.38087 to 2.33758, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 15/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5288 - accuracy: 0.2256 - val_loss: 2.3320 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.33758 to 2.33202, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 16/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4972 - accuracy: 0.2652 - val_loss: 2.3282 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.33202 to 2.32823, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 17/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4727 - accuracy: 0.2725 - val_loss: 2.3184 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.32823 to 2.31842, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 18/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4396 - accuracy: 0.2872 - val_loss: 2.3150 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.31842 to 2.31497, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 19/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4432 - accuracy: 0.2806 - val_loss: 2.3089 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.31497 to 2.30887, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 20/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4235 - accuracy: 0.2872 - val_loss: 2.3088 - val_accuracy: 0.2974\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.30887 to 2.30880, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 21/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3954 - accuracy: 0.2916 - val_loss: 2.3179 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.30880\n",
      "Epoch 22/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4090 - accuracy: 0.2872 - val_loss: 2.3098 - val_accuracy: 0.2991\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.30880\n",
      "Epoch 23/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3873 - accuracy: 0.2894 - val_loss: 2.2942 - val_accuracy: 0.3026\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.30880 to 2.29420, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 24/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3701 - accuracy: 0.2916 - val_loss: 2.2934 - val_accuracy: 0.3009\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.29420 to 2.29336, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 25/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3779 - accuracy: 0.2938 - val_loss: 2.2976 - val_accuracy: 0.3009\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.29336\n",
      "Epoch 26/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3529 - accuracy: 0.2952 - val_loss: 2.2761 - val_accuracy: 0.3043\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.29336 to 2.27612, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 27/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.3555 - accuracy: 0.2982 - val_loss: 2.2618 - val_accuracy: 0.3162\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.27612 to 2.26178, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 28/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3565 - accuracy: 0.3011 - val_loss: 2.2724 - val_accuracy: 0.3094\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.26178\n",
      "Epoch 29/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3251 - accuracy: 0.2982 - val_loss: 2.2573 - val_accuracy: 0.3197\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.26178 to 2.25734, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 30/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3194 - accuracy: 0.2967 - val_loss: 2.2419 - val_accuracy: 0.3248\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.25734 to 2.24195, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 31/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2804 - accuracy: 0.3121 - val_loss: 2.2278 - val_accuracy: 0.3316\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.24195 to 2.22778, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 32/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 2.2962 - accuracy: 0.3062 - val_loss: 2.2349 - val_accuracy: 0.3179\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.22778\n",
      "Epoch 33/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.2874 - accuracy: 0.3128 - val_loss: 2.2071 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.22778 to 2.20711, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 34/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2636 - accuracy: 0.3201 - val_loss: 2.1977 - val_accuracy: 0.3231\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.20711 to 2.19768, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 35/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2630 - accuracy: 0.3106 - val_loss: 2.1984 - val_accuracy: 0.3231\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.19768\n",
      "Epoch 36/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 2.2268 - accuracy: 0.3326 - val_loss: 2.1736 - val_accuracy: 0.3368\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.19768 to 2.17364, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 37/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2099 - accuracy: 0.3238 - val_loss: 2.1212 - val_accuracy: 0.3538\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.17364 to 2.12125, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 38/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1863 - accuracy: 0.3363 - val_loss: 2.1048 - val_accuracy: 0.3504\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.12125 to 2.10484, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 39/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1441 - accuracy: 0.3487 - val_loss: 2.0766 - val_accuracy: 0.3761\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.10484 to 2.07660, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 40/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.1575 - accuracy: 0.3436 - val_loss: 2.0477 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.07660 to 2.04766, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 41/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0779 - accuracy: 0.3568 - val_loss: 1.9551 - val_accuracy: 0.3966\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.04766 to 1.95514, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 42/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0605 - accuracy: 0.3714 - val_loss: 1.9573 - val_accuracy: 0.3932\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.95514\n",
      "Epoch 43/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0271 - accuracy: 0.3692 - val_loss: 1.8778 - val_accuracy: 0.4120\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.95514 to 1.87777, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 44/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9276 - accuracy: 0.4029 - val_loss: 1.8108 - val_accuracy: 0.4513\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.87777 to 1.81080, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 45/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9210 - accuracy: 0.4073 - val_loss: 1.6991 - val_accuracy: 0.4855\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.81080 to 1.69913, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 46/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8905 - accuracy: 0.4081 - val_loss: 1.6591 - val_accuracy: 0.4786\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.69913 to 1.65909, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 47/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7965 - accuracy: 0.4374 - val_loss: 1.6202 - val_accuracy: 0.4991\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.65909 to 1.62016, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 48/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7949 - accuracy: 0.4447 - val_loss: 1.5808 - val_accuracy: 0.5265\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.62016 to 1.58077, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 49/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7763 - accuracy: 0.4542 - val_loss: 1.5543 - val_accuracy: 0.5402\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.58077 to 1.55426, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 50/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7196 - accuracy: 0.4674 - val_loss: 1.4887 - val_accuracy: 0.5436\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.55426 to 1.48869, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 51/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6796 - accuracy: 0.4725 - val_loss: 1.4210 - val_accuracy: 0.5675\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.48869 to 1.42103, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 52/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.6301 - accuracy: 0.4879 - val_loss: 1.4640 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.42103\n",
      "Epoch 53/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5965 - accuracy: 0.4989 - val_loss: 1.3718 - val_accuracy: 0.5966\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.42103 to 1.37179, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 54/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5527 - accuracy: 0.5062 - val_loss: 1.3204 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.37179 to 1.32042, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 55/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5418 - accuracy: 0.5209 - val_loss: 1.3052 - val_accuracy: 0.6205\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.32042 to 1.30516, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 56/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4994 - accuracy: 0.5473 - val_loss: 1.3161 - val_accuracy: 0.6068\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.30516\n",
      "Epoch 57/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4785 - accuracy: 0.5304 - val_loss: 1.2541 - val_accuracy: 0.6239\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.30516 to 1.25408, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 58/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4887 - accuracy: 0.5399 - val_loss: 1.2389 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.25408 to 1.23892, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 59/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3893 - accuracy: 0.5575 - val_loss: 1.2150 - val_accuracy: 0.6359\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.23892 to 1.21502, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 60/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4463 - accuracy: 0.5502 - val_loss: 1.2207 - val_accuracy: 0.6376\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.21502\n",
      "Epoch 61/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3669 - accuracy: 0.5744 - val_loss: 1.1904 - val_accuracy: 0.6496\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.21502 to 1.19037, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 62/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3238 - accuracy: 0.5707 - val_loss: 1.1588 - val_accuracy: 0.6632\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.19037 to 1.15877, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 63/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3184 - accuracy: 0.5846 - val_loss: 1.0925 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.15877 to 1.09251, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 64/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.5736 - val_loss: 1.1215 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.09251\n",
      "Epoch 65/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2880 - accuracy: 0.5956 - val_loss: 1.0684 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.09251 to 1.06837, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 66/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2867 - accuracy: 0.5949 - val_loss: 1.0637 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.06837 to 1.06368, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 67/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2127 - accuracy: 0.6190 - val_loss: 1.0557 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.06368 to 1.05567, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 68/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1808 - accuracy: 0.6264 - val_loss: 1.0178 - val_accuracy: 0.7026\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.05567 to 1.01778, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 69/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1910 - accuracy: 0.6242 - val_loss: 1.0265 - val_accuracy: 0.6889\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.01778\n",
      "Epoch 70/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2226 - accuracy: 0.6088 - val_loss: 1.0072 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.01778 to 1.00721, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 71/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1987 - accuracy: 0.6330 - val_loss: 1.0239 - val_accuracy: 0.6957\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.00721\n",
      "Epoch 72/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1420 - accuracy: 0.6418 - val_loss: 0.9867 - val_accuracy: 0.6957\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.00721 to 0.98672, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 73/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1584 - accuracy: 0.6308 - val_loss: 0.9926 - val_accuracy: 0.6906\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.98672\n",
      "Epoch 74/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1299 - accuracy: 0.6601 - val_loss: 0.9406 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.98672 to 0.94057, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 75/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.6681 - val_loss: 0.9133 - val_accuracy: 0.7299\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.94057 to 0.91335, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 76/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1297 - accuracy: 0.6447 - val_loss: 0.9505 - val_accuracy: 0.7128\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.91335\n",
      "Epoch 77/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0878 - accuracy: 0.6440 - val_loss: 0.9197 - val_accuracy: 0.7316\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.91335\n",
      "Epoch 78/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0665 - accuracy: 0.6498 - val_loss: 0.9296 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.91335\n",
      "Epoch 79/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0889 - accuracy: 0.6513 - val_loss: 0.9130 - val_accuracy: 0.7179\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.91335 to 0.91298, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 80/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9920 - accuracy: 0.6674 - val_loss: 0.8594 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.91298 to 0.85944, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 81/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9948 - accuracy: 0.6777 - val_loss: 0.8560 - val_accuracy: 0.7436\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.85944 to 0.85603, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 82/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0040 - accuracy: 0.6894 - val_loss: 0.8696 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.85603\n",
      "Epoch 83/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9622 - accuracy: 0.6747 - val_loss: 0.8526 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.85603 to 0.85265, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 84/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.6879 - val_loss: 0.8437 - val_accuracy: 0.7179\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.85265 to 0.84374, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 85/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9540 - accuracy: 0.6916 - val_loss: 0.8770 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.84374\n",
      "Epoch 86/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9267 - accuracy: 0.7033 - val_loss: 0.8161 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.84374 to 0.81611, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 87/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8931 - accuracy: 0.7187 - val_loss: 0.8171 - val_accuracy: 0.7402\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.81611\n",
      "Epoch 88/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9432 - accuracy: 0.7121 - val_loss: 0.8128 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.81611 to 0.81277, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 89/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8879 - accuracy: 0.7223 - val_loss: 0.8355 - val_accuracy: 0.7350\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.81277\n",
      "Epoch 90/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8696 - accuracy: 0.7092 - val_loss: 0.7814 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.81277 to 0.78136, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 91/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8829 - accuracy: 0.7143 - val_loss: 0.7756 - val_accuracy: 0.7675\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.78136 to 0.77558, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 92/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.9083 - accuracy: 0.7121 - val_loss: 0.7937 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.77558\n",
      "Epoch 93/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8659 - accuracy: 0.7238 - val_loss: 0.7889 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.77558\n",
      "Epoch 94/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8838 - accuracy: 0.7209 - val_loss: 0.7896 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.77558\n",
      "Epoch 95/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8312 - accuracy: 0.7304 - val_loss: 0.7329 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.77558 to 0.73288, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 96/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.7077 - val_loss: 0.7971 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.73288\n",
      "Epoch 97/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8772 - accuracy: 0.7106 - val_loss: 0.7521 - val_accuracy: 0.7709\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.73288\n",
      "Epoch 98/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.7451 - val_loss: 0.7285 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.73288 to 0.72851, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 99/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.8097 - accuracy: 0.7363 - val_loss: 0.7242 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.72851 to 0.72418, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 100/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7929 - accuracy: 0.7465 - val_loss: 0.7714 - val_accuracy: 0.7573\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.72418\n",
      "Epoch 101/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.8238 - accuracy: 0.7355 - val_loss: 0.7399 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.72418\n",
      "Epoch 102/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.7544 - accuracy: 0.7634 - val_loss: 0.7234 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.72418 to 0.72336, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 103/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.7569 - accuracy: 0.7524 - val_loss: 0.7140 - val_accuracy: 0.7897\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.72336 to 0.71399, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 104/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7833 - accuracy: 0.7487 - val_loss: 0.7432 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.71399\n",
      "Epoch 105/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7815 - accuracy: 0.7516 - val_loss: 0.7344 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.71399\n",
      "Epoch 106/250\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.7745 - accuracy: 0.7678 - val_loss: 0.7397 - val_accuracy: 0.7761\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.71399\n",
      "Epoch 107/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.7424 - accuracy: 0.7458 - val_loss: 0.7061 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.71399 to 0.70609, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 108/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.7745 - accuracy: 0.7370 - val_loss: 0.7210 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.70609\n",
      "Epoch 109/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7250 - accuracy: 0.7597 - val_loss: 0.7060 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.70609 to 0.70595, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 110/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.7604 - val_loss: 0.7273 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.70595\n",
      "Epoch 111/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.7143 - accuracy: 0.7612 - val_loss: 0.6940 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.70595 to 0.69402, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 112/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.7463 - accuracy: 0.7648 - val_loss: 0.7209 - val_accuracy: 0.7692\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.69402\n",
      "Epoch 113/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.7619 - val_loss: 0.7032 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.69402\n",
      "Epoch 114/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.7634 - val_loss: 0.6803 - val_accuracy: 0.7932\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.69402 to 0.68030, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 115/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7058 - accuracy: 0.7700 - val_loss: 0.6983 - val_accuracy: 0.7829\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.68030\n",
      "Epoch 116/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.7839 - val_loss: 0.6657 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.68030 to 0.66570, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 117/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6677 - accuracy: 0.7795 - val_loss: 0.6702 - val_accuracy: 0.7983\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.66570\n",
      "Epoch 118/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.7832 - val_loss: 0.6625 - val_accuracy: 0.7744\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.66570 to 0.66246, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 119/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.7729 - val_loss: 0.6694 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.66246\n",
      "Epoch 120/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.7516 - accuracy: 0.7531 - val_loss: 0.6686 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.66246\n",
      "Epoch 121/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7766 - val_loss: 0.6648 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.66246\n",
      "Epoch 122/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.6508 - accuracy: 0.7766 - val_loss: 0.6462 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.66246 to 0.64617, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 123/250\n",
      "43/43 [==============================] - 1s 15ms/step - loss: 0.6469 - accuracy: 0.7868 - val_loss: 0.6172 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.64617 to 0.61724, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 124/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.7890 - val_loss: 0.6374 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.61724\n",
      "Epoch 125/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6425 - accuracy: 0.7912 - val_loss: 0.6601 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.61724\n",
      "Epoch 126/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.7941 - val_loss: 0.6654 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.61724\n",
      "Epoch 127/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.7868 - val_loss: 0.6277 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.61724\n",
      "Epoch 128/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.6451 - accuracy: 0.7853 - val_loss: 0.6623 - val_accuracy: 0.7949\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.61724\n",
      "Epoch 129/250\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.6329 - accuracy: 0.7817 - val_loss: 0.6756 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.61724\n",
      "Epoch 130/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7971 - val_loss: 0.6360 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.61724\n",
      "Epoch 131/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.7963 - val_loss: 0.6414 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.61724\n",
      "Epoch 132/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.8066 - val_loss: 0.6470 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.61724\n",
      "Epoch 133/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.7971 - val_loss: 0.6428 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.61724\n",
      "Epoch 134/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.7817 - val_loss: 0.6421 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.61724\n",
      "Epoch 135/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7927 - val_loss: 0.6817 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.61724\n",
      "Epoch 136/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.7905 - val_loss: 0.6069 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.61724 to 0.60690, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 137/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.8190 - val_loss: 0.6316 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.60690\n",
      "Epoch 138/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.8044 - val_loss: 0.6383 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.60690\n",
      "Epoch 139/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.8110 - val_loss: 0.6319 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.60690\n",
      "Epoch 140/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.8029 - val_loss: 0.6278 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.60690\n",
      "Epoch 141/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.7868 - val_loss: 0.6255 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.60690\n",
      "Epoch 142/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.8059 - val_loss: 0.6320 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.60690\n",
      "Epoch 143/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.8000 - val_loss: 0.6013 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.60690 to 0.60133, saving model to saved_models/speakers_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8190 - val_loss: 0.6110 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.60133\n",
      "Epoch 145/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8212 - val_loss: 0.6354 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.60133\n",
      "Epoch 146/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.8103 - val_loss: 0.6414 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.60133\n",
      "Epoch 147/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.8029 - val_loss: 0.6099 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.60133\n",
      "Epoch 148/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8176 - val_loss: 0.6072 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.60133\n",
      "Epoch 149/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.8271 - val_loss: 0.6024 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.60133\n",
      "Epoch 150/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8088 - val_loss: 0.6012 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.60133 to 0.60115, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 151/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8249 - val_loss: 0.6085 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.60115\n",
      "Epoch 152/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.8249 - val_loss: 0.5906 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.60115 to 0.59059, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 153/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.8212 - val_loss: 0.6075 - val_accuracy: 0.8034\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.59059\n",
      "Epoch 154/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8271 - val_loss: 0.5904 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.59059 to 0.59043, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 155/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.8256 - val_loss: 0.5849 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.59043 to 0.58487, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 156/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.8037 - val_loss: 0.5863 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.58487\n",
      "Epoch 157/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.8168 - val_loss: 0.5831 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.58487 to 0.58314, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 158/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.8227 - val_loss: 0.5979 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.58314\n",
      "Epoch 159/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.8286 - val_loss: 0.5643 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.58314 to 0.56425, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 160/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.8242 - val_loss: 0.6175 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.56425\n",
      "Epoch 161/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8205 - val_loss: 0.6235 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.56425\n",
      "Epoch 162/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8249 - val_loss: 0.6230 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.56425\n",
      "Epoch 163/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.8234 - val_loss: 0.5919 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.56425\n",
      "Epoch 164/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.8198 - val_loss: 0.5806 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.56425\n",
      "Epoch 165/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8352 - val_loss: 0.5988 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.56425\n",
      "Epoch 166/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.8227 - val_loss: 0.6259 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.56425\n",
      "Epoch 167/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8315 - val_loss: 0.5476 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.56425 to 0.54756, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 168/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8454 - val_loss: 0.6058 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.54756\n",
      "Epoch 169/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.8440 - val_loss: 0.6000 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.54756\n",
      "Epoch 170/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8256 - val_loss: 0.6029 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.54756\n",
      "Epoch 171/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8425 - val_loss: 0.5716 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.54756\n",
      "Epoch 172/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.8396 - val_loss: 0.6232 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.54756\n",
      "Epoch 173/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8396 - val_loss: 0.5827 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.54756\n",
      "Epoch 174/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.8593 - val_loss: 0.5627 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.54756\n",
      "Epoch 175/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8293 - val_loss: 0.5651 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.54756\n",
      "Epoch 176/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8278 - val_loss: 0.5711 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.54756\n",
      "Epoch 177/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.8344 - val_loss: 0.5633 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.54756\n",
      "Epoch 178/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8388 - val_loss: 0.5713 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.54756\n",
      "Epoch 179/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8579 - val_loss: 0.5656 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.54756\n",
      "Epoch 180/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8498 - val_loss: 0.5711 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.54756\n",
      "Epoch 181/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8542 - val_loss: 0.6295 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.54756\n",
      "Epoch 182/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8432 - val_loss: 0.6260 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.54756\n",
      "Epoch 183/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.8505 - val_loss: 0.5727 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.54756\n",
      "Epoch 184/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8381 - val_loss: 0.5661 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.54756\n",
      "Epoch 185/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8462 - val_loss: 0.5603 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.54756\n",
      "Epoch 186/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8557 - val_loss: 0.5700 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.54756\n",
      "Epoch 187/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8542 - val_loss: 0.5824 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.54756\n",
      "Epoch 188/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.8432 - val_loss: 0.5793 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.54756\n",
      "Epoch 189/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8484 - val_loss: 0.5805 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.54756\n",
      "Epoch 190/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.8440 - val_loss: 0.5787 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.54756\n",
      "Epoch 191/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8484 - val_loss: 0.6158 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.54756\n",
      "Epoch 192/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8440 - val_loss: 0.6112 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.54756\n",
      "Epoch 193/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8557 - val_loss: 0.6265 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.54756\n",
      "Epoch 194/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.8454 - val_loss: 0.5827 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.54756\n",
      "Epoch 195/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8469 - val_loss: 0.5873 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.54756\n",
      "Epoch 196/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8454 - val_loss: 0.5990 - val_accuracy: 0.8120\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.54756\n",
      "Epoch 197/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8623 - val_loss: 0.5930 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.54756\n",
      "Epoch 198/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.8403 - val_loss: 0.5968 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.54756\n",
      "Epoch 199/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8447 - val_loss: 0.5670 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.54756\n",
      "Epoch 200/250\n",
      "43/43 [==============================] - 1s 14ms/step - loss: 0.4472 - accuracy: 0.8579 - val_loss: 0.5779 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.54756\n",
      "Epoch 201/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.8447 - val_loss: 0.5566 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.54756\n",
      "Epoch 202/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8469 - val_loss: 0.5537 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.54756\n",
      "Epoch 203/250\n",
      "43/43 [==============================] - 1s 17ms/step - loss: 0.4292 - accuracy: 0.8645 - val_loss: 0.5907 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.54756\n",
      "Epoch 204/250\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.4386 - accuracy: 0.8667 - val_loss: 0.5797 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.54756\n",
      "Epoch 205/250\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.4355 - accuracy: 0.8447 - val_loss: 0.5586 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.54756\n",
      "Epoch 206/250\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.4283 - accuracy: 0.8586 - val_loss: 0.5741 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.54756\n",
      "Epoch 207/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.3941 - accuracy: 0.8769 - val_loss: 0.5861 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.54756\n",
      "Epoch 208/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8557 - val_loss: 0.5860 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.54756\n",
      "Epoch 209/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8637 - val_loss: 0.5715 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.54756\n",
      "Epoch 210/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.8586 - val_loss: 0.5988 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.54756\n",
      "Epoch 211/250\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.8469 - val_loss: 0.5975 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.54756\n",
      "Epoch 212/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8762 - val_loss: 0.5608 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.54756\n",
      "Epoch 213/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8549 - val_loss: 0.5679 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.54756\n",
      "Epoch 214/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.8469 - val_loss: 0.5907 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.54756\n",
      "Epoch 215/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8462 - val_loss: 0.5758 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.54756\n",
      "Epoch 216/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8542 - val_loss: 0.5849 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.54756\n",
      "Epoch 217/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8630 - val_loss: 0.5699 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.54756\n",
      "Epoch 218/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8623 - val_loss: 0.5436 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.54756 to 0.54362, saving model to saved_models/speakers_classification.hdf5\n",
      "Epoch 219/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8645 - val_loss: 0.5985 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.54362\n",
      "Epoch 220/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8703 - val_loss: 0.5649 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.54362\n",
      "Epoch 221/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8593 - val_loss: 0.5980 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.54362\n",
      "Epoch 222/250\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.4130 - accuracy: 0.8674 - val_loss: 0.5764 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.54362\n",
      "Epoch 223/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8777 - val_loss: 0.6086 - val_accuracy: 0.8137\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.54362\n",
      "Epoch 224/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.4520 - accuracy: 0.8689 - val_loss: 0.5659 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.54362\n",
      "Epoch 225/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8740 - val_loss: 0.5861 - val_accuracy: 0.8325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00225: val_loss did not improve from 0.54362\n",
      "Epoch 226/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8652 - val_loss: 0.6012 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.54362\n",
      "Epoch 227/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3676 - accuracy: 0.8769 - val_loss: 0.5820 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.54362\n",
      "Epoch 228/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8799 - val_loss: 0.5697 - val_accuracy: 0.8325\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.54362\n",
      "Epoch 229/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8623 - val_loss: 0.6320 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.54362\n",
      "Epoch 230/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.8615 - val_loss: 0.6014 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.54362\n",
      "Epoch 231/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8491 - val_loss: 0.6183 - val_accuracy: 0.8154\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.54362\n",
      "Epoch 232/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8711 - val_loss: 0.5794 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.54362\n",
      "Epoch 233/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8696 - val_loss: 0.5922 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.54362\n",
      "Epoch 234/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8652 - val_loss: 0.6362 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.54362\n",
      "Epoch 235/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8674 - val_loss: 0.5930 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.54362\n",
      "Epoch 236/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8593 - val_loss: 0.6103 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.54362\n",
      "Epoch 237/250\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.8615 - val_loss: 0.5786 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.54362\n",
      "Epoch 238/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8711 - val_loss: 0.5995 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.54362\n",
      "Epoch 239/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8821 - val_loss: 0.6493 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.54362\n",
      "Epoch 240/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8747 - val_loss: 0.5808 - val_accuracy: 0.8274\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.54362\n",
      "Epoch 241/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8703 - val_loss: 0.6221 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.54362\n",
      "Epoch 242/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8850 - val_loss: 0.6011 - val_accuracy: 0.8308\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.54362\n",
      "Epoch 243/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3431 - accuracy: 0.8982 - val_loss: 0.5863 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.54362\n",
      "Epoch 244/250\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8696 - val_loss: 0.6310 - val_accuracy: 0.8342\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.54362\n",
      "Epoch 245/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8718 - val_loss: 0.5909 - val_accuracy: 0.8410\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.54362\n",
      "Epoch 246/250\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.3498 - accuracy: 0.8799 - val_loss: 0.5945 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.54362\n",
      "Epoch 247/250\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8799 - val_loss: 0.6388 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.54362\n",
      "Epoch 248/250\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8755 - val_loss: 0.6351 - val_accuracy: 0.8291\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.54362\n",
      "Epoch 249/250\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8681 - val_loss: 0.5635 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.54362\n",
      "Epoch 250/250\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3662 - accuracy: 0.8740 - val_loss: 0.5717 - val_accuracy: 0.8496\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.54362\n",
      "Training completed in time:  0:00:57.027681\n"
     ]
    }
   ],
   "source": [
    "## Train model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 250\n",
    "num_batch_size = 32\n",
    "\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50)\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/speakers_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model_h = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, \n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer, earlystopping], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFZCAYAAABjUBJJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABwNUlEQVR4nO3dd3xb1f3/8deRLFvee8VxYmfvQZwEEkZCWGWvMkopo4W2X+iilEIXXb9uOmihLVDKKKPMsjdJCEnI3jvO8Ij33kM6vz+kOM52wLZs+f18PPKIdHWl+7m2fP3x0ed8jrHWIiIiIiIiR+cIdAAiIiIiIn2dkmYRERERkeNQ0iwiIiIichxKmkVEREREjkNJs4iIiIjIcShpFhERERE5DiXNIiIDlDHmUWNMqTFm41EeN8aY+40xO40x640xJ/V2jCIifYWSZhGRgesx4LxjPP45YKT/363A33shJhGRPklJs4jIAGWt/QioPMYulwBPWJ9PgDhjTHrvRCci0reEBDqArkhKSrJZWVmBDkNE5IStWrWq3FqbHOg4PqUMIL/T/QL/tqJDdzTG3IpvNJrIyMhpY8aM6ZUARUS629Gu2/0iac7KymLlypWBDkNE5IQZY/YGOobeYK19CHgIICcnx+qaLSL91dGu2yrPEBGRoykEMjvdH+zfJiIy4ChpFhGRo3kV+JK/i8bJQI219rDSDBGRgaBflGeIiEj3M8Y8A8wBkowxBcC9gAvAWvsP4E3gfGAn0AjcFJhIRUQCT0mziPSYtrY2CgoKaG5uDnQoPc7tdjN48GBcLlegQ+kya+21x3ncArd1x7H0XhCR/k5Js4j0mIKCAqKjo8nKysIYE+hweoy1loqKCgoKCsjOzg50OH2S3gsi0t+ppllEekxzczOJiYlBnSQBGGNITEwcEKOon5beCyLS3ylpFpEeFexJ0n4D5Tw/i4HyNRoo5yky0ChpFhERERE5DiXNIhK0KioqmDJlClOmTCEtLY2MjIyO+62trcd87sqVK/nmN7/ZS5FKT9N7QUQ+K00EFJGglZiYyNq1awH46U9/SlRUFHfeeWfH4+3t7YSEHPkymJOTQ05OTm+EKb1A7wUR+aw00iwiA8qNN97I1772NWbOnMldd93F8uXLOeWUU5g6dSqzZs1i27ZtACxYsIALL7wQ8CVZN998M3PmzGHYsGHcf//9gTwF6SZ6L4jIiQjakeZ7XtrAaSOTOH9ieqBDERHgZ69tYvO+2m59zXGDYrj3ovEn/LyCggKWLFmC0+mktraWRYsWERISwvvvv88PfvADXnzxxcOes3XrVubPn09dXR2jR4/m61//uvrwfkp6L4hIfxS0SfNLqwuICQ9R0iwih/n85z+P0+kEoKamhhtuuIEdO3ZgjKGtre2Iz7ngggsICwsjLCyMlJQUSkpKGDx4cG+GLT1A7wUR6aqgTZqNAWsDHYWI7PdpRgF7SmRkZMftH//4x8ydO5eXX36ZPXv2MGfOnCM+JywsrOO20+mkvb29p8MMWnoviEh/FLQ1zQaDVdYsIsdRU1NDRkYGAI899lhgg5GA0ntBRI4laJNmh0aaRaQL7rrrLu655x6mTp2qEcMBTu8FETkW0x9GY3NycuzKlStP6DkT7n2Hq3Iy+clF43ooKhE5ni1btjB27NhAh9FrjnS+xphV1toB1a/sSNdsvRdEpL842nU7aEeaDWDp+38QiIiIiEjfF7xJs8ozRERERKSbBHHSrImAIiIiItI9gjZpdhhUnCEiIiIi3SJok2ZjDF6NNIuIiIhINwjepBnVNIuIiIhI9wjepNkYlWeIDHBz587lnXfeOWjbn//8Z77+9a8fcf85c+Zwou0tpX/Qe0FEPqseS5qNMY8aY0qNMRsP2f4NY8xWY8wmY8zveu74aCKgyAB37bXX8uyzzx607dlnn+Xaa68NUEQSKHoviMhn1ZMjzY8B53XeYIyZC1wCTLbWjgf+0FMHV3mGiFx55ZW88cYbtLa2ArBnzx727dvHM888Q05ODuPHj+fee+8NcJTSG/ReEJHPKqSnXtha+5ExJuuQzV8HfmOtbfHvU9pTx3cYo6RZpI+5+p9LD9t24aR0rj8li6ZWDzf+e/lhj185bTCfz8mksqGVr/9n1UGP/ferpxzzeAkJCcyYMYO33nqLSy65hGeffZarrrqKH/zgByQkJODxeJg3bx7r169n0qRJn+3k5ITovSAi/U1v1zSPAk4zxiwzxiw0xkw/2o7GmFuNMSuNMSvLyspO+EDGoO4ZInLQx/L7P45/7rnnOOmkk5g6dSqbNm1i8+bNAY5SeoPeCyLBo6yuhZrGtl49Zo+NNB/jeAnAycB04DljzDB7hOJja+1DwEMAOTk5J5z9+pbRFpG+5FijgeGhzmM+nhAZetzRxCO55JJL+M53vsPq1atpbGwkISGBP/zhD6xYsYL4+HhuvPFGmpubT/h15bPRe0FEPosvPrKMkalR/O0LJ/XaMXt7pLkAeMn6LAe8QFJPHMioPENEgKioKObOncvNN9/MtddeS21tLZGRkcTGxlJSUsJbb70V6BCll+i9IBIcCqub2FZSx46S+l49bm+PNP8PmAvMN8aMAkKB8p44kLpniMh+1157LZdddhnPPvssY8aMYerUqYwZM4bMzExmz54d6PCkF+m9INL/fbzDV7abV9mItRZjTK8ct8eSZmPMM8AcIMkYUwDcCzwKPOpvQ9cK3HCk0ozu4FCfZhHxu/TSSw/6I/qxxx474n4LFizonYAkYPReEOn/Fu3wjbc2tXmoaGglKSqsV47bk90zjtb88os9dczONBFQREREpP9rbffy8poCLp2agcvhYEluBUlRYZTXt5BX2dhrSXPwrgiI+jSLiIiIBFJFfQte74GEzFrLvxfv5tvPrjlo+7H8b00h339xA48t3sPmoloqG1q5KmcwAPmVjXy4tYRz/rSQq/+5lH3VTT1yHhDESbPKM0T6hoEyt2CgnOdnMVC+RgPlPCW43fn8Ov703vaDtlU1tHLHf9d2udVbeX0Lp/52Pn9fmIvHa/F6LQ8uyOVnr23mf2v3sau8axP5Xlu/D4B/LMzlnU3FAFwzfQgAeysa+c1bW6ltamfzvlpufmwFja3t7Cyt6/afxaBNmlF5hkjAud1uKioqgj6JsNZSUVGB2+0OdCh9lt4LIv1Hm8fLa+v2dSSo+y3JreClNYUs2tm19TNeW7ePpjYPjy3Zw0V//Zg7X1jHf1fkkxztK6dYm1/TsW9RTRNNrZ7DXqO8voUluRWcMSqZqsY2Hpi/k9Gp0QxJjCA5OoyHP9rF9pJ6vv+50fz1C1PZWlzHL9/YwkV/Xcyf3t/xGb4Kh+vt7hm9xoAaNYsE2ODBgykoKODTLFDU37jdbgYPHhzoMPosvRdE+o/tJXW0tHvJLaunzePF5fSNseZXNQKwrbiOC4+ycObr6/fxs9c288Y3T+Wl1YVEh4VQVtdCWV0Lm4tqAfh/l03g129uZW1+FVdOG0x9Sztn/mEhIQ7Djy8cx6VTM/Bai9vl5I31RXi8lrs/N4YZ2Qn8/p1tnDrS1604LtzFjroWhiVFcuGkQbicDuaNSeHpZXlEhjq5enpmt35dgjZp9pVnKGsWCSSXy0V2dnagw5A+QO8Fkb7LWsszy/N5Yuke7rtqMhsKfCPAbR7LrrIGRqZE4XAY8it9SfOWorojvk5FfQs//t9Gqhrb+MM729hQWMOPLhjLst2VDEuK5JGPd+O1lnPHp/HG+iLW5lcDviS9qc1DRlw4d7+0nt+/u430WDev3DabZ5bnMSEjhrHpMYxJiyYjLpxZwxMB+O45o9i0r5avnDasI7G/45xRLMmt4J7zx5IRF96tX6egTZqNAa830FGIiIiI9A3PLM9jYkYsEzJiD9q+JLeCH7y8AYAF28ooqGryr3cB33p2DR6v5YWvzSK/yjfJbltJ7UHP//uCXD7cWsLeikbqW9oZFOvmuZUFRIY6+fy0TL5y2jAAapvbqGlqIykqjCmZcTz00S6eXpbXMcj5yA05/PDlDZTWtbC+oIY/vbedrcV1/OLSCYBv4bpLp2Z0HPe8CemcNyH9oFjGD4plzU/Oxu1yduNXzidoa5oNGmkWERGRvm9NXhU/e23TYTX/O0vrqW3u2qS742loaeeHL2/g4UW7AKhubGV3eQMAy3dX4jAQF+Fie0kdGwqrmZ6VQIjDsLW4jh2l9dzz8noK/CPN+ZVN1Le0A1DZ0Mqf399OfmUTI1KieO6rp3DdyUMB+MLMIcRGuDpi+PXlk3jwumkAnDM+jbgIFz94eQP/XLiLcJeT0anRvPR/s5l/5xwGxbq5/8OdxEW4uGTKoBM6155ImCGYk2ajlnMiIiLS9z23soB/L95DVaeuFB6v5fIHF3PX8+tpbvNQ03Rw8tzc5uFnr23ihVUFtHsO/2i9oKqR//fGZlrbfY+tK6jGa2G7f+npn7+2mcseXEy7x8va/GpGpkQzNTOONXnVbCmqY0ZWAsOTozAGLj8pgzc3FLOnooFhyZGAr6QC4KlP9tLS7uXJL8/g6VtOZuqQeK7KyeSSKYO49fThRz3nKZlxLL1nHjHuEPIqGxmZ6isBAXA5Hfz04vFcOyOT179xKjFu11FfpzcFcdJs6GL7PxEREZGA2T9BrsA/0Q5gd3k9tc3tvLO5mHn3LeSLjyzDWkudf+T5tXX7+PfiPdz5/Doe8o8ed/b4kj08vGg3728pAWBNXjUAuaX1tLZ7mb+tlOrGNlbtrWJdQTVTMuMYlRZNXmUjHq9l9ogkrpmRyf/NGc53zxkNgNfC+RPSMQY+2FJCS7uHx5fuZc7oZEamRnccOzk6jL9cM7WjS8bRuJwO5oxOAWBUp+eDbyT615dPYnB8xIl8KXtU0NY0O9Q+Q0RERPq4do+XrR1JcxOTBscBsLHwQN1wYXUThdVN3P70GhbtKGPpPfN4dkU+w5IjSYwM5aXVhUwZHEdMuAu3y8Ge8kbe9reLe2l1IeeNT2P13ioAWv3t5PaPaj/xyV6qG9uYMiSOUP9kunCXk5OGxnGKf8IdwKTBsawvqGFaVjznjU/jyaV7SfavyveVU4d96vOfNzaFV9ftY1Rq1Kd+jUO9sraQqoZWbpzdvZOPgzZp9i2jHegoRERERHxLQd//wQ7GDYrhvPFpHaUIu8sbaPGXUHQead5QWENYiIO/XDMVj9fyjWdW88aGIgD+vXg3q/ZW8cPzx+J2OfjxK5u4/tHluEMchLmcVDa0ApARF86HW0sY9aO38FrL2PQYthTV8tBHu3AY3+juG+t9rzklMw6PP3GakZ1AWMjBdcHnjk9jfUENWYmRfO2M4by1sZifvraZMWnRzB6RyKc1b2wqF0xM55xxaZ/6NTrbXlLHt55dy/SseG6YlYUxplteF4I5acYEfRN9ERER6R8W55bzt/k7AfjlpRMoqW3GWjpqhME30rzfxsIaxqbHcN4EXzL51LJEPtlVgdvl5I/vbcftcnDFtMF4reXeVzeRGh2Gx1qa27xMHRLHpsJa7r92Kj9/bRPjBsWytbiW2+aM4CtPrGRbSR0zsxO4cPIgfvLKRqyFqLAQkqPDSIwM5YKJB3ekALh5djYjUqLITvLF+48vnsRHO8q5ZPIgSutaaGnzMiTxxEsposJCeOC6k074eUezJs83ov6bKyZ1a8IMQZw0O4yKM0RERCTwrLX8b00hoSEO4iNcfLyjvKN8IizEQWiIg+zEyI6kuaXdw6bCGlJj3by9sYjzJqRz70Xj2V1ezxsbinlt3T4SI0Np83hJjXFz/7VTGZkSTUJkKK0eL4mRoRTXNON2OUmIDOU7Z40kJca3SuX+Rgl/+PxkthTVdjRN2F3eQGZCBB/dNZdfvbmFSZmxjEmL6TiH8FAn544/MBrcud3b3S+u59kV+XxyzzzSYntnNcw/vbedmHAXF08exFsbi7h6eiZhIU42FNYQFRZCdmLk8V/kBAXtREA0EVBEREQCaE95A09+spdX1+3jlbX7GJYUSc7QBD7cVtqxzyVTBnHvReMYmhhBQVUj1lrufnED9a0ecssaSPUnu6PTojlvQjqXT80gLMRBYXUzzy7PB+DCSYMYnRZNcnQYGXHhuF1OspIi+c8ne5m/rYxHPt7dcbw3vnEa8++cQ2ZCBO9vKSHc5eStb53GzGEJACzNreCpZXmU1bUcdj6ltc185fEVFNc0H7T9ltOHERHq5K4X1x/x6/DrN7fw5Cd7u/x1K69vobimmdZ2L7vK6g97fHd5A/d/uINfvL6Zv364g5+8somluRUAbCisZfygmI7yl+4UtEmzAZVniIiISMA8tGgXP/7fRhZu8y0fPzwliomDYzvawDkM/OLSCVw3cyjpseEUVDXx3xX5vLymEIBrpmcydUj8Qa85d0wKo/2dJl5eU3DMXGdXuS/hvHjygT7H4wbFdJRYhDgdzBubwtj0mI4a5nc3+0bAK+pbaWn3HPR6r6zdx/tbSvnlG5sP2j48OYovn5rNoh1lrMmr4ranVtPY6uvj3Njazj8/8n0dHv5oFzVNbdz37jbufnH9UWOf9ZsPOfnXH/D3Bbmced9C/tUp6Qd4bPFuQhyGMWnRDEuKJCLUybubfV1CLpyYzudzunf57P2CujxDRERE5FC5ZfUMS4o8Zs1raV0zKdEHlxo0tLTT2u4lPjK0Y1tTq4d/LMzlymmDyUw4uKZ32S7f6OcHW30jy7fPHUFVo2+SXmSYk4YWD3kVjeypaOT19ftobPXwk1c2AjAiOYp7LxrPy2sK2FfdzG1zRwC+bhtDEiNIj3Nz5pgUPF5LiPPw87DWsnx3JZdPzThsBcD9fnXZRMDXbaK2uZ35W0tZmluBy2n49n/XMjz5VCYOjqWl3UNRdTO5/lHfhdvKqG9pp7apjWW7K/jrhzu55bRhWAtX/mMpHq/lnPGpXDIlA3eIkwV3zuGrT67i0cW72bivhlfW7gPgW2eNJD02vONr+8s3NjM1M77jj4pX1xViDPzi9c2cOiKJEKchKzGS/63dx/kT0/ndlZNo81iW76nk3U3F3HnOaG45/dN38jie4B1pNgavRppFRESkk63Ftcy7byH//Ojw3sb7LdhWyoz/9wEbCmp4fMkefv3mFtblV3PNQ58w/f+9z6/f2tKx75/e385fPtjBDf9eTk1jG29tKOKFVQXkVzaSW+Zbca+mqQ13iIMxadEdCWxDi4epQ+Jo81h++cZm4iJc5GTF4/FazhiVzD+uP4nwUCeLd1bw+JI9HccLcTr42xdO4p/X53D19CGEOB1UNrTy9sYiWto9vLG+iN++vZWqxjaSo93MyE5g8c5yNhbWUFTTRE1jG6V1zZTWHiixeGFVAb99ayv5lY0MinNz31VTAF8HD4A/v7+Dc/70EbfNHcHfvjCVupZ23tlYzKzffMh3/ruOgsomzh6XCtDRgWP/HyQOhyErKZJbTh9GUU0zr6zdx8gUX3u53NKGjudc/69lPLM8n9++vZUfnj/W93hZA1eeNJjHb55BcW0z8+5byH9X5PP8107hjrNHERbiJCoshJtmZ1Pb1M6Z9y2g7QgLvXSXoB1p9pVnBDoKERER6Ut2lvpGS19fv4/LpmYQ43axobAGt8vR0SP5yaW++tsXVuXzuP/2/iR7VGoUj368mzvPGc224joeWbSLWcMTWbGnkksfXNyxNHVEqK/c4ZRhiSzdVYHHWk797XxOG5lEdlIEu8sbeeaWk/nPJ3vZW9HIYzdNZ87oFFraPQe1exuaEEFpXQtNrR7qW9opqjnQy7m0rpmPtpdT19zGz17bTEp0GKX+WuQZWQm89a3T8HotJ/3yPc4em0pkWAhPL8/DWkubx5ckrfvJOQyOj2DTvlreu+MMwDdK/aOXN7Auv5qrp2fy0uoCWj1enlqWx92fG8Pw5CjGpsewNr+aJz/Zy+i0aJKiwnjkSzl85YmV3PO5MR0lIW9tKKK8voULJw3ilGGJ3Dg7i8z4CF5YVdCx+MnineWszqvmxllZFFQ1ct6ENP7fm74/TK6YNpiThyXytSdXAbBxXw1fmDnkoO/p9KwEnrplJs8sy6O2qY3EqGMvqvJpBW3S7DBGSbOIiMgA99aGIlbnVfHDC8YBsNs/+vujC8Zx9h8XMiQxgo2FtaTFuFly95mU1DUz3z9R7/lVBR2vExUWwryxKcwZncx3/ruOHSX13PXCeuIjQ0mIDOXnF0/g3lc3MXVIHLfPHcG3n12LO8TBH66azIurCogIdfLLN7bw7Ip8Jg2OJTk6jN3lDfzyjS2cOSaFM0YlAxzWH3l/G7e8ykaeX5nP40v3sOTueSRHh/H+5lJ+8PIGkqPDGD8oBo/XUlrXQnqsm4Xby5g7JgWHwzA9K4Hleyp59taTaWn34HY5eWzJHmLDXcSEhzA4PpzKhlYaWtqJDAvBGMOZY1J4ZV0hX5sznCunDeaB+bn8Y2EuN5+axdh0X1eNX1w6gYTIULKSfDGOz4jhxllZnDkmhaZWD08t28uiHeWU1DZz/SlZPHPryR3n9ZNB4yivb+EXr2+mqc1DjDuEe84f03H+799xBlmJEYQ4HeSW1Xd0GymtbeE/n+zl6umZuJwHCiamZyUwPSuhm941Rxa0STMGlWeIiIgEidLaZhKjwnAeMmlpT3kDDy/axY8vHIfb5aSopomUaDdOh6GuuY3/rsxn4fYy/m/OcJravOSW1ZMRF87Gwhpqm9vZvK+W1JgwimubufnxFeyrbsJr6VgIJMLloLHNy68vn8iFk9JZtrsSgD+8u43NRbVMGhzL6+uLyEyI4MM7z8DpMNz+9BpumzuC51fls6Okjq+dMZyVe3zPmzU8EWshMz6cX/lHU3935dF7Cg/1t07bXFTDf1fk87kJ6R0jtGeNTeHeVw3NbR6+c9YoZgxLwHp9JSgLt5d1vMbM7ATe21yCwfDryycBcNe5Y6hracMY07ES4GNL9nTUTt9x9mje3FjMsl0VfO/cMVwyJYMH5u8kxu06KL7vnD2q43Z6bDg/vXg8AC+uKuCXb/jOr/NExP1a2j387u2tbC6q5elbTubm2dkH/cEwIuXACoHR7hAumJjOvReN48EFufzqzS1cd8hoc28I3ppm1KdZREQkGJTXtzDjVx/w+3e2HfbYn97fzlPL8nhjfRGltc2c8fsF/OFd3353Pr+ORTvKsRa+98J6Zv3mQ26ancWjN07vSOi81rcCXojTsCavmu0l9SREuLhgoq8nsTvUSWSokymZcVz0t495yF+m8eHWUqLdIZw9LpXYcBfvbCpmcHwEH+8oZ9XeKnKy4mn1eLnx3ysY9aO3KG9o5fyJafzkonEs3VVBRUMrf7lmKst/MI+kY5QTZCVG4HIa/rlwF3Ut7dx86oGloVNi3Lzz7dNZes88zhqXSozbRWyEi5nDErnrvDEd+83M9q3Yd81DSzu2hYc6OyY6XnZSBudPTOOa6Qe6TgxJjGDRXXO5ZoYvOR2VGs1frpmK23XwSPjRXDFtMD843xfDpMGHT0S856UNPLeygKiwEGLcroOS5EOlRLt54LqTSIlxk1tWT/ZxJnH2lKBNmh1Gq5uIiIgEgw+2+NqJPbsi77DH6pt9rc3e21zCC6sLaG338q+Pd1NQ1ci24rqOiWnz/R0sHlm0m+HJkVwyZRDfOmskAO9sLMHgm7AHEB4aQpq/P3JlQxuD4yO4/l/L2FhYy42zstifrg1LiuQbZ47ku+eMYldZAztL63lnUwnpsW6mDY3npxeN74gzKzGCB6+bxpg0XwnDvReNIyEytGPRkaOJiwhl5Y/Opry+hZnZCUzJjDvo8WHJUUSFHbtwYNygGC6fmsF9V00+4uNJUWE8eN20w2qBU48T2/Hcevpw5t85hxtmZR32mMOf9HZeMOV4Nu+rZdGOcvZVNx1/5x4QtEmzUXmGiMhxGWPOM8ZsM8bsNMbcfYTHhxhj5htj1hhj1htjzg9EnDJwVTa0doxuNrS088D8nfztwx1U+1u3bdpXy+jUaL4xbwS/f3sbaTFuxqXHsCav+qBlqf3z3nhtfRE7y+oprmnmwy2lOI2h1ePtmBgHsK+6ie+/tIHTRyZxxqhkvnP2SPZUNAK+8orB8b42adf6R2HPHpfKOeNSqW1uY8G2Ui6clI4xhnljU3n0xhzOGpvCKH9vZYCfXjyeM8ekdvlrsLWolpY2L/f4u0qcKKfD8MerpzBtaM/W/B5JdlLkQbXH+3319GGcOz71hHoqZ8T5vu5zRqd0W3wnImhrmh3GaKBZROQYjDFO4AHgbKAAWGGMedVa23nlgh8Bz1lr/26MGQe8CWT1erAyIK3aW8kdz63jzW+extO3zOT+D3YQ7nLy89c3886mEl69fTZ/vmYKkaEhvLZuHxaIj3Txv9tmk1/ZSLt/lHnemBS2FNWSnRTJ4twKXl5d2FGbPDEjhtvPHMlX/d0ZwPdB9fUnD+UnF447aGW5cJeTEKeDK6YN5u8Lcjl/km8Z6fTYcB76Ug6/e3srXmv50ilZHc85c0zqCSXIRzJzWCJLfzDvuCPK/cnI1Gj+eX3OCT0nNsLFu985nSGH9MPuLcHz1T+ERppFRI5rBrDTWrsLwBjzLHAJ0DlptkCM/3YssK9XI5QBobS2maeX5zFtaDynjUzG67U0tnn4ZFcleysaafdYZg1PYtbwJADcLic/eHkDi3dWMHNYAusLqnl17T5cTsOWojr2VjQQFx7Kl04ZyhNL9/K980YzOjWaopomZv1mPgv83TEcBqZkxnPOuFRumzuclXuquHLaYMakxTAhI+agutlFd83tGPH+ur+jxKGT4iYNjuP/5ow4bJGT7hBMCfNn0XnEvrf12HfAGPMocCFQaq2dcMhj3wX+ACRba8t7KgblzCIix5QB5He6XwDMPGSfnwLvGmO+AUQCZx3phYwxtwK3AgwZ0vuz2iVwvF5Lq8fb5QlinTW0tON2Obn0gcVkxIfzZf8kt1++sYVHF+/m9FHJDE2MIDbiQHK6Oq+KaUPjSIwM5cZ/L+f2M0fw5/d3APCjC8byyze28Id3tvHh1lK+ePJQADLjIzDGMCgugoy4cLaV1BMdFsJ/v3oKg+LcGGP43rljDg+wk86JcFiIk8HxhyfG501I47wJXa/Rlf6lJ2uaHwPOO3SjMSYTOAc4vJq/G6k8Q0SkW1wLPGatHQycDzxpjDnsd4e19iFrbY61Nic5ObnXg5TA+d4L6xnz47ex1tLc5uny83aW1jP+3nf45Rub2VfTzLUzhhDtdtHU6uHRxbsB+Gh7WccKes1tHn779lYuf3AJ//fUau44ZxQzhyWwYk8lydFh/PnqKdw0O5sxadHsrWykodXTsSBJZKdR2pyseMA3OW7coBjiIkIR6YoeS5qttR8BlUd46E/AXfRwbwtjfCvaiIjIURUCnWfhDPZv6+zLwHMA1tqlgBtI6pXopF94cbVvAZBvPruWMT9+m8qG1sP28Xgt24rrOlbjA3h7YxHgW6zCGF+nhp+/tpn/fOJbge9z/hHbiRmxvLupmLP+uJC/L8hlRnYCuWUNhDod/OfLM9leUs+s4YlcOjUDp8MwMzuBLUW1HcfZv2jIfjn+BTAmZhzeBk3kWHq1QMYYcwlQaK1dd7z+ep/1oz4toy0iclwrgJHGmGx8yfI1wBcO2ScPmAc8ZowZiy9pLkPEb1Csm301zby2zlfunltWT0LkwV0a7nhuLa+s9T1+5bTB3DQ7i/e2lDI5M47SumaGJ0VSVNPMo4t3E+0OYURKFHedN4bqxjbiwl3c+uQqRqdG8/QtMzk5O5GLH/iY772wnv+tLaSsrqWjDzHAjOzEjqWvAf55/bSDYjllWCLGwLSh8T31JZEg1Wst54wxEcAPgJ90Zf/P+lGfrzxDWbOIyNFYa9uB24F3gC34umRsMsb83BhzsX+37wK3GGPWAc8AN1p9jCed/OGqyVw7YwiPfMnXCSG/svGwfVbuqeKkIXH844vTeGFVAW+sL2JdfrWvTVtTO7srGvjz+9sBSIgI5cHrTiI7KZJnbj2ZLUW1hIY4eP7rpzBreBIOh+Gxm2Zw+9wRLM2tAHyLk+y3//ao1Gg+/v7cw2qtR6REMf+7c1R7LCesN0eahwPZwP5R5sHAamPMDGttcXcfzBjwerv7VUVEgou19k18beQ6b/tJp9ubgdm9HZf0PV6vpc3rPWipY6Cjq8X+eub8yoMXnmhoaaewuolrZ2Ry7vhUot0hPLggF/AtbGGA372zraOn8l5/0u31WrYU1/Lqun2c41/tbr+kqDDuPHc0EzJi+GRXJcOTIzseS44O4yunZjNrROIRJ+sBZCVFHnG7yLH0WtJsrd0AdHSjNsbsAXJ6rnuGJgKKiIh0h6qGVs74/XzuOHsUN872dbh4e2MR4aEhtLR5mDY0nsSoMIYlRdLqOXgy4A5/HfPI1GiMMYxKjaap1cO3zxrJiJQonlvZRqjTwWM3T+cLDy8D4KXVhYxNj+Zbz64FfEsyH8l5E9I5b0L6Ydt/dOG47jp1kQ492XLuGWAOkGSMKQDutdb+q6eOdyiHJgKKiIh0i90VDdQ2t7Mmv5obgedW5vP9F9fjNIZ2r+XfN01n7ugUPrxzDvmVjewoqeOxJXuoaWrj91dO5oWvncLIFF9/3VGpUby9sZizx/kW/Fi0o5yThsYxa3gS/zdnOC+tLuD19fvweNMIDXHw+E0zOHlY769kJ3KoHkuarbXXHufxrJ46NuzvntGTRxAREQlOq/ZW0dzmYfYIX6OUxxbvAWBNXjU1jW3c9cJ6ANr9v2jTYtwdz318yR6e+GQvY9Ki2VFSj9NhOjpWAAyOj6CqsY3a5nb2VTexpaiWu84bDcBd540hNtzFr9/ayoo9VQxLiuSU4Qcm+YkEUq9NBOxtmggoIiLy6azYU8lNj62grK4FgPwqX51xXmUjDa3t/OWaKdx5zqiO/WPDXewqq+ftjUU88vFuxqRFs76ghqY2D3e9sI5FOw40XJk8OJYZ2QlU1Lfwi9c3Exfh4gszDnTJGjfItwDl2vxqRqRE9cbpinRJ0K7J6FtGO9BRiIiI9D/njEvlD+9s447n1nLZ1AzyK5vITopkd3kDz63M59tnjaK13UtVYxtPfrKXl1YXcP+HO/mKf0W/cH/HCgP8b+0+UmLcNLR42FhYw6OLd9PY6uHM+xYC8PNLxh+0wMj4QQf6Jytplr4keJNmjGqaRURETlB+ZSMFVU3cevowHlyQy6Idvvn6N5wylNRYNxdM9E28Cw1xUFbXQlqMmx2l9bS2ewlxGhwGYsJ9nS6SosO4/5qpPLJoFw99tAunwzBtaDzfO3c0728pYWZ2AnNHpxx0/ITIUNJj3RTVNCtplj4leJNm08NLDoqIiAShNzcU8eu3trLqR2dxw6wsZv7qAwCGJEZwyZSMg/a985zRVDa28tNXNwGwfHclu359AXP/sACA8voWpmTGsbmolnPHp/KXa6Z29E2ennX0yX3j0mOUNEufE8RJs9FEQBERkU5a2718/8X11DS18eiN04+4z+q8KoYmRpAYFQbAK7fNJjTEQXqs+7B9hyRGMCQxgvzKRkIchmW7K3n0493sLm9g6pA41uRVsyaviqKaZq4/ZehhC40czbSseJbtriQrUf2Upe8I2omAvmW0lTWLiIiA73fid/67lpfXFPLh1tLDfke+u6mYqoZWVu2tZmpmXMf2yZlxjE2POajueL/SumZ2ltZT0dDKl0/NZnRqND9/fTMZceF892xfR4w3NhQBMMrfcq4rvnLqMN674/QuJ9kivSFoR5odKs8QERHp4PFaBsW5SYtxU1zbTGVDKw/Mz2VMWjTpcW5ufXIVZ41Npby+hRnZx27z9p3/ruX0UUk8sXQvO0t8i5dMGhzHV88YzvMr87kqJ5NodwhhIQ7e2uhb9HdkatdLLXwj2+Gf/mRFekDwjjQbg1cjzSIiIv5Jeg5+eME4fn7JeNJj3by5sZhHF+8mt6yeP7y7HYD3t5QAMPMYi4m0tnt5eU0h3/nvOtbkVVPX0g7A0MQIEiJD+eoZw4mPDCXE6eCc8WlUNrQSFuI46pLWIv1F8CbNaHETERGRmqY2xv7kbZ5atheAc8ansfSeeZTVteAwcNuZI0iIcHHmGF8Xi/s+P5lhSUevJS6pbe647TDgdBgAMhMOT4pvnDUU8LWO27+fSH8VtOUZmggoIiICu8rq8XgtKdEHT+TLLasnMyGCGLeLR26YTnVjK+sLapg1IhFjjp7gFndKmueOTqHV42XTvlpi/W3mOjtpSDynjUw6qPeySH8VxEmzJgKKiMjAtLeigW89u5bfXTmJ3LIG4MBCIdZavvafVbyzqaRjdNnpMCRGhTF3TMoRX6+5zcPzK/O5dsYQimt8SfPTt8xkQkYs1Q1tFNU0HfF5xhie/PLM7j49kYAI3qQZTQQUEZGBo6aprWO0d8G2MtbmV3P706uZNTwJl9OQGe+bWGeMYWNhLQCnjkjq0mv/55O9/PKNLQxJjOxImidkxBLjdhHjdjEkUfXKEvyCNml2aCKgiIgMIL96YwthLgdNrR7CXA6mZMaxNr+a7SX1jEyJIsR5YBpTWqyboYkR3Oxf9nq/plYPoSGOjvrj/MpGPtxayrMr8gHYUVJHUU0zEaFOosOCNoUQOaLgnQhoNBFQREQGjoLqRpbkVvDC6gJSo93877bZzMz2dcG4/pShB+2bHBVGUc2B2mRrLa3tXs68bwF/eX97x/Y/vrede1/dxM5SX1u5HSX1FNc2kRbrPmbds0gwCto/E40xKs8QEZEBo7immVGp0VhrWbm3CoA/Xj2FpKhQwkIOXiRkdV4VpXUt1DW3Ud/Szrl/+ojzJqRRVNPMGxuKuOOc0bS2e3l/SwkTM2IZkhhBQWUjO0rrAI64OqBIsAvykWalzSIiMjCU1raQGuPG6TAs3F7GJ7sqyIgLPyxhBnjiyzP43rmjiXa7WLSjnNrmdp5bWQBAblkDv3lrK7c/vZq65na+fdZIHvjCSUwaHMeOknqKappJi9HCIzLwBG/SjMozRERkYGhoaaeupZ3UGDefn5YJHLlv8n5j0mK4be4IAJbtqiQ0xJcOzB2dDMA/Fuby7uYSosJCmO2fLDgqNYq6lnaKapo10iwDUtCWZzhUniEiIgNEQ2s7M7ITGJESxVljU7jspAySosK69Nzleyo4c3QKX5g5hMmZcVz6wGJCHIY/XT0Fr7W4Xb6R6hEp0R3POXVk17puiASToE2ajUHdM0REJKhYa9lV3sDw5KiDtqdEu3nuq6d03O9qwryvuon8yiZumpXN6aN8o8xPfWUm4S4n8ZGhB+07dUgcN87K4qLJ6UwbevRltkWClcozRERE+olPdlUy776FvLupuFteb9GOMgBOHpbYsW1QXPhhCTOA2+XkpxePV8IsA1bwJs3GaCKgiIgElYmDYwlxGNbkV3dsW19Qzd8X5HLWHxfS0u45odd7e2MxmQnhjE2PPv7OIgNcECfNGmkWEZHgEhUWwklD4ztGiAG++cwafvv2VvIqG4/YKeNoapvbWLyzgvPGp6nnskgXBG/SjCYCiohIcPn7glyW765kY2EtO0p8PZNvmJUFQGu797jPL6hqZG9FAwCPLNpNq8fLuePTeixekWAStBMBHerTLCIiQWZNXlXH7YcX7eJ3V07mptnZtHm8OLowWnzb02toafPw1TOGcf8HO7hkyiCmDY3vyZBFgkaPJc3GmEeBC4FSa+0E/7bfAxcBrUAucJO1trpnjg9e5cwiIhJESupaOG1kEj+9eDxDO/VhvvX04cd9bmF1E+v8tdCPLNrNsKRI/njVFJVmiHRRT5ZnPAacd8i294AJ1tpJwHbgnp46uK9Ps7JmERHp/7xeS3VjK2W1zaREuxmeHEWI88R+hb+z8UDHjU37apk7JgWnQwmzSFf12EiztfYjY0zWIdve7XT3E+DKnjo+GmkWEZEgcefz63hpTSEAKTFd68F8qLc3FTMiJYqSmmbqWto5w9+XWUS6JpATAW8G3jrag8aYW40xK40xK8vKyo6221EZDBpoFhGR/qq5zYPXP/ozMvVAS7gRhyxs0hUFVY0s313JxZMHMXNYAm6XgxnZ6rcsciICkjQbY34ItANPHW0fa+1D1toca21OcvKJ/zXsMKg8Q0RE+iWv13L5g0u47pFltHu83Dgri9AQB185NZsrpg0+5nOPNAn+lbX7ALhsagY/OH8sj3xpesfy2CLSNb2eNBtjbsQ3QfA624PtLTQRUERE+qv520rZXFTL0l0VzPjVBxgDM7IS+GjHsT95fWTRLk797Xw8h/wCfGl1ATOyE8hMiGBYchSnjkzqyfBFglKvtpwzxpwH3AWcYa1t7NFjoRUBRUSkf3p6WR5pMW4umpxOc5uXsBAHmQnhfLyznPL6FpKiDq9rbmr18OCCXCobWsmvbCQrKRKA4ppmcssauHbGkN4+DZGg0pMt554B5gBJxpgC4F583TLCgPf8LW4+sdZ+rSeO71BJs4iI9FN/vmYKu8sbmDQ4rmPbTy8ez8WTM46YMAO8sCqfyoZWAHaW1nckzSv3VgIwPUs1zCKfRU92z7j2CJv/1VPHO4wxWkZbRET6pWi366CEGSAsxMkpwxOP+pzFOytIjg6jrK6FnWX1nEUqACv3VBHucjJuUExPhiwS9IJ4GW0flWiIiEh/8tBHuTy5dM8JP6+gupFx6TEkR4eRW1rfsX3l3kqmZMbhOsG+ziJysKD9Cdq/nKhyZhER6S+stfzr4918srvyhJ+bX9nE4PhwRiRHsbOsnsbWdu54bi2b9tUyXe3lRD6zoE2a968K6lXWLCIi/cTmolpKals4Y+SJtVqtbW6jpqmNzIQIRqREsbO0nj++u52XVhdy/clDueW07B6KWGTg6NXuGb2pozwjoFGIiIh03bubSnAYmDc2pcvPKa9vYVdZAwCZ8RFEhjqpa27nkY9384WZQ/j5JRN6KlyRASVok2aHw5c2a6RZRET6i3c2FZMzNIHEo3TIOFS7x8tlDy6mtqkdgMyEcOaMTsbjteyraeb2M0f0ZLgiA0rQJs37KWcWEZG+7KPtZWwtruXGWdlMyYxj+Aksk/3e5hLyK5s67mfGRxAZFsKNs1WOIdLdgjZp3j8RUEREpC/739pCcssa+PKpw/juOaOJDOv68taPL91DdFgIdS3tRIY6iYtw9WCkIgObJgKKiIgEiLWWRTvKyYwPx+kwJEeHERHatfGslnYPy3dXcv0pQxmaGEFmQgRGA0YiPSZoR5oP9GkOaBgiIiJHta2kjrK6Fk7vYreMsroW7v9gB5/PGYzb5cRrYXRaNGeNS6Xdo194Ij0paJPmjj7NAY5DRETkaD7eUQ7AaaOSurT/n9/fzlPL8vjPsr3cNMtXtzw8OYoJGbE9FqOI+Kg8Q0REpJd5vZa9FQ2syatmaGIE6bHhx31OfmUjz63M5/KpGbgcDp5evheA7KTIng5XRAjikeb9lDOLiEhf87t3tvHYkt2s+OFZVDe2dek5724uoc1j+c7ZoyioamL5nkrSY91EhgX9r3KRPiFoR5o7umcoaRYRkT7E67XkDI2nuc3LuvwaMhMiuvS83LJ64iJcDI4PZ4Z/WewTaU8nIp9N0CbNKs8QEZG+aEtxLV95YiUAX/zXMmqaujbSnFtaz/DkKIwxnZJmlWaI9JbgTZr9/ytlFhE5OmPMecaYbcaYncaYu4+yz1XGmM3GmE3GmKd7O8Zgs72k7qD74a6u9WXeVd7AMH/98rSh8WTEhXPysMRuj09EjixoC6H2L6NtNdIsInJExhgn8ABwNlAArDDGvGqt3dxpn5HAPcBsa22VMSYlMNEGj+0l9bichv98eSb5VU2Ehhx//KqmqY2yuhaGp/jKMSLDQlh895k9HaqIdBK0SfP+kWavcmYRkaOZAey01u4CMMY8C1wCbO60zy3AA9baKgBrbWmvRxlErLVsKaolOymSmcMSmdnF5+0qqwdUwywSSMFbntHRp1lZs4jIUWQA+Z3uF/i3dTYKGGWMWWyM+cQYc96RXsgYc6sxZqUxZmVZWVkPhdv/Ld1VwYJtZeRkJXT5OZv21fDwol0ADFMNs0jABO9I8/7mGcqZRUQ+ixBgJDAHGAx8ZIyZaK2t7ryTtfYh4CGAnJwcXXmP4uTsRP7w+clcOCm9y8/56wc7eXtTMbHhLoZ0sdOGiHS/4B1pZn9Nc4ADERHpuwqBzE73B/u3dVYAvGqtbbPW7ga240ui5VNwOAxXTvMtgd1V20vqOHNMCgu/NweXM2h/bYv0eUH70+foaNOsrFlE5ChWACONMdnGmFDgGuDVQ/b5H75RZowxSfjKNXb1YoxBY2txLZf87WNW51V1af991U0U1zSzp6KBCYNiiIsI7eEIReRYgr48QxMBRUSOzFrbboy5HXgHcAKPWms3GWN+Dqy01r7qf+wcY8xmwAN8z1pbEbio+6991U2sK6jpmKh+LNZavvDwJ7R7LV4Lo9Kiezw+ETm24E2aUcs5EZHjsda+Cbx5yLafdLptgTv8/+QzKK1tASA5Ouy4++6paGRPRWPH/dGpSppFAi1oyzM0EVBERPqSsrquJc17yhuYv/VAZz+X05CVpK4ZIoEWvCPNRhMBRUSk7yirbyE23EVYyNEnAdY0tTHnDwsAyIgLx+1y4HI6NAFQpA/osaTZGPMocCFQaq2d4N+WAPwXyAL2AFftb5jf7cf3/6+JgCIiEmgFVY2kxbo5bWTSMffbWVrfcXvO6GSumzkUjybniPQJPfmn62PAoU3w7wY+sNaOBD7w3+8RDv+ZaaRZRIKdMeYiY4yGIvuonaV1nPrb+bgcDv72hZOOuW+uf+W/h7+Uwz3nj2XcoBgmDo7tjTBF5Dh67CJrrf0IqDxk8yXA4/7bjwOX9tTx908E9CprFpHgdzWwwxjzO2PMmEAHIwfb3yrumeV5x903t6yeUKeDuaOTiQoL2gpKkX6pt0cmUq21Rf7bxUDq0Xb8rEuydkwE/BRBioj0J9baLwJTgVzgMWPMUv81VC0X+oCkqDC+NW8ku8ob+MXrm4+4j7WW3LJ6dpU1MDQxghDVMIv0OQH7qfS3MTpqTmutfcham2OtzUlOTj7h1z8wEVBps4gEP2ttLfAC8CyQDlwGrDbGfCOggQlr8qqYkOErsQhxHLlL86Id5cy7byELt5UxPDmqN8MTkS7q7c9+Sowx6dbaImNMOlB63Gd8Sh0TAZUzi0iQM8ZcDNwEjACeAGZYa0uNMRHAZuCvgYxvoPvxKxtJjAzjnW+fztDEiCPus2KPr5qx1eNleIray4n0Rb090vwqcIP/9g3AKz11IMf+keaeOoCISN9xBfAna+1Ea+3vrbWlANbaRuDLgQ1tYPN6LbmlDQxPjmJ0WjRu14F2c81tHqoaWgFYm19NqL8kY2SKqmpE+qKebDn3DDAHSDLGFAD3Ar8BnjPGfBnYC1zVc8f3/a+JgCIyAPwU2D9fBGNMOL45JHustR8ELCqhqLaZpjbPEUePf/PWVuZvK2X+d+ewLr+aK6ZlMG9MKqeNOnZbOhEJjB5Lmq211x7loXk9dczOVJ4hIgPI88CsTvc9/m3TAxOOgG9OzRNL9gAw6gjLYG/aV8PeikYW55ZT29zO1Mx4zhp31PnxIhJgQTs9VysCisgAEmKtbd1/x387NIDxCLC9pJ6F28u4OieTaUPiD3t8T0UjAP9cuAuAyZlxvRmeiJygoG0CqfIMERlAyowxF1trXwUwxlwClAc4pgFvdFo0b37zNIw5MJCzX0NLO2V1LQB8vLOc7KRIRqWqa4ZIXxa8SXOgAxAR6T1fA54yxvwN3+UvH/hSYEMa2LxeS7vXEhpy5A9091Q0AOAw4LVw9fTMwxJrEelbgrY8w6HyDBEZIKy1udbak4FxwFhr7Sxr7c5AxzWQbSisYerP32VpbsURH9/rL804c0wKoSEOrjhpcG+GJyKfQpdGmo0xkUCTtdZrjBkFjAHesta29Wh0n4HKM0RkIDHGXACMB9ydFnf6eUCDGsAW55bT0Oph5FFKLnaX+0aaf3PFJBpa2kmODuvN8ETkU+jqSPNH+C7EGcC7wPXAYz0VVHfQMtoiMlAYY/4BXA18A195xueBoQENaoDLLW0gNSaMpKgjJ8N7KxpIivI9PjRRi5mI9AddTZqNv0n+5cCD1trP4xvR6LP2j7RopFlEBoBZ1tovAVXW2p8BpwCjAhzTgJZX2cDQhKMnw9uK6xierGRZpD/pctJsjDkFuA54w7/NeYz9A059mkVkAGn2/99ojBkEtAHpAYxnwNtb0ciQoyyZXdvcxobCGmZmJ/RyVCLyWXS1e8a3gXuAl621m4wxw4D5PRZVN3B0zEJW1iwiQe81Y0wc8HtgNb4L38MBjWgAs9ZyzYwhjB8Uc8THl++qxGvhlOFa+U+kP+lS0mytXQgsBDDGOIBya+03ezKwz+rARMDAxiEi0pP81+QPrLXVwIvGmNcBt7W2JrCRDVzGGO44++jVMUt3VRAa4mDqkLjeC0pEPrMulWcYY542xsT4u2hsBDYbY77Xs6F9Nga1nBOR4Get9QIPdLrfooQ5sGqa2qhqaMUe4ReQ12uZv62UaUPicbv6dJWjiByiqzXN46y1tcClwFtANr4OGn2WY3/3DGXNIhL8PjDGXGG0Okaf8PzKfKb+4j1qmg7vyvrGhiJ2lTVwzYzMAEQmIp9FV5NmlzHGhS9pftXfn7lvZ6MqzxCRgeOrwPNAizGm1hhTZ4ypDXRQA9Xeikai3SHERYQetN1ay/0f7GBUahQXTRoUoOhE5NPqatL8T2APEAl8ZIwZCvTpC3JHeUYfz+1FRD4ra220tdZhrQ211sb47x95Fpr0uG3FdYxMOXxRk/UFNeworefLp2bjcOhDAZH+pqsTAe8H7u+0aa8xZm7PhNQ9HGqeISIDhDHm9CNtt9Z+1NuxDHTWWrYU13Lx5MNHkl9fvw+X03DeeHUDFOmPurqMdixwL7D/wrwQ+DnQZyebHFjcJMCBiIj0vM4Ts93ADGAVcGZgwhm4CqqaqGtuZ2z6wQP9Xq/ljfVFnD4ymdgIV4CiE5HPoqt9mh/F1zXjKv/964F/41shsE86sIy2smYRCW7W2os63zfGZAJ/Dkw0A9dPXtmI02H4zeUTOWV44kGP7SitZ19NM98+Sws1ivRXXU2ah1trr+h0/2fGmLU9EE+3OdA9I7BxiIgEQAEwNtBBDDRPLN0LwIffPYOhiQcvkb18dwXAYcm0iPQfXU2am4wxp1prPwYwxswGmnourO6wvzxDWbOIBDdjzF85MIPDAUzBtzKg9JLmNk/H7bc3FfN/c0Yc9Piy3ZWkx7oZHB/e26GJSDfpatL8NeAJf20zQBVwQ8+E1D06RpoDG4aISG9Y2el2O/CMtXZxoIIZiKoaW4kNdzEjO4HsQ0aZrbUs213JrOGJqJW2SP/V1e4Z64DJxpgY//1aY8y3gfU9GNtnsv/CpMVNRGQAeAFottZ6AIwxTmNMhLW2McBxDRjpseGsu/ccrLWHJcbLd1dSVtfCjOyEAEUnIt2hq32aAV+y7F8ZEOCOHoin23R0nFPOLCLB7wOg8+f+4cD7AYplQDs0Ya5tbuOO59aRmRB+xDZ0ItJ/nFDSfIg+/RmTo2OkOcCBiIj0PLe1tn7/Hf/tiADGM+C8sraQ259eTZvHe9D2N9YXUVjdxH2fn0K0W63mRPqzz5I09+l01HQso92nwxQR6Q4NxpiT9t8xxkyjz0/WDi5r8qpZuK0Ml/PgX6sLt5WRHutmelZ8gCITke5yzJpmY0wdR06ODQd/FHhCjDHfAb7if+0NwE3W2uZP+3rHopRZRAaAbwPPG2P24bs+pwFXBzSiAaaopom0WPdB29o8XhbvLOfCyemaACgSBI6ZNFtro7v7gMaYDOCbwDhrbZMx5jngGuCx7jyOyjNEZKCw1q4wxowBRvs3bbPWtgUypoGmuKb5sKR51d4q6lraOWNUSoCiEpHu9FnKMz6LECDcGBOCr+5uX3cfoGNFQGXNIhLkjDG3AZHW2o3W2o1AlDHm/wId10BSVNPMoNiDP4B9Ze0+3C4Hs0doQRORYNDrSbO1thD4A5AHFAE11tp3D93PGHOrMWalMWZlWVnZCR/HqE+ziAwct1hrq/ffsdZWAbcELpyBxVpLUlQY2ckH+jM3tLTz6tpCLpg4SBMARYJEryfNxph44BIgGxgERBpjvnjoftbah6y1OdbanOTk5BM+jsozRGQAcZpORbPGGCcQGsB4BhRjDG9+6zS+dsbwjm2vrttHQ6uHa2dkBjAyEelOgSjPOAvYba0t89fcvQTM6u6D7P/toe4ZIjIAvA381xgzzxgzD3gGeCvAMQ1YbR4vf1+Qy/hBMUwbqq4ZIsEiEElzHnCyMSbCPzIyD9jS3QdReYaIDCDfBz4Evub/t4HP0OFITswnuyq44u9L2FXma5X90uoC8iobuePsUeqaIRJEAlHTvAzfkq+r8V3YHcBD3X0cLaMtIgOFtdYLLAP2ADOAM+mBwQg5sryKRlbtrero0bxwexmZCeGcOUZdM0SCyTFbzvUUa+29wL09eQwtoy0iwc4YMwq41v+vHPgvgLV2biDjGmjK6lsASI4OAyC/solhSVEaZRYJMoFqOdfjOiYCqkBDRILXVnyjyhdaa0+11v4V8AQ4pgGntLaZaHcIbpcTgPyqRjITVB0jEmyCNmnuWEbbG9g4RER60OX4WnfON8Y87J8EqOHNXlZW30KKf5S5rrmN6sY2BsdHBDgqEeluASnP6A2G/SPNIiLByVr7P+B/xphIfK08vw2kGGP+Drx8pB740v0Gx0cQG+7rxVxQ1QRAppJmkaATvEmzVgQUkQHCWtsAPA087e+F/3l8HTWUNPeCH5w/tuN2fmUjgMozRIJQ0JdnKGcWkYHEWlvlXxxqXqBjGYjyNdIsErSCOGnWREAREelZNU1tzP7Nh7y0ugDwjTRHhjqJi9DS2SLBJmiTZodGmkVEjssYc54xZpsxZqcx5u5j7HeFMcYaY3J6M76+bktRLYXVTcSFu7jv3W38b20hmQkRajcnEoSCNmnePxHQq6RZROSIjDFO4AHgc8A44FpjzLgj7BcNfAvfAirSycbCGgBW7q3irx/uZGJGLN87d3SAoxKRnhC8SXPHMtrKmkVEjmIGsNNau8ta2wo8i68Lx6F+AfwWaO7N4PqqmqY2nli6h+Y2DxsKa0iLcfPo4t2cPS6VJ26ewbyxqYEOUUR6QPAnzcqZRUSOJgPI73S/wL+tgzHmJCDTWvvGsV7IGHOrMWalMWZlWVlZ90fahzyzPI+fvLKJ37y1lQ2FNYxOi6a5zcvs4YkqyxAJYsHbcm5/n2ZlzSIin4oxxgH8EbjxePtaax8CHgLIyckJ6gvv3ooGAO44ZxQupyHa7WLh9jLSYtVmTiSYBe1Ic8dEwMCGISLSlxUCmZ3uD/Zv2y8amAAsMMbsAU4GXh3okwFzyxqYNjSeGLeLH14wjjFp0QAMinMHODIR6UlBmzTv/4jMq5mAIiJHswIYaYzJNsaEAtcAr+5/0FpbY61NstZmWWuzgE+Ai621KwMTbt+wu7yBYUmRHfeLa32l3mmxSppFglkQl2f4KGUWETkya227MeZ24B3ACTxqrd1kjPk5sNJa++qxX2HgsdbyjTNHMCwpqmPbvupmXE5DUmRYACMTkZ4WtEmzY//iJsqaRUSOylr7JvDmIdt+cpR95/RGTH2ZMYYvnZJ10LbimiZSY9w4HJoEKBLMgrY8Y/9Qs1dZs4iIdJOimiZ2ltYfVPq3r6aZQZoEKBL0gjZpVtcfERHpbs8sy+OcPy2kzesFfPNmimuaVc8sMgAEbdKs8gwREeluueUNZCZEEBbiJL+ykXH3vk1eZSPpSppFgl7QJs37B5pVniEiIt1lV1kD2f7OGQu2l9Hc5htxnpIZF8CoRKQ3BO1EQKM+zSIi0o28Xsue8gZOGZYIwCe5FaTHully95laCVBkAAjakWaVZ4iISHcqrm2mqc3DsORIvF7L0l0VnDJMS2eLDBRBO9K8n8ozRESkO8SGu3j4SzmMSYtme2kdlQ2tnDI8MdBhiUgvCdqkWX/4i4hId3noo1x2lTXw04vH43Y5eeijXABmj0gKcGQi0luCNml2aBltERHpJo8v2UthdRMpMWHMG5PKwu1ljEqNYlCc+jOLDBQBSZqNMXHAI8AEfHP1brbWLu3WY/j/V8osIiKfRUltM4XVTZw/MY01edX89cOdOI3h5lOzAx2aiPSiQE0E/AvwtrV2DDAZ2NLdB9BEQBER6Q5r8qoB+Mqp2eypaMBaaPdazhiVHNjARKRX9fpIszEmFjgduBHAWtsKtHb/cXz/ayKgiIh8FjHhIZw7PpXQECf5lU182T/CPCM7IcCRiUhvCkR5RjZQBvzbGDMZWAV8y1rb0J0H2d8CSCmziIh8FrOGJzFreBIPzN8JwK2nDyM1RisAigw0gSjPCAFOAv5urZ0KNAB3H7qTMeZWY8xKY8zKsrKyT3UgY1B9hoiIdInHa9leUnfQtuY2Dy+szGflnko+2FLCxIxYJcwiA1QgkuYCoMBau8x//wV8SfRBrLUPWWtzrLU5ycmfrm7MAGqeISIiXfGbt7Zwzp8+Ym/FgQ8+l+SWc+cL6/nqk6tYk1/NvLEpAYxQRAKp15Nma20xkG+MGe3fNA/Y3BPHMsZgVaAhIiJdcPX0TAA+2l6Gx2vZUVLHe5tLAKhoaMVaOGtsaiBDFJEAClSf5m8ATxljQoFdwE09cRCHUXWGiIgcm7WW6sY2hidHkZkQzkc7yqlqbOPBBb7WcuAr90uNdjN+UEyAoxWRQAlIyzlr7Vp/6cUka+2l1tqqnjiOwag8Q0REjunZFfmc9ceFFFQ1MWtYEu9tLuGCSelEhoYQGuL7Nfnnq6fwx6smd0wyF5GBJ1B9mnuHQeUZIiJyVNZaHl60i8yECDLiwjltlG9Z7L/Pz6WioZWqxjai3SFcPHkQs7RktsiAFtRJs8ozRETkWF5fX8SusgaumZ5JXXM7za0enrllJm9uLCIqzFfBODo1WiPMIhKwmuZeYTBYZc0iInKIdzcV86+Pd7NsdyUA509K58mle/n9O9sYnhxJS7uXp74yk+seWcbotOgARysifUFQJ80aaRYRkSN5fX0RO0vr+d65o7HWEuN2dSTQuWUNXDdzCCcPS+TJm2eQnRwZ4GhFpC8I6qTZGE0EFBGRA3aU1LGztJ53NhVz2dQMrps5BK+Fdo+XVXsqOXNMCinRYXzn7FEAqmMWkQ7BnTSjiYAiIgNJQ0s7ZXUtAFhg+e4KluRW8NOLxuMwhkseWExjq4ex6TGcMTKZM+9bSLvHy1dOG0ZDq4fLpmZw0eRBgT0JEemTgjtpVnmGiEjQa233UtvcRmy4iwXbyrjt6dUHPZ4W46bN6yU23MX910ylqrGV3eUN3PbMaoYlR+FyOvjje9sBmJGdEIhTEJF+IMiTZk0EFBEJdhv31XD5g0v4903TmZwZy5+untzxWFRoCBFhTlKi3TS3edhaXMsD83NpavNw4aR0fnvFJFxOB+9sKqa+pZ3UGHcAz0RE+rIgT5pRcYaISJBrbPEAEBkawuD4CNJi3BhjaGxt58q/L2VbSR23nJbN25uKya9s4nMT0vjGmSMZ12l1P5VkiMjxBHXS7DBG5RkiIkGuobUdgMgwJwBX/XMp6bHhuJyG3LJ6xqXH8PCi3YxMieKpr8xktib3icinENRJswG8yppFRIJa4/6kOTSEsroWVudVA9UA3D53BF+bM5yluRXMGZ2MyxnUa3qJSA8K7qRZ5RkiIkGvwV+eERHm5JNdFQBEhYUQEerk63OGExkWwtnjUgMZoogEgSBPmlWeISIS7KZkxnHXeaOJcbtYkltBVFgI737ndCwQGRbUv+ZEpBcF9dXEgLpniIgEuQkZsUzIiMVay5LccmZmJzAoLjzQYYlIkAnupFl9mkVEgl5pXTOt7V62FNWxt6KR2+eOCHRIIhKEgjppdhijiYAiIkHuT+/t4P0tJSRHhZGVGMFlUzMCHZKIBKGgnkbsW0ZbRESCWWNrO+4QB5uLavniyUMJUYcMEekBQX1l0URAEZHg19Di6Wgll5kQEeBoRCRYBXnSrImAIiLBrqGlnRCnASA5OizA0YhIsAr+pDnQQYiISI9qbG3H4E+ao5Q0i0jPCOqkWRMBRUSC39fnjGBCRgygkWYR6TlBnTS7Q5w0tXoCHYaIiPSg8yakEe12EeMOwe1yBjocEQlSQZ00x4SHUNfcHugwRESkB60vqCavskGjzCLSo4K6T3O020VpXXOgwxARkR5ireXyB5eQHB3G0ER1zhCRnhPUI83R7hBqmzTSLCISrFo9Xtq9lqY2D8nR7kCHIyJBLGBJszHGaYxZY4x5vaeOEe0Ooa65radeXkREAqyxxeP/v50UlWeISA8K5Ejzt4AtPXmAGLeLuuZ29WoWEQlSDa2+TxNbPVY1zSLSowKSNBtjBgMXAI/05HGi3S7avZbmNm9PHkZERD6jRz/ezf0f7Djh5zW0HOiQlKQezSLSgwI10vxn4C7gqNmsMeZWY8xKY8zKsrKyT3WQaLdvnqNKNERE+rbFO8t5Z1PxCT8vLcbNtTMyARg/KKa7wxIR6dDr3TOMMRcCpdbaVcaYOUfbz1r7EPAQQE5Ozqeqr9ifNNc2t5ESowkiIiJ9ldvlpKX9wDjKrrJ6vvXsWqZkxvGLSycAcPU/l1LV2HrQ8+aOTqGsrpWMuHDGpEX3aswiMrAEouXcbOBiY8z5gBuIMcb8x1r7xe4+UIzbBUCtejWLiPRpYSEOWtoPlFr8c+EutpfUcd6EtI5tWYmRJESGHvS8hMhQHl+6h6tyMjHG9Fq8IjLw9HrSbK29B7gHwD/SfGdPJMzgW9wE0AInIiJ9XJjLQYt//klFfQsvry3kymmDuW3uiI59fnvlpMOe9/KaAprbvJw1NrXXYhWRgSnI+zT7RppV0ywicmTGmPOMMduMMTuNMXcf4fE7jDGbjTHrjTEfGGOG9kQcMW5XxxLYTy/Lo7Xdy82zs475nKZWD79/exsTMmI4dURST4QlItIhoEmztXaBtfbCnnr9AxMBNdIsInIoY4wTeAD4HDAOuNYYM+6Q3dYAOdbaScALwO96IpZ7zh/LR3fNBWDjvhrOGJXMiJSj1yhXNrTylSdWsK+mmR9dMA6HQ6UZItKzgn4ZbYDaJo00i4gcwQxgp7V2F4Ax5lngEmDz/h2stfM77f8J0CPldJ398/ocGlqOPNjh9Vp2ltVz21Or2VvZyO+unMTJwxJ7OiQRkeBOmiNDnTiMRppFRI4iA8jvdL8AmHmM/b8MvHWkB4wxtwK3AgwZMuSEA3lvcwkvrS7gL9dMJTTEQWTY4b+eVu2t5J6XNrC9pJ6IUCeP3zSDU4YrYRaR3hHUSbMxhmi3SzXNIiKfkTHmi0AOcMaRHv+sbUL3VjTw1sZiMt/dxtq8ap772imHvj63P70GhzH8v8smcPrIZDITIk78REREPqWgTprBV9eskWYRkSMqBDI73R/s33YQY8xZwA+BM6y1LT0RSJh/EuDO0nryKhsPemz+tlKSo8Ioqmnm/102getm9shcRBGRYxoASbNLfZpFRI5sBTDSGJONL1m+BvhC5x2MMVOBfwLnWWtLeyqQsBDfvPTqxlbCQ50d2wurm7jp3ytIifYtkT0zO6GnQhAROaagbjkHEBfuoqy+RwZGRET6NWttO3A78A6wBXjOWrvJGPNzY8zF/t1+D0QBzxtj1hpjXu2JWA4kzW2Euw4kzav2VgFQWtdCYmQow5OjeuLwIiLHFfQjzVOHxPHQR7uob2kn6ggTS0REBjJr7ZvAm4ds+0mn22f1Rhwx4S4y4sJpbPUQ32nVv9V7q3A6DB6vZUZ2glb9E5GACfqR5lNHJNHutSzfXRHoUERE5Cjmjk5h8d1ncsmUQeQMje/Yviavipyh8dx5zii+clp2ACMUkYEu6IdeTxoaT1iIg493VHDmGC2zKiLSl91z/tiO281tHjbtq+WW04dx+5kjAxiViMgAGGl2u5zMyE7g1XX7WL67MtDhiIjIEeSW1fOlR5ezJq+qY9vqvCravZZpQ+KP8UwRkd4R1Enzgwt2cs9L6zlpSDwuJ1z1z6X84OUNbC2uDXRoIiLSSXObh4+2l3HZg0v43dtbAfh4RzlOh2HmMHXMEJHAC9ryjL0VDfz+nW04jaHda7nipAxiwl08vmQPTy/LY2Z2An+6egqD4sIDHaqIyIAXFnKgY0ZjqweAxTvLmZoZR7TbFaiwREQ6BG3S/PiSvTiN4ePvn0ltcxtOh2F4chQXTR7E5Q8uYdnuSi7+28e8evupSpxFRAJsf8s5gIhQJ9WNrawvrOFb81TLLCJ9Q9CWZ2QmhHPjrCzSYt2MSo3u6O150pB4Fn5vDqNSoyivb+XKfyyhqKYpwNGKiAxsYa4Dv47CXU5W7a3CWpg1PCmAUYmIHBC0SfNNs7P50YXjjvjY0MRInrh5JiEOQ1ldC197chWt7d5ejlBERPYLdzlJi3H7boc62VlaD8DotOhAhiUi0iFok+bjSYt1c9LQeAbHR7CuoIYbHl3Oqr3qriEiEgjRbhfv3nE6F05KZ3hKFLll9SRHhxEbrnpmEekbBmzSDHDf5yfz5jdP46cXjWNnWT1feHgZH+8oD3RYIiIDUozbxd++cBJzR6eQW9bAsKTIQIckItJhQCfNmQkRhIc6uWFWFu98+3SGJETwxX8t49IHFrNgWynW2kCHKCIyYHzh4U94bPFuwNe3eXhKVIAjEhE5IGi7Z3TVQx/lsnJPFb+5YhIvfG0WL6wu4N+Ld3Pjv1cwIyuBL54ylPPGpxEaMqD/vhAR6XFLcitYkltBaqyb6sa2jgncIiJ9wYBPmsemx3Dfu9u54P5F/OqyiXz51GyuP3ko/12Rxz8W7uKbz6xhUKybjPhwRqREceGkQYxIiaLda8lQqzoRkW5XWtsCwLBklWeISN8x4JPm00Ym89xXT+F7L6zjpsdWcNnUDH5y4TiuPyWL62YOZeH2Mh5fuofGVg+vrSvimeX5Hc8dnhzJSUPiafN4OW1kMnERLto8lqlD4kj1zwIXEZETU17fDMDwJI00i0jfMeCTZoDJmXG89o1TeWB+Lg/O38m8sSlcOGkQ72wq5p8f7SIuwkVGXDijU6PZWlzLrOFJRLtDeHNDEW9vKgbgf2v3dbxeqNPB5MxYpmclcP7EdMrqWxiWFMnQRI2aiIgcT1VjO8ZAepwGH0Sk71DS7BcW4uSOs0dx5UmDyUzwlV24nA6i3SFU1LeSW1ZPdUMbkWEh3PylbGIjXFQ2tLI6rxoAh/FNLGxt93LW2FS2Ftfy4IJcHlyQ23GM4cmRJEeH8flpmVw8ZRAup+qkRUQOVdXQQnJUmK6RItKnmP7QISInJ8euXLky0GEcpqS2mcqGVhpa2lm4vYyNhTWMSo3mnvPHAnDB/YvYtK8WgPgIFw5jaPdaapraiHGHMHdMCl+YMYSZwxIDeRoi0oOMMaustTmBjqM3fdpr9rJdFby4uoD8ykYa27y8ctvsHohOROTYjnbd7vWRZmNMJvAEkApY4CFr7V96O47ukBrj7qhdzslKOOzx314xifL6FkprW3h3czGF1c1cMDGNMWkxvLWxiHc3FfPK2n0kRYUxNDGCf980nRi3GvmLyMA0c1giM4clctYfFzJCnTNEpI8JRHlGO/Bda+1qY0w0sMoY8561dnMAYulREzJiO25fNT3zoMeKapp4cXUh4S4nCZEu1uZVceOjy7lhVhafm5CuFnciMuD88OUNVDW2UlzTzGkjkwIdjojIQXo9abbWFgFF/tt1xpgtQAYQdEnzsVwyNYOUGDfPrcjnw22lRIeFsKu8gW89u5Y/JGzj6a+cTGZCRKDDFBHpNU8ty+u4nR6rSYAi0rcEdDjTGJMFTAWWHeGxW40xK40xK8vKyno9tp4W43Zx7vg0/nXjdF65bTbN7V6+f94Y/n3jdKoa2vj+i+upbmwNdJgiIgGRHqs++CLStwQsaTbGRAEvAt+21tYe+ri19iFrbY61Nic5Obn3A+xFkwbH8ZvLJzIuPYa5Y1K45bRsluRWMOXn73HVP5eytfiwL4+ISNCZM/rAtV4jzSLS1wQkaTbGuPAlzE9Za18KRAx9zeUnDWZyZhw7Sup4YH4uZ45J4Y6zRrKrrJ5bn1hFfUt7oEMUEelR/75xOr+6bAIAaUqaRaSP6fWk2RhjgH8BW6y1f+zt4/d1I1KiuPnUbD7cWkp8ZCj/+OI0CqoaOekX73HWHxfywPydeLx9v02giMiJMsZQWN2Ew6BVVUWkzwnESPNs4HrgTGPMWv+/8wMQR59kjOH7541m9ohEfv/ONoYkRvDQ9TnccMpQUqLD+P0727jliZUU1zQHOlQRkW63ck8V4wfFamETEelzev2qZK392FprrLWTrLVT/P/e7O04+jJjDD+7eDzNbV7O/8sipmcn8MMLxvH0LSfz80vG8/HOcs7640JeWVtIf1icRkSkK1raPazJr2ZG9uF970VEAk1/yvdRI1Ki+d9ts/nq6cOJDfcteJJbVs/1Jw/l/e+cwZi0aL717Fqu/ucnbNpXE+BoRUQ+u/UFNbS2e5mppFlE+iAlzX3YuEEx3HL6MADWF1Rz1h8X8vl/LCU23MUzt57Mzy4ez67yei7522Iue3AxTy3bi1f1ziLSTy3bVQHA9COssCoiEmhKmvuJESlR/PySCawvqOH6R5dR1dDKDbOyeP+OM/jyqdm0ebz88OWNzL1vAdc8tJQ7n1+H12tpbvMEOnQRkeOy1vLqun1MHhxLfGRooMMRETlMIJbRlk8hIjSE608eyqBYN1//z2pO/vUHPHJDDmeOSeWe88d2/MJ5aXUhJbXNfLKrgK3FtewoqeeJm2cwc1hioE9BROSolu6qYHtJPb+7clKgQxEROSKNNPcz88am8s8vTeOMUckkRobR2u7lw60lGGO4ZEoGj988g7e+dRqnjUxiY2EtUWEhfO0/q/hoexkejTyLSB/12OI9xEe4uHjyoECHIiJyRBpp7ofmjk5h7ugUAP718W5+8fpmshIjaPNYTh2RxC8uncA/vjiN3eUNRIWFcPNjK/jSo8s7nj8lM45zxqcya3gSUzLjAnQWIiIHfG5iGmeMTsbtcgY6FBGRI1LS3M996ZShOI3vo812j+W/K/Npbvfwl2umMiIliqW7Knjl9tm8sb6IoppmrLW8sKqA3729jdCQHTzpL92oaWxj2e4KcrISSFA9oYj0ssumDg50CCIix6SkuZ9zOR3cODubG2dnA/Daun20ebwAtHm83PTvFWTEhXPLadncfuYIXE4H3z5rFOX1LVzz8Cdc+/AnTMmMY1txHQ2tHlxOwz2fG8vEwbFkJ0WSFBUWyNMTERER6RNMf1gcIycnx65cuTLQYfQ71lre3ljMvz7ezcq9VZw1NoXrZg5l7hhfaUdFfQv/WJjL6rxqRqVGcc74NP6zdC8fbC0FICzEwTXTM/FYS21TO3ecPYqhiRFUNbZpNFqki4wxq6y1OYGOozfpmi0i/dnRrtsaaQ5ixhg+NzGdz01M59GPd/Pz1zeTX9nEnNHJFFQ18du3tzIxI5bHbpqOBWLcLk4fmczr6/cRFuJg/tYynl6eB0Co08Fr6/eRGBlGRUMLD1+fw1njUgN7giIiIiK9RCPNA8jGwhqGJEYQ43axsbCG259ezZ6Kxo7HB8eH8953ziA81MnzK/MZkxZDWqwbAK+1PLM8jx2l9WwrrqO6sZW5o1OoamzjjFFJnDs+DXeokxi3K1CnJ9InaaRZRKR/0UizMCEj9qDbC743l+W7K1mSW47DGLYW11LR0MLg0Aje3ljMD17ewNfnjKCqoZWimmbuOHsU3z4rhq3FtdzyxEoW7SjH7XLw/pYSfvzKJoyBSYPj+Mqp2WTEh/PUJ3ncfuYIspMiAWhu8+ByOnA6TKC+BCIiIiKfipLmAW5GdgIzsg9fsva+qyZz94sbuP+DHYQ4DPGRobicvmR3TV41p49M5qxxqewtb6C4tpnIsBC8XnhlbSHfeGZNx+u8t7mYS6ZkUFbXwvxtpaTHujl1ZBJRYS7Gpkfz9LI8hqdE8e2zRpIS7e618xYRERE5EUqa5YjiIkL5x/XTyK9sxOkwpMa4O0aIC6oaeWpZHk8ty+vYf9bwRJ6+5WQunpzOd59fh7WQFBXG0l0VPLMij7QYN5efNJiPtpfx/MoCWtp9HT5SY8JYm1/N/K2lfD4nk3HpMSzeWc6EjBiunj4E8HUBcTm1Do+IiIgEjpJmOabMhIjDtn3v3DF8flomFQ0tDIoLp6imGY/XVxv/cW4FeZWNNLd5yS2rJz3WTUSok5f/bzYOh2Hmr96npd1LVFgI0e4Q2r2W/3x5Jr94YzN//WAHnSvsl+ZWsKO0nk37agkNMcSGu/jc+HRW7q3igknpfPX0YYQ4HWwsrKG5zcOUzDhK6loYFOvGmINLQBbtKMNgOHVkUk9+uURERCRIaSKg9Kh2j5dluyuZPcKXrC7YVkpNUxt/+WAHu8sb+M5Zo/jmvJG0ebyM/OFbRIQ6afN4afP43pej06I4d1wa72wuYVtxHQAGsIDTGJKiQympbQF8LfJa2r0kRIYyMzuB608eSlZSJH96fzvPryzAYeD+a6Zw4eQMADxei9NhaG7z4HY58XotuysaiA13Hdaf2lrLst2VTMyIJTJMf2tK12kioIhI/3K067aSZgmI+pZ2CquaGJ0WDUBLu4fnVuRz9rg0nA7D4p3lbCmu5TtnjcLtcrKnvIHNRbW8sKqAQbFuNhTWAIbRaVGMSI7ixdWF7Cytx3OE9/P+JHu/iFAn0e4QyupayMlKoKi6ieZ2L7VNbbS0ewlxGG49PZvZI5JZtL2MNzcWUVLbQku7l9SYMH5zxSRyhsazvbiex5fuZnd5I9WNrUzPSuDUkUl8bkI64aFOXl+/j/zKJi6YmE6UO4SIUCdOh+koNalvaSfC5cRxhImRXq9lxZ5KqhrbaPV4OXlYwhFrvpvbPISFOLCWjtfZ/0fA0VhreWdTMYXVzZw+MomRqdFd+p5tKaqlsqG14w+gQDlauc76gmo276tlzuiUjq4vtc1tPL54D6eOTGJYchRul4OwEN/XZmluBcNTItlaVMfotGhSYw58fa21vLGhiI93lDMiJYqbZ2cf8fvUFUqaRUT6FyXNEvTaPF6Ka5qJjXDx+rp9OIyhqc1DZnwElQ2t1Da38e7mEtbmVePxWq47eQiLdpSzu7wBA4SHOglxGGqb2w97bbfLQXObrw7b4FuJsdW/8uKhpg6J40cXjOPFVQUdfa47v86aH59DeKiTSx9YzN6KBoYnR1HV2EpLu5dZwxP53ZWTeWVtId96dm3H80JDHEwbEs+/bszB6TD86OWN1DW38/amYowBl8PB0nvOpKHFw6UPLuayqRmMTImirrmddq/lwknpZCZEsK24jn8uzOWlNYWAb3T+T1dP4fyJ6ZTVtfDIx7vIr/S1IQxxOGhp93DnOaMZmRrNS6sLuOO5dUzOjKOt3Ut+VSNDEyN4/RunAfDXD3YQGuJg6pB4Fu0oY0luBRdOSuem2dnkltXzy9c309zmJSM+nO0ldeSW1vPzSyZwxbTB/OeTvby0uoAhCRHUt3gYHB/O2eNSOWVYIu1ey/89tZqdpXUkRIayOq+ab545gjvOGQ3AN55ZQ4TLySvrCmlu8+IwsPbec4hxu7ji70tYtbeK/dU6ceEuPvzuHABO/e2HtHb6VGPqkDie/+ophDgdnHnfAnaVNRDjDqG2uZ2rczL57ZWTTvg9CUqaRUT6G7Wck6Dncjo6arC/MHPoEff5ymnDaGn3kFfRyPDkKADW5FczIjmK2IgDPab3VjSQX9nE0MQIIkKdJEaFkV/ZyLr8aj7aUUa028XotGiiw5ycPCyJpjYP87eWsmBbKR9sLeWKvy8BIMLlxBhoaPVgDDS3eTn/Lx/R3O6ltd1LdWMbq/Oq8JeE89zKAnaU1tPQ3E5ipIuKhjYmZsRSXNvM0l0VnPbbD7l2xlCW7qqgoKqJiyal09TmYUxaNGvzqymsbmLqkDieWLqnIxkEX5/tr54+jK3FtfxvbSFfPX0Y158ylLtf3MDu8gZa2j3Ut7Tx74/3MDghHIcxtHt8o+9PfrKXn108nnPGp/HteY28vamYtFg304bG47GW8voWFu8s56MdZazYU9VxzMmZccSG+76m0WEhFNU0ExUWwodbS0mJDuPaGUO4YFI64CuV8Vr4ZFcl0e4QPt5Zxlsbi1j8/TN5b3MJS3PLyclKoLC6iUunDOKdTSXccc5o/9ewlQV51YxLj+Eb80ayp7wB6/975oKJ6dxx9ihW7KkEYGNhLVuKa5k1PIm/XDOVhxbt4rqZQyiuaWZtfjU7y+oZkxbDzOxEbjgliy+ePJTfvr2VtzYWfda3p4iI9HMaaRbpZvmVjeworSM+IpSx6TGEOAyPLdnDuoIaZg1P5PElexiREoXL6SA1xk11YytTh8Rx7vg0Hl60i6W5FSRHh+F0GAbHR/D6un0kx7iZPTyR1XlVfLKrsuNYTofpmIS5X4w7hC+ePJSX1xRQVtdCWmw4BVVNxLhD+NoZw1m8s5whiRGU1bWQW9aAy2GoaGilpqmV604eytaiOgqqmhiZGsWCbWUAzMxO4Aszh/DIot1sKKxhQkYMY9NimDUikR+8tJGmNg9xES6+fvpwCmuaiAh1cuGkQdQ0tXXUiKfFutlWXEdkmJOUaDc7SusIdzkZlhzFij2VvLp2HwA5WfGcPCyRyoZWxqbH4PVavNYS4i/JaGn38OzyPM6fOIiCqkaGJkYSH+HCGIPXa1lXUE1eZSMXTRp0UElFUU0Tbe2WIYmHT249FmstRTVNDIo7seftp5FmEZH+ReUZIkGivL6FfdVN7CipZ21+NRdOSqe4tpmMuHAcDsMf3tnGktwKEiND+deN0xmbHs0HW0p5ZNEuVudVkxgZSl1LO4mRoUwbGk9zm5ewEAe1zW0s2lHOmLRo0mPdLNhexqVTMpiSGcf9H+ygoqGVcJeTG2dnsWpvFZv31VLf0s6w5Eh+etF4fvzKRvZ2WmHyUGPSotlaXIfD+JL9No/FGBiVEs22kjpfzbcx1LW0E+Iw5GTFMzEjlhV7qiiqaWL8oFgqG1oJcRhW7q3qKJ0YkRLFd88excLtZby/pZTyet/E0EumDGJIQgSNrR5qmtp4ZW0hbR7L2PQYLp+agcNhKKhqZFhyFOPSYxiTFs3v39lGq8fLFScNJjUmjFV7q3htXRELt5dy31VTuHjyoBP+filpFhHpX5Q0iwwgpbXNRISFENWp00dru5e3NhZxxqhk3C7nYaszer2WysbWjs4hZXUtJEWFYoyvw8ieigYSIkM7JiSW1jbz1LI8rpmRSXpsOG0eL3mVjR1dTLYU1ZIQGUpdczs7S+t5elke54xPJTbcRVObh/GDYlm5p5LVeVV8flomV+VkEhriYG1+Ne9tLuGj7WXs9LctHJUaza6yeiJCQ9i4r4b/mzOcD7eWMWFQDK+s3Uerx0t0WAinj07m7LGpbC2u4x8Lc3E6DOEu3wTMs8amMiEjhmeX57OtxNeJZX+s4Jsg2tTmIcLlpKHV0zGKHxbiIDspkm0ldTxx8wxOG5l8Qt8LJc0iIv2LkmYR6Xf2X586991ubG0nIvTAHwNr8qpoaPEwIzuB0JADXTVKapuJi3B1dMvo/JpVjW20e70kR4Wxr6aZFbsreWFVAVdPz2Te2BQe/Xg3Da0eLp48iEGx4YSGOHjoo118fc7wg47RFUqaRUT6FyXNIiIBoKRZRKR/Odp1W2sTi4iIiIgcR0CSZmPMecaYbcaYncaYuwMRg4iIHP96bIwJM8b81//4MmNMVgDCFBEJuF5Pmo0xTuAB4HPAOOBaY8y43o5DRGSg6+L1+MtAlbV2BPAn4Le9G6WISN8QiJHmGcBOa+0ua20r8CxwSQDiEBEZ6LpyPb4EeNx/+wVgnuk8M1NEZIAIxIqAGUB+p/sFwMxDdzLG3Arc6r9bb4zZ9imOlQSUf4rn9QfBfG4Q3OcXzOcGOr9DHXl5yr6hK9fjjn2ste3GmBogkUO+Brpmd0kwn18wnxsE9/kF87nBpzu/I163++wy2tbah4CHPstrGGNWBuus9WA+Nwju8wvmcwOd30Cla/bxBfP5BfO5QXCfXzCfG3Tv+QWiPKMQyOx0f7B/m4iI9K6uXI879jHGhACxQEWvRCci0ocEImleAYw0xmQbY0KBa4BXAxCHiMhA15Xr8avADf7bVwIf2v7Q4F9EpJv1enmGvybuduAdwAk8aq3d1EOH+0wfFfZxwXxuENznF8znBjq/fuNo12NjzM+BldbaV4F/AU8aY3YClfgS654SNF/bowjm8wvmc4PgPr9gPjfoxvPrFysCioiIiIgEklYEFBERERE5DiXNIiIiIiLHEZRJczAu022M2WOM2WCMWWuMWenflmCMec8Ys8P/f3yg4+wqY8yjxphSY8zGTtuOeD7G537/93O9MeakwEV+fEc5t58aYwr937+1xpjzOz12j//cthljzg1M1F1jjMk0xsw3xmw2xmwyxnzLvz1YvndHO7+g+P71ZcF23dY1u1/93AftNRuC+7rd69dsa21Q/cM3mSUXGAaEAuuAcYGOqxvOaw+QdMi23wF3+2/fDfw20HGewPmcDpwEbDze+QDnA28BBjgZWBbo+D/Fuf0UuPMI+47zv0fDgGz/e9cZ6HM4xrmlAyf5b0cD2/3nECzfu6OdX1B8//rqv2C8buua3a9+7oP2mu2POWiv2719zQ7GkeaBtEx35+VtHwcuDVwoJ8Za+xG+mfidHe18LgGesD6fAHHGmPReCfRTOMq5Hc0lwLPW2hZr7W5gJ773cJ9krS2y1q72364DtuBbMS5YvndHO7+j6Vffvz5soFy3dc3ug4L5mg3Bfd3u7Wt2MCbNR1oW9lhfwP7CAu8aY1YZ33K1AKnW2iL/7WIgNTChdZujnU+wfE9v93/U9Winj2X77bkZY7KAqcAygvB7d8j5QZB9//qYYPw66pp9QH/9fgbdz3wwX7d745odjElzsDrVWnsS8DngNmPM6Z0ftL7PHYKmf2CwnQ/wd2A4MAUoAu4LaDSfkTEmCngR+La1trbzY8HwvTvC+QXV9096ha7Z/VvQ/cwH83W7t67ZwZg0B+Uy3dbaQv//pcDL+D5OKNn/kYn//9LARdgtjnY+/f57aq0tsdZ6rLVe4GEOfBzU787NGOPCd3F6ylr7kn9z0HzvjnR+wfT966OC7uuoa3b//n4G2898MF+3e/OaHYxJc9At022MiTTGRO+/DZwDbOTg5W1vAF4JTITd5mjn8yrwJf+M3pOBmk4fKfULh9SDXYbv+we+c7vGGBNmjMkGRgLLezu+rjLGGHwrxG2x1v6x00NB8b072vkFy/evDwuq67au2f3r5/5IgulnPpiv271+zf40sxX7+j98Mz+345sV+cNAx9MN5zMM32zPdcCm/ecEJAIfADuA94GEQMd6Auf0DL6PTNrw1RR9+Wjng28G7wP+7+cGICfQ8X+Kc3vSH/t6/w9teqf9f+g/t23A5wId/3HO7VR8H+GtB9b6/50fRN+7o51fUHz/+vK/YLpu65rd737ug/aa7Y83aK/bvX3N1jLaIiIiIiLHEYzlGSIiIiIi3UpJs4iIiIjIcShpFhERERE5DiXNIiIiIiLHoaRZREREROQ4lDRL0DDGeIwxazv9u7sbXzvLGLPx+HuKiEhX6Jot/U1IoAMQ6UZN1topgQ5CRES6RNds6Vc00ixBzxizxxjzO2PMBmPMcmPMCP/2LGPMh8aY9caYD4wxQ/zbU40xLxtj1vn/zfK/lNMY87AxZpMx5l1jTHjATkpEJEjpmi19lZJmCSbhh3zUd3Wnx2qstROBvwF/9m/7K/C4tXYS8BRwv3/7/cBCa+1k4CR8K3qBb7nNB6y144Fq4IoePRsRkeCma7b0K1oRUIKGMabeWht1hO17gDOttbuMMS6g2FqbaIwpx7e0Zpt/e5G1NskYUwYMtta2dHqNLOA9a+1I//3vAy5r7S974dRERIKOrtnS32ikWQYKe5TbJ6Kl020PmhMgItJTdM2WPkdJswwUV3f6f6n/9hLgGv/t64BF/tsfAF8HMMY4jTGxvRWkiIgAumZLH6S/uiSYhBtj1na6/7a1dn8Lo3hjzHp8Iw/X+rd9A/i3MeZ7QBlwk3/7t4CHjDFfxjc68XWgqKeDFxEZYHTNln5FNc0S9Pz1cTnW2vJAxyIiIsema7b0VSrPEBERERE5Do00i4iIiIgch0aaRURERESOQ0mziIiIiMhxKGkWERERETkOJc0iIiIiIsehpFlERERE5Dj+P72tfQXnfXuBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'accuracy']#, 'f1_m', 'recall_m']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(model_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837, 39)\n",
      "['id10013' 'id10009' 'id10009' 'id10003' 'id10009' 'id10009' 'id10009'\n",
      " 'id10009' 'id10009' 'id10009' 'id10004' 'id10009' 'id10009' 'id10009'\n",
      " 'id10009' 'id10009' 'id10009' 'id10009' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10001' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10007'\n",
      " 'id10007' 'id10007' 'id10007' 'id10007' 'id10007' 'id10014' 'id10007'\n",
      " 'id10006' 'id10014' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10014' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10014' 'id10006' 'id10006' 'id10006'\n",
      " 'id10006' 'id10006' 'id10006' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10017' 'id10001' 'id10001' 'id10001'\n",
      " 'id10001' 'id10001' 'id10001' 'id10001' 'id10001' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10001' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008' 'id10008'\n",
      " 'id10008' 'id10008' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10018' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10017' 'id10005' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10012'\n",
      " 'id10012' 'id10012' 'id10012' 'id10012' 'id10012' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10018' 'id10015' 'id10015' 'id10015'\n",
      " 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015' 'id10015'\n",
      " 'id10017' 'id10015' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10006' 'id10014' 'id10003' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10006' 'id10014' 'id10014' 'id10014' 'id10014' 'id10014'\n",
      " 'id10014' 'id10014' 'id10014' 'id10013' 'id10013' 'id10013' 'id10013'\n",
      " 'id10013' 'id10006' 'id10013' 'id10013' 'id10013' 'id10013' 'id10013'\n",
      " 'id10003' 'id10010' 'id10013' 'id10013' 'id10013' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004' 'id10004'\n",
      " 'id10004' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10002'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10017' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003' 'id10003'\n",
      " 'id10003' 'id10003' 'id10003' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10002'\n",
      " 'id10002' 'id10002' 'id10002' 'id10002' 'id10002' 'id10012' 'id10002'\n",
      " 'id10005' 'id10005' 'id10005' 'id10005' 'id10005' 'id10012' 'id10005'\n",
      " 'id10017' 'id10005' 'id10003' 'id10005' 'id10005' 'id10005' 'id10017'\n",
      " 'id10005' 'id10005' 'id10005' 'id10005' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10017' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10017' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10017'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10018' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10017' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10017' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016' 'id10016'\n",
      " 'id10019' 'id10016' 'id10016' 'id10011' 'id10016' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10011' 'id10011'\n",
      " 'id10011' 'id10011' 'id10011' 'id10011' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10012' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10017' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018' 'id10018'\n",
      " 'id10018' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020' 'id10020'\n",
      " 'id10020' 'id10020' 'id10020' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10019'\n",
      " 'id10019' 'id10019' 'id10019' 'id10019' 'id10019' 'id10018' 'id10010'\n",
      " 'id10003' 'id10016' 'id10010' 'id10008' 'id10010' 'id10010' 'id10010'\n",
      " 'id10010' 'id10010' 'id10010' 'id10007' 'id10010' 'id10010' 'id10010'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10003' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10016' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017' 'id10017'\n",
      " 'id10017' 'id10017' 'id10017' 'id10017']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.92      0.96      0.94        23\n",
      "     id10002       0.97      0.97      0.97        39\n",
      "     id10003       0.89      0.96      0.92        51\n",
      "     id10004       0.97      0.97      0.97        32\n",
      "     id10005       0.93      0.78      0.85        18\n",
      "     id10006       0.92      0.92      0.92        38\n",
      "     id10007       0.96      0.92      0.94        24\n",
      "     id10008       0.97      0.97      0.97        32\n",
      "     id10009       1.00      0.83      0.91        18\n",
      "     id10010       0.92      0.69      0.79        16\n",
      "     id10011       1.00      0.92      0.96        36\n",
      "     id10012       0.93      0.91      0.92        45\n",
      "     id10013       0.86      0.80      0.83        15\n",
      "     id10014       0.87      0.90      0.88        29\n",
      "     id10015       1.00      0.89      0.94        18\n",
      "     id10016       0.96      0.89      0.93        76\n",
      "     id10017       0.77      0.96      0.85        46\n",
      "     id10018       0.92      0.98      0.95        81\n",
      "     id10019       0.96      1.00      0.98        23\n",
      "     id10020       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           0.94       837\n",
      "   macro avg       0.94      0.91      0.92       837\n",
      "weighted avg       0.94      0.94      0.94       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = np.hstack((df_test['mfcc'].to_list(),\n",
    "                    df_test['delta'].to_list(),\n",
    "                    df_test['zcr'].to_list()))\n",
    "print(X_test.shape)\n",
    "y_true = df_test['speaker']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred = le.classes_[y_pred]\n",
    "print(y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     id10001       0.00      0.00      0.00        23\n",
      "     id10002       0.00      0.00      0.00        39\n",
      "     id10003       0.07      0.12      0.09        51\n",
      "     id10004       0.00      0.00      0.00        32\n",
      "     id10005       0.02      0.06      0.03        18\n",
      "     id10006       0.02      0.03      0.02        38\n",
      "     id10007       0.00      0.00      0.00        24\n",
      "     id10008       0.00      0.00      0.00        32\n",
      "     id10009       0.00      0.00      0.00        18\n",
      "     id10010       0.00      0.00      0.00        16\n",
      "     id10011       0.01      0.03      0.02        36\n",
      "     id10012       0.00      0.00      0.00        45\n",
      "     id10013       0.00      0.00      0.00        15\n",
      "     id10014       0.19      0.24      0.21        29\n",
      "     id10015       0.00      0.00      0.00        18\n",
      "     id10016       0.00      0.00      0.00        76\n",
      "     id10017       0.07      0.07      0.07        46\n",
      "     id10018       0.00      0.00      0.00        81\n",
      "     id10019       0.05      0.04      0.04        23\n",
      "     id10020       0.85      0.23      0.36       177\n",
      "\n",
      "    accuracy                           0.07       837\n",
      "   macro avg       0.06      0.04      0.04       837\n",
      "weighted avg       0.20      0.07      0.10       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import mixture\n",
    "# fit a Gaussian Mixture Model with two components\n",
    "gmm = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "gmm.fit(X_train)\n",
    "\n",
    "y_true_gmm = df_test['speaker']\n",
    "\n",
    "y_pred_gmm = gmm.predict(X_test)\n",
    "y_pred_gmm = le.classes_[y_pred_gmm]\n",
    "print(classification_report(y_true_gmm, y_pred_gmm, target_names=le.classes_))\n",
    "\n",
    "filename = 'saved_models/gaussian_mixture_model.sav'\n",
    "pickle.dump(gmm, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "# # display predicted scores by the model as a contour plot\n",
    "# x = np.linspace(0., 39., 39, endpoint=True)\n",
    "# # np.linspace(0, 10, N, endpoint=True)\n",
    "# y = np.linspace(0., 39., 39, endpoint=True)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "# XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "# Z = -clf.score_samples(XX)\n",
    "# Z = Z.reshape(X.shape)\n",
    "\n",
    "# CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0),\n",
    "#                  levels=np.logspace(0, 3, 10))\n",
    "# CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "# plt.scatter(X_train[:, 0], X_train[:, 1], .8)\n",
    "\n",
    "# plt.title('Negative log-likelihood predicted by a GMM')\n",
    "# plt.axis('tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
